{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_AI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "# MODEL = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the scarecrow win an award? \\n\\nBecause he was outstanding in his field!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 11, 'total_tokens': 29, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-1e8aaeb6-2c02-4a35-a073-3f372b8de3a9-0', usage_metadata={'input_tokens': 11, 'output_tokens': 18, 'total_tokens': 29})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(api_key=OPEN_AI_KEY, model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3.1\")\n",
    "\n",
    "model.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't skeletons fight each other? \\n\\nThey don't have the guts!\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'ece380_notes.pdf', 'page': 0}, page_content='ECE 380: Control Systems\\nCourse Notes: Winter 2014\\nProf. Shreyas Sundaram\\nDepartment of Electrical and Computer Engineering\\nUniversity of Waterloo'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 1}, page_content='ii\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 2}, page_content='Acknowledgments\\nParts of these course notes are loosely based on lecture notes by Professors\\nDaniel Liberzon, Sean Meyn, and Mark Spong (University of Illinois), on notes\\nby Professors Daniel Davison and Daniel Miller (University of Waterloo), and\\non parts of the textbook Feedback Control of Dynamic Systems (5th edition) by\\nFranklin, Powell and Emami-Naeini. I claim credit for all typos and mistakes\\nin the notes.\\nThe L ATEX template for The Not So Short Introduction to L ATEX 2εby T. Oetiker\\net al. was used to typeset portions of these notes.\\nShreyas Sundaram\\nUniversity of Waterloo\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 3}, page_content='iv\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 4}, page_content='Contents\\n1 Introduction 1\\n1.1 Dynamical Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.2 What is Control Theory? . . . . . . . . . . . . . . . . . . . . . . 2\\n1.3 Outline of the Course . . . . . . . . . . . . . . . . . . . . . . . . 4\\n2 Review of Complex Numbers 5\\n3 Review of Laplace Transforms 9\\n3.1 The Laplace Transform . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 The Inverse Laplace Transform . . . . . . . . . . . . . . . . . . . 13\\n3.2.1 Partial Fraction Expansion . . . . . . . . . . . . . . . . . 13\\n3.3 The Final Value Theorem . . . . . . . . . . . . . . . . . . . . . . 15\\n4 Linear Time-Invariant Systems 17\\n4.1 Linearity, Time-Invariance and Causality . . . . . . . . . . . . . . 17\\n4.2 Transfer Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n4.2.1 Obtaining the transfer function of a diﬀerential equation\\nmodel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.3 Frequency Response . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n5 Bode Plots 25\\n5.1 Rules for Drawing Bode Plots . . . . . . . . . . . . . . . . . . . . 26\\n5.1.1 Bode Plot for Ko. . . . . . . . . . . . . . . . . . . . . . . 27\\n5.1.2 Bode Plot for sq. . . . . . . . . . . . . . . . . . . . . . . 28\\n5.1.3 Bode Plot for (s\\np+ 1)−1and (s\\nz+ 1) . . . . . . . . . . . . 29\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 5}, page_content='vi CONTENTS\\n5.1.4 Bode Plot for(\\n(s\\nωn)2+ 2ζ(s\\nωn) + 1)±1\\n. . . . . . . . . . . 32\\n5.1.5 Nonminimum Phase Systems . . . . . . . . . . . . . . . . 34\\n6 Modeling and Block Diagram Manipulation 37\\n6.1 Mathematical Models of Physical Systems . . . . . . . . . . . . . 37\\n6.1.1 Mechanical Systems . . . . . . . . . . . . . . . . . . . . . 37\\n6.1.2 Electrical Systems . . . . . . . . . . . . . . . . . . . . . . 38\\n6.1.3 Rotational Systems . . . . . . . . . . . . . . . . . . . . . . 39\\n6.2 Block Diagram Manipulation . . . . . . . . . . . . . . . . . . . . 41\\n6.2.1 Systems with Multiple Inputs and Outputs . . . . . . . . 45\\n7 Step Responses of Linear Systems 47\\n7.1 Step Response of First Order Systems . . . . . . . . . . . . . . . 47\\n7.1.1 Rise time . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n7.1.2 Settling time . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n7.2 Step Response of Second Order Systems . . . . . . . . . . . . . . 50\\n7.2.1 Underdamped and Critically Damped Systems (0 ≤ζ≤1) 50\\n7.2.2 Overdamped System ( ζ >1) . . . . . . . . . . . . . . . . 52\\n7.2.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\n8 Performance of Second Order Step Responses 55\\n8.1 Performance Measures . . . . . . . . . . . . . . . . . . . . . . . . 55\\n8.1.1 Rise time ( tr) . . . . . . . . . . . . . . . . . . . . . . . . . 56\\n8.1.2 Peak value ( Mp), Peak time ( tp) and Overshoot OS . . . 56\\n8.1.3 Settling Time ( ts) . . . . . . . . . . . . . . . . . . . . . . 57\\n8.2 Choosing Pole Locations to Meet Performance Speciﬁcations . . 58\\n8.3 Eﬀects of Poles and Zeros on the Step Response . . . . . . . . . . 60\\n8.3.1 Eﬀect of a Zero on the Step Response . . . . . . . . . . . 61\\n8.3.2 Eﬀect of Poles on the Step Response . . . . . . . . . . . . 63\\n9 Stability of Linear Time-Invariant Systems 65\\n9.1 Pole-zero cancellations and stability . . . . . . . . . . . . . . . . 65\\n9.2 Stability of the Unity Feedback Loop . . . . . . . . . . . . . . . . 67\\n9.3 Tests for Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 6}, page_content='CONTENTS vii\\n9.3.1 A Necessary Condition for Stability . . . . . . . . . . . . 68\\n9.3.2 A Necessary and Suﬃcient Condition: Routh-Hurwitz Test 70\\n9.3.3 Testing For Degree of Stability . . . . . . . . . . . . . . . 72\\n9.3.4 Testing Parametric Stability with Routh-Hurwitz . . . . . 73\\n10 Properties of Feedback 75\\n10.1 Feedforward Control . . . . . . . . . . . . . . . . . . . . . . . . . 76\\n10.2 Feedback Control . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n11 Tracking of Reference Signals 81\\n11.1 Tracking and Steady State Error . . . . . . . . . . . . . . . . . . 82\\n12 PID Control 89\\n12.1 Proportional (P) Control . . . . . . . . . . . . . . . . . . . . . . 89\\n12.2 Proportional-Integral (PI) Control . . . . . . . . . . . . . . . . . 91\\n12.3 Proportional-Integral-Derivative (PID) Control . . . . . . . . . . 91\\n12.4 Implementation Issues . . . . . . . . . . . . . . . . . . . . . . . . 93\\n13 Root Locus 95\\n13.1 The Root Locus Equations . . . . . . . . . . . . . . . . . . . . . 97\\n13.1.1 Phase Condition . . . . . . . . . . . . . . . . . . . . . . . 98\\n13.2 Rules for Plotting the Positive Root Locus . . . . . . . . . . . . . 100\\n13.2.1 Start Points and (Some) End Points of the Root Locus . 100\\n13.2.2 Points on the Real Axis . . . . . . . . . . . . . . . . . . . 100\\n13.2.3 Asymptotic Behavior of the Root Locus . . . . . . . . . . 101\\n13.2.4 Breakaway Points . . . . . . . . . . . . . . . . . . . . . . . 105\\n13.2.5 Some Root Locus Plots . . . . . . . . . . . . . . . . . . . 108\\n13.2.6 Choosing the Gain from the Root Locus . . . . . . . . . . 110\\n13.3 Rules for Plotting the Negative Root Locus . . . . . . . . . . . . 111\\n14 Stability Margins from Bode Plots 115\\n15 Compensator Design Using Bode Plots 123\\n15.1 Lead and Lag Compensators . . . . . . . . . . . . . . . . . . . . 123\\n15.2 Lead Compensator Design . . . . . . . . . . . . . . . . . . . . . . 126\\n15.3 Lag Compensator Design . . . . . . . . . . . . . . . . . . . . . . 130\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 7}, page_content='viii CONTENTS\\n16 Nyquist Plots 135\\n16.1 Nyquist Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\n16.2 Drawing Nyquist Plots . . . . . . . . . . . . . . . . . . . . . . . . 140\\n16.2.1 Nyquist Plots For Systems With Poles/Zeros On The Imag-\\ninary Axis . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\n16.3 Stability Margins from Nyquist Plots . . . . . . . . . . . . . . . . 146\\n17 Modern Control Theory: State Space Models 151\\n17.1 State-Space Models . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\n17.2 Nonlinear State-Space Models and Linearization . . . . . . . . . 156\\n17.2.1 Linearization via Taylor Series . . . . . . . . . . . . . . . 157\\n17.3 The Transfer Function of a Linear State-Space Model . . . . . . 159\\n17.4 Obtaining the Poles from the State-Space Model . . . . . . . . . 160\\n17.5 An Overview of Design Approaches for State-Space Models . . . 162\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 8}, page_content='Chapter 1\\nIntroduction\\n1.1 Dynamical Systems\\nFor the purposes of this course, a system is an abstract object that accepts inputs\\nand produces outputs in response. Systems are often composed of smaller com-\\nponents that are interconnected together, leading to behavior that is more than\\njust the sum of its parts. In the control literature, systems are also commonly\\nreferred to as plants orprocesses .\\nSystemInput Output\\nFigure 1.1: An abstract representation of a system.\\nThe term dynamical system loosely refers to any system that has an internal\\nstate and some dynamics (i.e., a rule specifying how the state evolves in time).\\nThis description applies to a very large class of systems, from automobiles and\\naviation to industrial manufacturing plants and the electrical power grid. The\\npresence of dynamics implies that the behavior of the system cannot be en-\\ntirely arbitrary; the temporal behavior of the system’s state and outputs can be\\npredicted to some extent by an appropriate model of the system.\\nExample 1. Consider a simple model of a car in motion. Let the speed of\\nthe car at any time tbe given by v(t). One of the inputs to the system is the\\nacceleration a(t), applied by the throttle. From basic physics, the evolution of\\nthe speed is given by\\ndv\\ndt=a(t). (1.1)\\nThe quantity v(t) is the state of the system, and equation (1.1) speciﬁes the\\ndynamics. There is a speedometer on the car, which is a sensor that measures\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 9}, page_content='2 Introduction\\nthe speed. The value provided by the sensor is denoted by s(t) =v(t), and this\\nis taken to be the output of the system.\\nAs shown by the above example, the inputs to physical systems are applied via\\nactuators , and the outputs are measurements of the system state provided by\\nsensors .\\nOther examples of systems: Electronic circuits, DC Motor, Economic Sys-\\ntems,...\\n1.2 What is Control Theory?\\nThe ﬁeld of control systems deals with applying or choosing the inputs to a\\ngiven system to make it behave in a certain way (i.e., make the state or output\\nof the system follow a certain trajectory). A key way to achieve this is via the\\nuse of feedback , where the input depends on the output in some way. This is\\nalso called closed loop control .\\nSystemOutput\\nMapping from\\noutput to inputInput\\nFigure 1.2: Feedback Control.\\nTypically, the mapping from outputs to inputs in the feedback loop is performed\\nvia a computational element known as a controller , which processes the sensor\\nmeasurements and converts it to an appropriate actuator signal. The basic\\narchitecture is shown below. Note that the feedback loop typically contains\\ndisturbances that we cannot control.\\nController SystemDesired\\nOutputControl\\nInput Output\\n−\\nFigure 1.3: Block Diagram of a feedback control system.\\nExample 2 (Cruise Control) .Consider again the simple model of a car from\\nExample 1. A cruise control system for the car would work as follows.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 10}, page_content='1.2 What is Control Theory? 3\\n•The speedometer in the car measures the current speed and produces\\ns(t) =v(t).\\n•The controller in the car uses these measurements to produce control sig-\\nnals: if the current measurement s(t) is less than the desired cruising\\nspeed, the controller sends a signal to the throttle to accelerate, and if\\ns(t) is greater than the desired speed, the throttle is asked to allow the\\ncar to slow down.\\n•The throttle performs the action speciﬁed by the controller.\\nThe motion of the car might also be aﬀected by disturbances such as wind\\ngusts, or slippery road conditions. A properly designed cruise control system\\nwill maintain the speed at (or near) the desired value despite these external\\nconditions.\\nExample 3 (Inverted Pendulum) .Suppose we try to balance a stick vertically\\nin the palm of our hand. The sensor, controller and actuator in this example\\nare our eyes, our brain, and our hand, respectively. This is an example of a\\nfeedback control system. Now what happens if we try to balance the stick\\nwith our eyes closed? The stick inevitably falls. This illustrates another type\\nof control, known as feedforward oropen loop control, where the input to the\\nsystem does not depend on the output. As this example illustrates, feedforward\\ncontrol is not robust to disturbances – if the stick is not perfectly balanced to\\nstart, or if our hand moves very slightly, the stick will fall. This illustrates the\\nbeneﬁt of feedback control.\\nAs we will see later, feedback control has many strengths, and is used to achieve\\nthe following objectives.\\n•Good tracking . Loosely speaking, feedback control allows us to make\\nthe output of the system follow the desired reference input (i.e., make the\\nsystem behave as it should).\\n•Disturbance rejection . Feedback control allows the system to maintain\\ngood behavior even when there are external inputs that we cannot control.\\n•Robustness . Feedback control can work well even when the actual model\\nof the plant is not known precisely; suﬃciently small errors in modeling\\ncan be counteracted by the feedback input.\\nFeedback control is everywhere; it appears not only in engineered systems (such\\nas automobiles and aircraft), but also in economic systems (e.g., choosing the\\ninterest rates to maintain a desired rate of inﬂation, growth, etc.), ecological sys-\\ntems (predator/prey populations, global climate) and biological systems (e.g.,\\nphysiology in animals and plants).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 11}, page_content='4 Introduction\\nExample 4 (Teary Eyes on a Cold Day) .Blinking and tears are a feedback\\nmechanism used by the body to warm the surface of the eyeball on cold days –\\nthe insides of the lids warm the eyes. In very cold situations, tears come from\\ninside the body (where they are warmed), and contain some proteins and salts\\nthat help to prevent front of eyes from freezing.\\n1.3 Outline of the Course\\nSince control systems appear in a large variety of applications, we will not\\nattempt to discuss each speciﬁc application in this course. Instead, we will\\ndeal with the underlying mathematical theory, analysis, and design of control\\nsystems. In this sense, it will be more mathematical than other engineering\\ncourses, but will be diﬀerent from other math courses in that it will pull together\\nvarious branches of mathematics for a particular purpose (i.e., to design systems\\nthat behave in desired ways).\\nThe trajectory of the course will be as follows.\\n•Modeling: Before we can control a system and make it behave in a\\ndesired manner, we need to represent the input-output behavior of the\\nsystem in a form that is suitable for mathematical analysis.\\n•Analysis: Once we understand how to model systems, we need to have a\\nbasic understanding of what the model tells us about the system’s response\\nto input signals. We will also need to formulate how exactly we want the\\noutput to get to its desired value (e.g., how quickly should it get there, do\\nwe care what the output does on the way there, can we be sure that the\\noutput will get there, etc.)\\n•Design: Finally, once we have analyzed the mathematical model of the\\nsystem, we will study ways to design controllers to supply appropriate\\ncontrol (input) signals to the system so that the output behaves as we\\nwant it to.\\nWe will be analyzing systems both in the time-domain (e.g., with diﬀerential\\nequations) and in the frequency domain (e.g., using Laplace transforms). We\\nwill start by reviewing some relevant mathematical concepts.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 12}, page_content='Chapter 2\\nReview of Complex\\nNumbers\\nConsider the polynomial f(x) =x2+ 1. The roots of the polynomial are the\\nvalues ofxfor whichf(x) = 0, or equivalently x2=−1. Clearly, there are no\\nrealnumbers that satisfy this equation. To address this problem, let us deﬁne\\na new “number” j, such that j2=−1. Since this number does not belong to\\nthe set of real numbers, we will call it an imaginary orcomplex number. With\\nthis number in hand, we can actually generate an inﬁnite set of other complex\\nnumbers.1\\nDeﬁnition 1 (Complex Numbers) .A complex number sis\\nof the form s=σ+jω, whereσandωare real numbers.\\nThe number σis called the real part of s, and is denoted\\nbyσ= Re(s). The number ωis called the imaginary part\\nofsand is denoted by ω= Im(s). The set of all complex\\nnumbers is denoted by C.\\nA complex number σ+jωcan alternatively be viewed simply as a pair of real\\nnumbers (σ,ω). Thus, we can plot complex numbers in a two-dimensional plane\\ncalled the complex plane . The horizontal axis is called the real axis and the\\nvertical axis is called the imaginary axis . The real axis represents all complex\\nnumbersssuch that Im( s) = 0; in other words, it contains all real numbers, and\\nthus real numbers are a subset of the complex numbers. The imaginary axis\\nrepresents all complex numbers ssuch that Re( s) = 0. The following regions of\\nthe plane will be useful to our discussions.\\n1An excellent (and intuitive) perspective on complex numbers can be found\\nin a New York Times essay written by Steven Strogatz; it is available at\\nhttp://opinionator.blogs.nytimes.com/2010/03/07/ﬁnding-your-roots/.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 13}, page_content='6 Review of Complex Numbers\\n•All complex numbers ssatisfying Re( s)<0 are said to lie in the Open\\nLeft Half Plane (OLHP).\\n•All complex numbers ssatisfying Re( s)≤0 are said to lie in the Closed\\nLeft Half Plane (CLHP).\\n•All complex numbers ssatisfying Re( s)>0 are said to lie in the Open\\nRight Half Plane (ORHP).\\n•All complex numbers ssatisfying Re( s)≥0 are said to lie in the Closed\\nRight Half Plane (CRHP).\\nFigure 2.1: A complex number s=σ+jωin the complex plane.\\nAn alternative representation of complex numbers is the polar form . Speciﬁcally,\\ngiven a complex number s=σ+jω, note that sis also speciﬁed uniquely by its\\ndistancerfrom the origin, and the angle θthats(as a vector from the origin)\\nmakes with the positive real axis:\\nr=√\\nσ2+ω2, θ = arctanω\\nσ.\\nThe number ris called the magnitude ofs, and is denoted by r=|s|. The\\nnumberθis called the phase ofs(in radians), and is denoted by θ=∠s.\\nConversely, we have σ=rcosθandω=rsinθ.\\nExample. What is the polar form representation of s= 3−j4?\\nNote from Euler’s equation that ejθ= cosθ+jsinθ, and so the complex number\\nscan be denoted by s=rejθ.\\nGiven the complex number s=σ+jω, its complex conjugate is deﬁned as the\\ncomplex number s∗=σ−jω. Note that\\nss∗= (σ+jω)(σ−jω) =σ2+ω2=|s|2=|s∗|2.\\nIn the geometric representation, the complex conjugate of a complex number is\\nobtained by reﬂecting the vector about the real axis.\\nAs we will see throughout the course, many interesting properties of control\\nsystems are related to the roots of certain polynomials. The following result\\nexplains why complex numbers are so useful.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 14}, page_content='7\\nTheorem 1 (Fundamental Theorem of Algebra) .Consider\\nany polynomial f(x) =anxn+an−1xn−1+···+a1x+a0,\\nwhere the coeﬃcients an,an−1,...,a 0are complex numbers.\\nThen the polynomial has ncomplex roots. Furthermore, if all\\ncoeﬃcients are real, then all non-real roots of f(x)appear in\\ncomplex conjugate pairs.\\nDecomposing a Real Polynomial into Factors\\nLetf(x) be a polynomial of degree nwith all real coeﬃcients. Suppose that\\nf(x) hasqroots atx= 0,rnonzero real roots at locations z1,z2,...,zr, and 2p\\ncomplex conjugate roots at c1,c∗\\n1,c2,c∗\\n2,...,cp,c∗\\np(we know that these complex\\nroots appear in complex conjugate pairs). Now, note that\\n(x−ci)(x−c∗\\ni) =x2−(ci+c∗\\ni)x+cic∗\\ni=x2−2Re(ci)x+|ci|2.\\nIf we deﬁne ωi=|ci|and\\nζi=−Re(ci)\\nωi\\nwe can write\\n(x−ci)(x−c∗\\ni) =x2+ 2ζiωix+ω2\\ni.\\nWe will be using this notation frequently throughout the course. The polynomial\\nf(x) can therefore always be decomposed as\\nf(x) =K0xq(x−z1)(x−z2)···(x−zr)(x2+2ζ1ω1x+ω2\\n1)···(x2+2ζpωpx+ω2\\np)\\nfor some constant K0.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 15}, page_content='8 Review of Complex Numbers\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 16}, page_content='Chapter 3\\nReview of Laplace\\nTransforms\\n3.1 The Laplace Transform\\nSupposef(t) is a function of time. In this course, unless otherwise noted, we\\nwill only deal with functions that satisfy f(t) = 0 fort<0.\\nTheLaplace Transform of the function f(t) is deﬁned as\\nL{f(t)}=∫∞\\n0f(t)e−stdt .\\nThis is a function of the complex variable s, so we can write L{f(t)}=F(s).\\nNote: There are various conditions that f(t) must satisfy in order to have\\na Laplace Transform. For example, it must not grow faster than estfor some\\ns. In this course, we will only deal with functions that have (unique) Laplace\\nTransforms.1\\nExample. Find the Laplace Transform of f(t) =e−at,t≥0, wherea∈R.\\nSolution.\\nF(s) =L{f(t)}=∫∞\\n0e−ate−stdt\\n=∫∞\\n0e−(s+a)tdt\\n1Uniqueness may be lost at points of discontinuity. More speciﬁcally, if f(t) and g(t) are\\npiecewise continuous functions, then F(s) =G(s) for all simplies that f(t) =g(t) everywhere\\nexcept at the points of discontinuity.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 17}, page_content='10 Review of Laplace Transforms\\n=−1\\ns+ae−(s+a)t⏐⏐⏐∞\\n0=1\\ns+a(if Re(s+a)>0).\\nExample. Find the Laplace Transform of the unit step function 1(t), deﬁned\\nas\\n1(t) ={1 ift≥0,\\n0 otherwise.\\nFigure 3.1: The unit step function 1(t).\\nSolution.\\nExample: The Dirac delta function (or impulse function). Consider the\\nfunctionδϵ(t) deﬁned as\\nδϵ(t) ={1\\nϵif 0≤t≤ϵ,\\n0 otherwise,\\nwhereϵis a small positive number.\\nFigure 3.2: (a) The function δϵ(t). (b) The impulse function δ(t).\\nNote that∫∞\\n−∞δϵ(t)dt= 1. Now suppose that we let ϵ→0; we still have\\nlim\\nϵ→0∫∞\\n−∞δϵ(t)dt= 1.\\nNote that as ϵgets smaller, the function gets narrower, but taller. Deﬁne the\\nimpulse function\\nδ(t) = lim\\nϵ→0δϵ(t) ={∞ ift= 0,\\n0 otherwise.\\nSome properties of δ(t):\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 18}, page_content='3.1 The Laplace Transform 11\\n•∫∞\\n−∞δ(t)dt= 1.\\n•Letf(t) be any function. Then∫∞\\n−∞δ(t−τ)f(t)dt=f(τ). This is called\\nthesifting property.\\nWhat is the Laplace Transform of δ(t)?\\nSolution.L{δ(t)}=∫∞\\n0δ(t)e−stdt=e0= 1.\\nTransforms of other common functions can be obtained from Laplace Transform\\ntables:\\nTable 3.1: Sample Table of Laplace Transforms.\\nf(t),t≥0F(s)\\nδ(t) 1\\n1(t)1\\ns\\ne−at 1\\ns+a\\nt1\\ns2\\nsinωtω\\ns2+ω2\\ncosωts\\ns2+ω2\\n......\\nNote: The functions f(t) in this table are only deﬁned for t≥0 (i.e., we are\\nassuming that f(t) = 0 fort<0).\\nSome properties of the Laplace Transform\\n1.Linearity.L{αf1(t) +βf2(t)}=αF1(s) +βF2(s).\\nExample. What isL{5e−3t−2 cos 4t}?\\nSolution.\\n2.Time Delay. Consider a delayed signalf(t−λ),λ≥0 (i.e., a shifted\\nversion off(t)).\\nL{f(t−λ)}=∫∞\\n0f(t−λ)e−stdt=∫∞\\nλf(t−λ)e−stdt\\n=∫∞\\n0f(τ)e−s(τ+λ)dτ(lettingτ=t−λ)\\n=e−sλF(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 19}, page_content='12 Review of Laplace Transforms\\nFigure 3.3: The time-delayed signal f(t−λ).\\nExample. What isL{1(t−5)}?\\nSolution.\\n3.Diﬀerentiation. L{df\\ndt}=sF(s)−f(0). More generally,\\nL{dmf\\ndtm}=smF(s)−sm−1f(0)−sm−2df\\ndt(0)−···−dm−1f\\ndtm−1(0).\\nExample. What isL{d\\ndte−at}?\\nSolution.\\n4.Integration.L{∫t\\n0f(τ)dτ}=1\\nsF(s).\\nExample. What isL{∫t\\n0cosτdτ}?\\nSolution.\\n5.Convolution. The convolution of two signals f1(t) andf2(t) is denoted\\nby\\nf1(t)∗f2(t) =∫t\\n0f1(τ)f2(t−τ)dτ .\\nThe Laplace Transform of the convolution of two signals is given by\\nL{f1(t)∗f2(t)}=F1(s)F2(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 20}, page_content='3.2 The Inverse Laplace Transform 13\\nThis is a very important property of Laplace Transforms! Convolution of\\ntwo signals in the time-domain (which could be hard to do) is equivalent\\nto the multiplication of their Laplace Transforms in the sdomain (which\\nis easy to do).\\nExample. What isL{1(t)∗1(t)}?\\nSolution.\\n3.2 The Inverse Laplace Transform\\nGiven the Laplace Transform F(s), we can obtain the corresponding time-\\ndomain function f(t) via the Inverse Laplace Transform:\\nf(t) =L−1{F(s)}=1\\n2πj∫σ+j∞\\nσ−j∞F(s)estds .\\nThis is quite tedious to apply in practice, and so we will not be using it in this\\nclass. Instead, we can simply use the Laplace Transform tables to obtain the\\ncorresponding functions.\\nExample. What isL−1{1\\ns(s+1)}?\\nSolution.\\nL−1{1\\ns(s+ 1)}=L−1{1\\ns−1\\ns+ 1}\\n=L−1{1\\ns}−L−1{1\\ns+ 1}\\n(by linearity of the (inverse) Laplace Transform)\\n=1(t)−e−t, t≥0.\\nIn the above example, we “broke up” the function1\\ns(s+1)into a sum of simpler\\nfunctions, and then applied the inverse Laplace Transform (by consulting the\\nLaplace Transform table) to each of them. This is a general technique for\\ninverting Laplace Transforms.\\n3.2.1 Partial Fraction Expansion\\nSuppose we have a rational function\\nF(s) =bmsm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0=N(s)\\nD(s),\\nwhere theai’s andbi’s are constant real numbers.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 21}, page_content='14 Review of Laplace Transforms\\nDeﬁnition 2. Ifm≤n, the rational function is called\\nproper . Ifm<n , it is strictly proper .\\nBy factoring N(s) andD(s), we can write\\nF(s) =K(s+z1)(s+z2)···(s+zm)\\n(s+p1)(s+p2)···(s+pn).\\nDeﬁnition 3 (Zeros and Poles) .The complex numbers\\n−z1,−z2,...,−zmare the roots of N(s) and are called the\\nzeros ofF(s). The complex numbers −p1,−p2,...,−pnare\\nthe roots of D(s) and are called the poles ofF(s).\\nNote: Remember these terms, as the poles and zeros of a system will play a\\nvery important role in our ability to control it.\\nFirst, suppose each of the poles are distinct and that F(s) is strictly proper.\\nWe would like to write\\nF(s) =k1\\ns+p1+k2\\ns+p2+···+kn\\ns+pn,\\nfor some constants k1,k2,...,kn, since the inverse Laplace Transform of F(s)\\nis easy in this form. How do we ﬁnd k1,k2,...,kn?\\nHeaviside’s Cover-up Method. To ﬁnd the constant ki, multiply both sides\\nof the expansion of F(s) by (s+pi):\\n(s+pi)F(s) =k1(s+pi)\\ns+p1+k2(s+pi)\\ns+p2+···+ki+···+kn(s+pi)\\ns+pn.\\nNow if we let s=−pi, then all terms on the right hand side will be equal to\\nzero, except for the term ki. Thus, we obtain\\nki= (s+pi)F(s)|s=−pi.\\nExample. What is the partial fraction expansion of F(s) =s+5\\ns3+3s2−6s−8?\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 22}, page_content='3.3 The Final Value Theorem 15\\nSolution.\\nThe partial fraction expansion when some of the poles are repeated is obtained\\nby following a similar procedure, but it is a little more complicated. We will\\nnot worry too much about this scenario here. One can also do a partial fraction\\nexpansion of nonstrictly proper functions by ﬁrst dividing the denominator into\\nthe numerator to obtain a constant and a strictly proper function, and then\\napplying the above partial fraction expansion. The details will be covered in a\\nhomework problem.\\n3.3 The Final Value Theorem\\nLetF(s) be the Laplace Transform of a function f(t). Often, we will be in-\\nterested in how f(t) behaves as t→∞ (this is referred to as the asymptotic\\norsteady state behavior of f(t)). Can we obtain this information directly from\\nF(s)?\\nTheorem 2 (Final Value Theorem) .If all poles of sF(s)\\nare in the open left half plane, then\\nlim\\nt→∞f(t) = lim\\ns→0sF(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 23}, page_content='16 Review of Laplace Transforms\\nExample. F(s) =1\\ns(s+1). What is lim t→∞f(t)?\\nSolution.\\nWhy do we need the poles of sF(s) to be in the OLHP in order to apply the\\nFinal Value Theorem? First, note from the partial fraction expansion of F(s)\\nthat\\nF(s) =k1\\ns+k2\\ns+p2+k3\\ns+p3+···+kn\\ns+pn\\n⇔f(t) =k11(t) +k2e−p2t+k3e−p3t+···+kne−pnt.\\nNote that if F(s) does not have a pole at s= 0, then the constant k1will simply\\nbe zero in the above expansion. Based on the above expansion, if one of the\\npoles has a positive real part, the corresponding exponential term will explode,\\nand thusf(t) will have no ﬁnal value! On the other hand, if all poles have\\nnegative real parts, all of the exponential terms will go to zero, leaving only the\\ntermk11(t) (corresponding tok1\\nsin the partial fraction expansion). Thus, the\\nasymptotic behavior of f(t) is simply k1, and this is obtained by calculating\\nlims→0sF(s).\\nOne must be careful about applying the Final Value Theorem; if the signal f(t)\\ndoes not settle down to some constant steady state value, the theorem might\\nyield nonsensical results. For example, consider the function f(t) = sint, with\\nLaplace transform\\nF(s) =1\\ns2+ 1.\\nThe function sF(s) does not have all poles in the OLHP (it has two poles on the\\nimaginary axis). However, if we forgot to check this before applying the Final\\nValue Theorem, we would get\\nlim\\ns→0sF(s) = 0,\\nand would mistakenly assume that f(t)→0. Clearlyf(t) has no steady state\\nvalue (it constantly oscillates between −1 and 1).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 24}, page_content='Chapter 4\\nLinear Time-Invariant\\nSystems\\n4.1 Linearity, Time-Invariance and Causality\\nConsider the system:\\nSystemInput Output\\nThe system is said to be linear if the Principle of Superposition holds.\\nDeﬁnition 4 (Principle of Superposition) .Suppose that the\\noutput of the system is y1(t) in response to input u1(t) and\\ny2(t) in response to input u2(t). Then the output of the\\nsystem in response to the input αu1(t) +βu2(t) isαy1(t) +\\nβy2(t), whereαandβare arbitrary real numbers. Note that\\nthis must hold for anyinputsu1(t) andu2(t).\\nThe system is said to be time-invariant if the output of the system is y(t−τ)\\nwhen the input is u(t−τ) (i.e., a time-shifted version of the input produces an\\nequivalent time-shift in the output).\\nThe system is said to be causal if the output at time tdepends only on the\\ninput up to time t. In particular, this means that if u(t) = 0 fort < τ , then\\ny(t) = 0 fort<τ .\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 25}, page_content='18 Linear Time-Invariant Systems\\nFigure 4.1: The Principle of Superposition.\\nFigure 4.2: The Time-Invariance Property\\nIn this class, we will primarily be dealing with the analysis of linear time-\\ninvariant causal systems (if the system is nonlinear, we will linearize it). We\\nwill be interested in how the system responds to certain types of inputs. The\\nimpulse response of a system is the output of the system when the input to\\nthe system is δ(t), and is denoted by the signal h(t). The step response is the\\noutput of the system when the input to the system is 1(t).\\nNote: The impulse response for causal systems satisﬁes h(t) = 0 fort<0.\\n4.2 Transfer Functions\\nRecall from the sifting property of the delta function that u(t) =∫∞\\n0u(τ)δ(t−\\nτ)dτ. Note that this can be interpreted in the following way: the signal u(t) is\\nthesum of an inﬁnite series of weighted and shifted delta functions. The delta\\nfunction at t=τis weighted by the value u(τ). Now, the time-invariance of\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 26}, page_content='4.2 Transfer Functions 19\\nFigure 4.3: (a) A causal system. (b) A non-causal system.\\nthe system says that the output of the system due to the input δ(t−τ) will be\\nh(t−τ). Using the Principle of Superposition, we see that the output of the\\nsystem when u(t) is the input will be the inﬁnite sum (or integral) of weighted\\nand shifted impulse responses (when all initial conditions are equal to zero):\\ny(t) =∫∞\\n0u(τ)h(t−τ)dτ .\\nNote that the output of the system is just the convolution of the signals u(t)\\nandh(t)! This is a well known relationship for linear time-invariant systems.\\nApplying Laplace Transforms to both sides of the above equation, we obtain\\nY(s) =H(s)U(s), or equivalently,\\nH(s) =Y(s)\\nU(s).\\nThe function H(s) is the ratio of the Laplace Transform of the output to the\\nLaplace Transform of the input (when all initial conditions are zero), and it is\\ncalled the transfer function of the system. Note that this transfer function is\\nindependent of the actual values of the inputs and outputs – it tells us how any\\ninput gets transformed into the output. It is a property of the system itself. We\\nwill frequently represent systems in block diagrams via their transfer functions:\\nH(s)Input\\nU(s)Output\\nY(s)\\nNote: The transfer function is the Laplace Transform of the impulse response\\nof the system.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 27}, page_content='20 Linear Time-Invariant Systems\\n4.2.1 Obtaining the transfer function of a diﬀerential equa-\\ntion model\\nWe will be dealing with systems whose input and output are related via a\\ndiﬀerential equation of the form\\ny(n)+an−1y(n−1)+···+a1˙y+a0y=bmu(m)+bm−1u(m−1)+···+b1˙u+b0u .\\nTaking Laplace Transforms of both sides (assuming that all initial conditions\\nare zero), we get\\n(sn+an−1sn−1+···+a1s+a0)Y(s) = (bmsm+bm−1sm−1+···+b1s+b0)U(s),\\nfrom which we obtain the transfer function\\nH(s) =Y(s)\\nU(s)=bmsm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0.\\nThe impulse response of this system is given by h(t) =L−1{H(s)}.\\nExample. Consider the system given by the diﬀerential equation ˙ y+3y= 2u(t).\\nWhat is the transfer function of this system? What is the impulse response?\\nWhat is the step response?\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 28}, page_content='4.3 Frequency Response 21\\n4.3 Frequency Response\\nSuppose that the input to the system is u(t) =es0t,t≥0, for some s0=σ+jω.\\nRecall that\\ny(t) =∫∞\\n0u(τ)h(t−τ)dτ=∫∞\\n0u(t−τ)h(τ)dτ .\\nSince both u(t) andh(t) are zero for t<0, the above expression becomes\\ny(t) =∫t\\n0u(t−τ)h(τ)dτ=∫t\\n0es0(t−τ)h(τ)dτ=es0t∫t\\n0e−s0τh(τ)dτ .\\nThe quantity∫t\\n0e−s0τh(τ)dτlooks a lot like the Laplace Transform of the signal\\nh(τ) evaluated at s=s0, except that the upper limit on the integration is t\\ninstead of∞. Suppose that we examine what happens when tbecomes very\\nlarge (i.e., as t→∞ ). In this case, if the integral exists, we can write\\ny(t) =H(s0)es0t.\\nThus, the asymptotic response (if H(s0) exists) to a complex exponential input\\nis that same complex exponential, scaled by the transfer function evaluated at\\ns0. This gives us one potential way to identify the transfer function of a given\\n“black box” system: apply the input es0tfor several diﬀerent values of s0, and\\nuse that to infer H(s).\\nProblem: If Re(s0)>0, thenes0tblows up very quickly, and if Re( s0)<0, it\\ndecays very quickly. What about s0=jω? This would solve the problem. How\\ndo we apply ejωtin practice?\\nSolution: Sinusoids. Recall the identity cos ωt=ejωt+e−jωt\\n2. Using the\\nPrinciple of Superposition and the property derived above:\\n•The response of the system to the input u1(t) =1\\n2ejωtis\\ny1(t) =1\\n2H(jω)ejωt.\\n•The response of the system to the input u2(t) =1\\n2e−jωtis\\ny2(t) =1\\n2H(−jω)e−jωt.\\nNote thatH(jω) is just a complex number, and so we can write it in the polar\\nformH(jω) =|H(jω)|ej∠H(jω), where|H(jω)|is the magnitude of H(jω) and\\n∠H(jω) is the phase of H(jω) (they will both depend on the choice of ω).\\nSimilarly,H(−jω) is just the complex conjugate of H(jω),1and so we can\\n1You should be able to prove this by using the fact that the numerator and denominator\\nofH(s) are polynomials with real coeﬃcients.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 29}, page_content='22 Linear Time-Invariant Systems\\nwriteH(−jω) =|H(jω)|e−j∠H(jω). Using these identities, and the Principle of\\nSuperposition, the output of the system when the input is u(t) =u1(t)+u2(t) =\\ncosωtis\\ny(t) =y1(t) +y2(t) =1\\n2H(jω)ejωt+1\\n2H(−jω)e−jωt\\n=1\\n2|H(jω)|ej∠H(jω)ejωt+1\\n2|H(jω)|e−j∠H(jω)e−jωt\\n=1\\n2|H(jω)|(\\nej(ωt+∠H(jω))+e−j(ωt+∠H(jω)))\\n=|H(jω)|cos(ωt+∠H(jω)).\\nIn other words, the (steady-state) response to the sinusoid cos ωtis a scaled and\\nphase-shifted version of the sinusoid! This is called the frequency response\\nof the system, and will be a useful fact to identify and analyze linear systems.\\nLater, we will be plotting the magnitude and phase of the system as we sweep\\nωfrom 0 to∞; this is called the Bode plot of the system.\\nAs an example, consider a linear system with transfer function\\nH(s) =ω2\\nn\\ns2+ 2ζωns+ω2n,\\nwhereζandωnare some real numbers. We will study systems of this form in\\nmore detail later in the course. Since the denominator of this transfer function\\nhas degree 2, it is called a second order system. The magnitude of this function\\nats=jωis given by\\n|H(jω)|=ω2\\nn\\n|−ω2+ 2ζωnωj+ω2n|\\n=ω2\\nn√\\n(ω2n−ω2)2+ 4ζ2ω2nω2=1√\\n(1−(ω\\nωn)2)2+ 4ζ2(ω\\nωn)2,\\nand the phase is given by\\n∠H(jω) =∠ω2\\nn\\n−ω2+ 2ζωnωj+ω2n\\n=∠1\\n−(ω\\nωn)2+ 2ζ(ω\\nωn)j+ 1=−tan−1\\uf8eb\\n\\uf8ec\\uf8ed2ζω\\nωn\\n1−(\\nω\\nωn)2\\uf8f6\\n\\uf8f7\\uf8f8.\\nSince these quantities are a function ofω\\nωn, we can plot them vsω\\nωnfor vari-\\nous values of ζ. Note that in the following plots, we used a logarithmic scale\\nfor the frequency. This is commonly done in order to include a wider range\\nof frequencies in our plots. The intervals on logarithmic scales are known as\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 30}, page_content='4.3 Frequency Response 23\\ndecades .\\nWe can label the following important characteristics of the magnitude plot:\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 31}, page_content='24 Linear Time-Invariant Systems\\n•The magnitude of the transfer function for low frequencies (i.e., near ω=\\n0) is called the low frequency gain or the DC gain .\\n•Thebandwidth of the system is the frequency at which the magnitude\\ndrops to1√\\n2times the DC gain, and is denoted by ωBW. For the sec-\\nond order system considered above, the plot shows that the bandwidth is\\napproximately equal to ωn.\\n•Theresonant peak is the diﬀerence between maximum value of the fre-\\nquency response magnitude and the DC gain, and is denoted by Mr.\\n•Theresonant frequency is the frequency at which the resonant peak\\noccurs, and is denoted by ωr.\\nThe concepts of bandwidth and DC gain will play an important role in this\\ncourse, and you should be comfortable manipulating and deriving these quan-\\ntities. While we identiﬁed these metrics using the magnitude plot of a second\\norder system, these quantities can be used to discuss the frequency response\\nof any transfer function. For simple ﬁrst order systems, we can calculate these\\nquantities explicitly, as shown in the following example.\\nExample. Find the bandwidth and DC gain of the system with transfer func-\\ntionH(s) =b\\ns+a.\\nSolution. The DC gain is the magnitude of the transfer function when s=jω,\\nwithω= 0. In this case, the DC gain is\\n|H(0)|=b\\na.\\nThe bandwidth is the frequency ωBWat which the magnitude |H(jωBW)|is\\nequal to1√\\n2of the DC gain. In this case, we have\\n1√\\n2b\\na=|H(jωBW)|=b\\n|jωBW+a|=b√\\na2+ω2\\nBW.\\nCancelling out the band squaring both sides, we obtain\\n2a2=a2+ω2\\nBW,\\nwhich means that ωBW=a.\\nNext, we will develop some ways to systematically draw the magnitude and\\nphase for general transfer functions.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 32}, page_content='Chapter 5\\nBode Plots\\nA Bode plot is a plot of the magnitude and phase of a linear system, where\\nthe magnitude is plotted on a logarithmic scale, and the phase is plotted on\\na linear scale. Speciﬁcally, consider the linear system with transfer function\\nH(s) =N(s)\\nD(s). For the moment, assume that all poles and zeros of the transfer\\nfunction are real (to avoid cumbersome notation), and write\\nH(s) =K(s+z1)(s+z2)···(s+zm)\\n(s+p1)(s+p2)···(s+pn).\\nWhen working with Bode plots, we will ﬁnd it more convenient to write this\\nsystem as:\\nH(s) =Ko(s\\nz1+ 1)(s\\nz2+ 1)···(s\\nzm+ 1)\\n(s\\np1+ 1)(s\\np2+ 1)···(s\\npn+ 1),\\nwhereKo=Kz1z2...zm\\np1p2...pn. This is called the Bode form , and the reason for doing\\nthis is that the DC gain of the above transfer function can now immediately be\\nobtained as Ko, which will be useful when drawing Bode plots. We will handle\\nmore general transfer functions after the following discussion.\\nThe magnitude of H(jω) is given by\\n|H(jω)|=|Ko||jω\\nz1+ 1||jω\\nz2+ 1|···|jω\\nzm+ 1|\\n|jω\\np1+ 1||jω\\np2+ 1|···|jω\\npn+ 1|.\\nNow if we take the logarithm of both sides (any base is acceptable, but base 10\\nis conventional), we get\\nlog|H(jω)|= log|Ko|+m∑\\ni=1log|jω\\nzi+ 1|−n∑\\ni=1log|jω\\npi+ 1|.\\nIn other words, when viewed on a logarithmic scale, the magnitudes of each\\nof the individual terms in the transfer function addtogether to produce the\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 33}, page_content='26 Bode Plots\\nmagnitude of the overall transfer function. This is quite useful, and the reason\\nfor introducing the logarithm. In keeping with convention, we will multiply both\\nsides of the above equation by 20, and work with the units in decibels ; this only\\nscales the magnitudes, but does not change the additivity due to the logarithm.\\nNote that the phase of H(jω) already satisﬁes the additivity property:\\n∠H(jω) =∠Ko+m∑\\ni=1∠(jω\\nzi+ 1)−n∑\\ni=1∠(jω\\npi+ 1),\\nand thus it suﬃces to consider the phase on a linear scale.\\nNote that we can always draw Bode plots for any transfer function by simply\\nevaluating the magnitude and phase for each value of ωand then plotting these\\nvalues. However, will want to come up with some quick rules to sketch these\\nplots.\\n5.1 Rules for Drawing Bode Plots\\nNow that we understand the general motivation behind drawing the log-magnitude\\nand phase of Bode plots, we will study how to draw the Bode plots of general\\ntransfer functions (potentially involving complex conjugate terms as well). We\\nwill assume for now that the transfer function H(s) has all zeros and poles in the\\nCLHP (we will discuss the more general case later). Recall from Chapter 2 that\\na polynomial with real coeﬃcients can always be decomposed into a product of a\\nconstant, ﬁrst order terms (corresponding to real roots) and second order terms\\n(corresponding to complex conjugate roots). Thus, we can assume (without loss\\nof generality) that H(s) is composed of four diﬀerent types of factors:\\n•Ko(a constant)\\n•sq(corresponding to zeros at the origin if qis a positive integer, or poles\\nat the origin if qis a negative integer)\\n•(s\\np+ 1)−1and (s\\nz+ 1) (corresponding to real poles and zeros)\\n•(\\n(s\\nωn)2+ 2ζ(s\\nωn) + 1)±1\\n(corresponding to complex conjugate zeros if the\\nexponent is 1, and complex conjugate poles if the exponent is −1).\\nExample. ConsiderH(s) = 3(s+2)(s2+2s+4)\\ns3(s+1)(s2+3s+4). Write this in Bode form, and\\nwrite the logarithm of the magnitude of H(jω) in terms of the logarithm of the\\nmagnitudes of each of the factors. Also write the phase of H(jω) in terms of\\nthe phases of each of the factors.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 34}, page_content='5.1 Rules for Drawing Bode Plots 27\\nSince the log-magnitude and phase are obtained by simply adding together the\\nlog-magnitudes and phases of the individual factors, we can draw the Bode plot\\nfor the overall system by drawing the Bode plots for each of the individual\\nfactors, and then adding the plots together.\\n5.1.1 Bode Plot for Ko\\nThe Bode plot of constant terms is very easy to draw. The log-magnitude is\\nsimply 20 log|Ko|, and the phase is\\n∠Ko={\\n0 ifKo>0\\nπifKo<0.\\nBoth the magnitude and phase are just horizontal lines.\\nExample. Draw the Bode plot of1\\n10.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 35}, page_content='28 Bode Plots\\nExample. Draw the Bode plot of −10.\\nSolution.\\n5.1.2 Bode Plot for sq\\nThe log-magnitude of the factor sqfors=jωis given by\\n20 log|(jω)q|= 20qlog|jω|= 20qlog|ω|.\\nOn a log scale, this simply a straight line with slope 20 q, going through the\\npoint 0 when ω= 1.\\nThe phase of sqats=jωis\\n∠(jω)q=q∠jω=qπ\\n2,\\nwhich is just a horizontal line at qπ\\n2.\\nExample. Draw the Bode plot of s2.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 36}, page_content='5.1 Rules for Drawing Bode Plots 29\\nExample. Draw the Bode plot of1\\ns3.\\nSolution.\\n5.1.3 Bode Plot for (s\\np+ 1)−1and (s\\nz+ 1)\\nA system zero at s=−zwill correspond to the factor (s\\nz+ 1) in the Bode form\\nof the transfer function, and a system pole at s=−pwill correspond to the\\nfactor (s\\np+ 1)−1, where we are assuming that z >0 andp>0. Let’s deal with\\nthe zero ﬁrst. The log-magnitude of the factor (s\\nz+ 1) ats=jωis given by\\n20 log|jω\\nz+ 1|= 20 log√\\n1 + (ω\\nz)2.\\nIfω≪z, we have 20 log|jω\\nz+ 1|≈0, and thus for values of ωless thanz, the\\nmagnitude is simply a horizontal line at 0. If ω≫z, we have 20 log|jω\\nz+ 1|≈\\n20 log(1\\nz) + 20 log(ω). On a log scale, this is a line of slope 20, going through\\nthe point 0 when ω=z. These two rules together produce a magnitude plot\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 37}, page_content='30 Bode Plots\\nthat looks like this:\\nThe pointω=zis called the breakpoint . These straight lines were derived\\nbased on values of ωthat were much smaller or much larger than the breakpoint,\\nand thus they are called asymptotes . Note that they are only approximations\\nto the shape of the actual magnitude plot – for example, the actual value of\\n20 log(jω\\nz+ 1) atω=zis equal to 3 dB. However, the approximations will\\nsuﬃce for us to obtain some general intuition about Bode plots.\\nThe phase of ( jω\\nz+ 1) is given by\\n∠(jω\\nz+ 1) = tan−1ω\\nz.\\nForω≪z, this is approximately equal to 0, and for ω≫z, this is approximately\\nequal toπ\\n2. At the breakpoint ω=z, the phase is tan−1(1) =π\\n4. The phase\\ncurve transitions smoothly from 0 toπ\\n2throughπ\\n4; for convenience, we will draw\\nthe transition as a line starting at ω= 0.1zand ending at ω= 10z(i.e., one\\ndecade before and one decade after z):\\nThe magnitude and phase plots for a factor corresponding to a pole follow the\\nsame rules as the plot for the zero, except that everything is negated. Speciﬁ-\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 38}, page_content='5.1 Rules for Drawing Bode Plots 31\\ncally, for a factor of the form ( jω\\np+ 1)−1, we have\\n20 log|(jω\\np+ 1)−1|= 20 log(√\\n1 + (ω\\nz)2)−1=−20 log(√\\n1 + (ω\\np)2),\\n∠(jω\\np+ 1)−1=−tan−1ω\\np.\\nThe Bode plot for the factor ( jω\\np+ 1)−1looks like this:\\nExample. Draw the Bode plot for H(s) = 10s+10\\n(s+1)(s+100).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 39}, page_content='32 Bode Plots\\n5.1.4 Bode Plot for(\\n(s\\nωn)2+ 2ζ(s\\nωn) + 1)±1\\nWe have already seen what the magnitude and phase plots look like for a second\\norder system of this form. To derive general rules for drawing this, note that\\nthe magnitude of this function at s=jωis given by\\n20 log⏐⏐⏐⏐(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1⏐⏐⏐⏐= 20 log√\\n(1−(ω\\nωn)2)2+ 4ζ2(ω\\nωn)2.\\nForω≪ωn, we haveω\\nωn≈0, and so 20 log⏐⏐⏐(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1⏐⏐⏐≈0. For\\nω≫ωn, we have\\n√\\n(1−(ω\\nωn)2)2+ 4ζ2(ω\\nωn)2≈√(ω\\nωn)4\\n=(ω\\nωn)2\\n,\\nand so 20 log⏐⏐⏐(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1⏐⏐⏐≈40 logω−40 logωn. This is a line of slope\\n40 passing through the point 0 when ω=ωn. The general magnitude curve for\\n20 log⏐⏐⏐(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1⏐⏐⏐thus looks like:\\nThe phase of(\\n(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1)\\nis given by\\n∠(\\n(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1)\\n= tan−1\\uf8eb\\n\\uf8ec\\uf8ed2ζω\\nωn\\n1−(\\nω\\nωn)2\\uf8f6\\n\\uf8f7\\uf8f8.\\nForω≪ωn, the argument of the arctan function is almost 0, and so the phase\\ncurve starts at 0 for small ω. Forω=ωn, the argument is ∞, and so the phase\\ncurve passes throughπ\\n2whenω=ωn. Forω≫ωn, the argument of the arctan\\nfunction approaches 0 from the negative side, and so the phase curve approaches\\nπfor large values of ω. Just as in the ﬁrst order case, we will take the phase\\ncurve transitions to occur one decade before and after ωn. This produces a\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 40}, page_content='5.1 Rules for Drawing Bode Plots 33\\nphase curve of the form:\\nThe Bode plot for the factor(\\n(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1)−1\\nlooks just like the Bode\\nplot for the factor(\\n(jω\\nωn)2+ 2ζ(ω\\nωn)j+ 1)\\n, except that everything is ﬂipped:\\nExample. Draw the Bode Plot of H(s) =(s+1)(s2+3s+100)\\ns2(s+10)(s+100)\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 41}, page_content='34 Bode Plots\\nSolution.\\n5.1.5 Nonminimum Phase Systems\\nSo far we have been looking at the case where all zeros and poles are in the\\nCLHP. Bode plots can also be drawn for systems that have zeros or poles in\\nthe RHP – however, note that for systems that have RHP poles, the steady\\nstate response to a sinusoidal input will not be a sinusoid (there won’t even be a\\nsteady state response, as the output will blow up). This does not change the fact\\nthat the transfer function will have a magnitude and phase at every frequency\\n(since the transfer function is simply a complex number at every frequency ω).\\nTransfer functions with zeros in the right half plane are called nonminimum\\nphase systems , and those with all zeros and poles in the CLHP are called\\nminimum phase systems .\\nTo gain intuition about how the Bode plot of a nonminimum phase system\\ncompares to that of a minimum phase system, let us see how the Bode plots of\\nthe termsH1(s) =s+ 1 andH2(s) =s−1 compare. First, note that\\n|H1(jω)|=|jω+ 1|=√\\n1 +ω2=|H2(jω)|,\\nand thus the magnitude plots of the two terms are identical. To compare the\\nphase contribution, it is useful to examine the complex number representation\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 42}, page_content='5.1 Rules for Drawing Bode Plots 35\\nofH1(jω) andH2(jω):\\nFrom this, we see that ∠H2(jω) =∠(jω−1) =π−∠H1(jω). Thus, the phase\\nplots of the two terms look like this:\\nAn alternative method to draw the phase plot of H2(s) =s−1 is to ﬁrst convert\\nit to Bode form to obtain H2(s) =−1(−s+ 1), where we now have a gain of −1\\nin front. This gain contributes nothing to the log-magnitude, but it contributes\\na phase ofπ. The phase of−s+1 is the negative of the phase of s+1 (since they\\nare complex conjugates), and once again, we obtain that the phase of H2(jω)\\nisπ−∠H1(jω).\\nExample. Draw the Bode plots for the systems\\nH1(s) = 10s+ 1\\ns+ 10, H 2(s) = 10s−1\\ns+ 10.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 43}, page_content='36 Bode Plots\\nAs we can see from the above example, the magnitudes of the two transfer\\nfunctions do not depend on whether the zero is in RHP or the LHP. However,\\nthe phase plots are quite diﬀerent. Based on the above analysis, we see that the\\nphase contribution of a zero in the right half plane is always at least as large (in\\nabsolute terms) as the phase contribution of a zero in the left half plane – this\\nis the reason for calling systems with such zeros (or poles) nonminimum phase.\\nNote that for minimum phase systems, the magnitude plot uniquely determines\\nthe transfer function, but for nonminimum phase systems, we need both the\\nmagnitude plot and the phase plot in order to determine the transfer function.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 44}, page_content='Chapter 6\\nModeling and Block\\nDiagram Manipulation\\nWith the mathematical foundations from the previous chapters in hand, we are\\nnow ready to move on to the modeling of control systems.\\n6.1 Mathematical Models of Physical Systems\\nThe ﬁrst task of control system design is to obtain an appropriate mathematical\\nmodel of the plant. In many applications, this can be diﬃcult to do, as ex-\\nperimental data is often noisy, and real-world systems are often quite complex.\\nThus, we must frequently come up with an approximate model, maintaining a\\ntradeoﬀ between complexity and how accurately it captures the actual physical\\nplant. In general, we try to follow Einstein’s rule: “Make things as simple as\\npossible, but no simpler.”\\nIf the system is known (or approximated) to be linear, then one way to identify\\na model is to apply sinusoidal inputs of appropriate frequencies to the system,\\nand then try and ﬁt an appropriate transfer function to the resulting Bode plot.\\nAn alternative (and complementary) method is to use physical laws to obtain\\nthe model. We will now study some examples of this approach.\\n6.1.1 Mechanical Systems\\nThe key equation governing the model of many mechanical systems is Newton’s\\nLaw:F=ma. In this equation, Frepresents the vector sum of all the forces\\nacting on a body, mrepresents the mass of the body, and arepresents the\\nacceleration of the body. The forces acting on the body can be generated by an\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 45}, page_content='38 Modeling and Block Diagram Manipulation\\noutside entity (as an input to the system), or by springs and dampers attached\\nto the body.\\nExample: Mass-Spring-Damper System.\\n6.1.2 Electrical Systems\\nStandard components in electrical systems include resistors ,capacitors and\\ninductors , connected together in various ways. The quantities of interest in\\nelectrical systems are voltages andcurrents .\\nFigure 6.1: (a) Components of Electrical Systems. (b) An Electrical System.\\nThe main modeling technique for electrical systems is to use Kirchoﬀ’s Laws .\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 46}, page_content='6.1 Mathematical Models of Physical Systems 39\\n•Kirchoﬀ’s Voltage Law (KVL): The algebraic sum of the voltages\\naround a closed loop is zero.\\n•Kirchoﬀ’s Current Law (KCL): The algebraic sum of the currents\\ncoming into a node is zero.\\nWe will see an example of an electric circuit model in the context of a DC motor\\nbelow.\\n6.1.3 Rotational Systems\\nWhen the system involves rotation about a point, the system dynamics are\\ngoverned by a modiﬁed form of Newton’s Law: τ=J¨θ. Here,τis the sum\\nof all external torques about the center of mass, Jis the moment of inertia of\\nthe body, and θis the angular position of the body (so that ¨θis the angular\\nacceleration).\\nExample: A DC motor consists of an electrical component and a rotational\\ncomponent. The input voltage to the electrical component induces a current,\\nwhich then provides a torque to the motor shaft via a magnetic ﬁeld. This\\ntorque causes the shaft to rotate. In turn, this torque also induces a voltage\\ndrop (called the back emf ) in the electrical circuit. Derive the overall system\\nequations. and ﬁnd the transfer function from the input voltage to the angular\\nvelocity (ω=˙θ) of the DC motor.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 47}, page_content='40 Modeling and Block Diagram Manipulation\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 48}, page_content='6.2 Block Diagram Manipulation 41\\nAll of the above examples considered above yielded models that involved linear\\ndiﬀerential equations of the form\\ny(n)+an−1y(n−1)+···+a1˙y+a0y=bmu(m)+bm−1u(m−1)+···+b1˙u+b0u .\\nAs we saw in Section 4.2, the transfer function of such systems is given by\\nH(s) =Y(s)\\nU(s)=bmsm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0.\\nIn practice, many systems are actually nonlinear , and there is a whole set of\\ntools devoted to controlling such systems. One technique is to linearize the\\nsystem around an operating point, where the nonlinearities are approximated\\nby linear functions. In the rest of the course, we restrict our attention to lin-\\near systems, and assume that these linearization techniques have been applied\\nto any nonlinearities in the system. We will now study how to manipulate\\ninterconnections of linear systems.\\n6.2 Block Diagram Manipulation\\nControl systems typically involve several smaller systems (or components) that\\nare interconnected together in various ways – the output of one system will be\\nthe input to other systems. For example, remember from the ﬁrst lecture that\\nthe basic block diagram of a feedback control system looks like this:\\nWe will frequently want to manipulate block diagram representations of systems\\nin order to ﬁnd the overall transfer function of the system in terms of the transfer\\nfunctions of the individual components or subsystems. There are three types of\\ninterconnections that we will be studying.\\nSeries Connection. In this case, the output of one system feeds directly into\\nthe input of another system.\\nFigure 6.2: Two Systems Connected in Series.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 49}, page_content='42 Modeling and Block Diagram Manipulation\\nThe overall transfer function from U(s) toY(s) can be obtained as follows:\\nY(s) =H2(s)Y1(s)\\nY1(s) =H1(s)U(s)}\\n⇒Y(s) =H2(s)H1(s)U(s),\\nand thus the overall transfer function is H(s) =Y(s)\\nU(s)=H2(s)H1(s).\\nParallel Connection. In this case, two (or more systems) obtain the same\\ninputU(s), and their outputs are summed together to produce the output of\\nthe overall system.\\nFigure 6.3: Two Systems Connected in Parallel.\\nThe overall transfer function from U(s) toY(s) can be obtained as follows:\\nY1(s) =H1(s)U(s)\\nY2(s) =H2(s)U(s)\\nY(s) =Y1(s) +Y2(s)\\uf8fc\\n\\uf8fd\\n\\uf8fe⇒Y(s) = (H1(s) +H2(s))U(s),\\nand thus the overall transfer function is H(s) =Y(s)\\nU(s)=H1(s) +H2(s).\\nFeedback Connection. In this case, the output of one system feeds into the\\ninput of a second system, and the output of this second system feeds back into\\nthe input of the ﬁrst system (perhaps in conjunction with another signal).\\nThe overall transfer function from R(s) toY(s) can be obtained by noting that\\nY(s) =H1(s)E(s)\\nY2(s) =H2(s)Y(s)\\nE(s) =R(s)−Y2(s),\\nwhich yields\\nY(s) =H1(s)(R(s)−Y2(s)) =H1(s)R(s)−H1(s)H2(s)Y(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 50}, page_content='6.2 Block Diagram Manipulation 43\\nFigure 6.4: Feedback Connection of Two Systems.\\nThus the overall transfer function is\\nH(s) =Y(s)\\nR(s)=H1(s)\\n1 +H1(s)H2(s).\\nThis is an important transfer function; the numerator is called the “forward\\ngain”, and the denominator is described as “1 + the loop gain”.\\nNote that in the above feedback conﬁguration, the output of the system H2(s)\\nissubtracted from the reference signal R(s) to produce the error E(s). This con-\\nﬁguration is thus called a negative feedback conﬁguration. If the signal Y2(s)\\nis instead added to the reference signal, the conﬁguration is called a positive\\nfeedback conﬁguration. In this case, the transfer function would be given by\\nH(s) =Y(s)\\nR(s)=H1(s)\\n1−H1(s)H2(s).\\nNote: The basic feedback control system shown at beginning of this section is\\na special case of the negative feedback conﬁguration shown above, with H1(s) =\\nP(s)C(s), andH2(s) = 1. The basic feedback control system is thus said to be\\nin “unity feedback” conﬁguration.\\nBased on the above conﬁgurations, we can derive the following rules to modify\\nblock diagrams.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 51}, page_content='44 Modeling and Block Diagram Manipulation\\nExample. Compute the transfer function from U(s) toY(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 52}, page_content='6.2 Block Diagram Manipulation 45\\n6.2.1 Systems with Multiple Inputs and Outputs\\nWe will frequently encounter interconnected systems that have multiple inputs\\n(e.g., control signals, disturbances, etc.) and outputs (e.g., diﬀerent sensor\\nmeasurements, etc.). For linear systems, we can simply use the Principle of\\nSuperposition to ﬁnd the transfer function from the inputs to the outputs. More\\nspeciﬁcally, if we have a set of inputs U1(s),U2(s),...,Um(s) and a set of outputs\\nY1(s),Y2(s),...,Yp(s), then we ﬁnd the transfer function Hij(s) from input\\nUi(s) to output Yj(s) by simply removing all of the other inputs and outputs\\nfrom the system and calculating the resulting transfer function as above. By\\nlinearity, each output can then be written as\\nYi(s) =H1i(s)U1(s) +H2i(s)U2(s) +···+Hmi(s)Um(s), i∈{1,2,...,p}.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 53}, page_content='46 Modeling and Block Diagram Manipulation\\nExample. Write the output Y(s) of the following system in terms of the inputs\\nR(s) andD(s).\\nC(s)P(s)R(s)D(s)\\n++Y(s)\\n−\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 54}, page_content='Chapter 7\\nStep Responses of Linear\\nSystems\\nConsider a system with transfer function of the form\\nH(s) =bmsm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0.\\nThe degree ( n) of the denominator polynomial is called the order of the system.\\nAs we have already seen, systems of order one and two arise frequently in prac-\\ntice; even when the order of a system is higher than two, one can sometimes\\napproximate the system by a ﬁrst or second order system in order to obtain\\nintuition about the system’s behavior. It is therefore important for us to study\\nthe responses of ﬁrst and second order systems to various types of inputs (and\\nin particular, to step inputs). Recall that for step inputs u(t) =1(t), we have\\nU(s) =1\\ns.\\nNote that if all poles of H(s) are in the OLHP, the Final Value Theorem states\\nthat the steady-state value of the step response is given by\\nlim\\ns→0sY(s) = lim\\ns→0sH(s)U(s) = lim\\ns→0sH(s)1\\ns= lim\\ns→0H(s) =H(0).\\nThe quantity H(0) is called the DC gain of the system. This is true regardless\\nof the order of the system.\\n7.1 Step Response of First Order Systems\\nConsider a ﬁrst order system with transfer function\\nH(s) =b0\\ns+a0, a 0̸= 0.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 55}, page_content='48 Step Responses of Linear Systems\\nThis system has a single pole at s=−a0. The step response of this system is\\nobtained by calculating\\nY(s) =H(s)U(s) =b0\\ns+a01\\ns\\n=b0\\na0(1\\ns−1\\ns+a0)\\n,\\nwhich produces\\ny(t) =b0\\na01(t)−b0\\na0e−a0t, t≥0. (7.1)\\nConsider two cases:\\n•Ifa0>0, then the pole of the transfer function is in the OLHP, and\\ne−a0t→0 ast→∞ . The step response thus reaches a steady-state value\\nofb0\\na0(which is the DC gain of the system). The response is said to be\\nstable .\\n•Ifa0<0, the pole of the transfer function is in the ORHP, and e−a0t→∞\\nast→∞ . The step response therefore goes to ∞, and there is no steady\\nstate value. The response is said to be unstable .\\nFigure 7.1: Step Response of First Order System. (a) Pole in OLHP. (b) Pole\\nin ORHP.\\nWe will now study two measures of performance that can be used to evaluate\\nthe step-response.\\n7.1.1 Rise time\\nThe rise timetrof a step response is deﬁned as the amount of time required for\\nthe response to go from 10% of its ﬁnal value to 90% of its ﬁnal value.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 56}, page_content='7.1 Step Response of First Order Systems 49\\nThe rise time of a ﬁrst order system with transfer function H(s) =b0\\ns+a0is\\ntr=ln 9\\na0\\n(you should be able to easily prove this). Note that the larger a0is, the smaller\\nthe rise time becomes. This can also be seen from the actual step-response\\n(7.1): a larger value of a0means that the term e−a0tdies out faster, leading the\\nresponse to get to its steady state quicker.\\n7.1.2 Settling time\\nAnother measure of performance is the settling time of the response, deﬁned as\\nthe time required for the response to get to within a certain percentage of its\\nﬁnal value and stay there. We will take this percentage to be 2%, but sometimes\\nthe settling time is deﬁned in terms of 1% or 5% as well. By equating (7.1) to\\n0.98b0\\na0and solving for t, we ﬁnd that the 2% settling time for the ﬁrst order\\nstep response is\\nts≈3.91\\na0.\\nNote: The quantity τ=1\\na0is called the time-constant of the system, and (7.1)\\nis commonly written as\\ny(t) =b0\\na01(t)−b0\\na0e−t\\nτ.\\nA larger time-constant means that the system takes longer to settle to its steady\\nstate. To ﬁnd the time-constant in practice, note that at t=τwe have\\ny(τ) =b0\\na0(1−e−1)≈0.63b0\\na0.\\nSince the steady state value of y(t) isb0\\na0(the DC gain of the system), we see that\\nthe time-constant is the point in time where the output of the system reaches\\n63% of its ﬁnal value.\\nOne can also readily verify that the bandwidth of the system H(s) occurs at\\ns=a0(i.e.,|H(ja0)|=1√\\n2|H(0)|). Thus, we get the following rule of thumb.\\nFast response⇔Smallτ⇔Largea0⇔Large bandwidth\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 57}, page_content='50 Step Responses of Linear Systems\\n7.2 Step Response of Second Order Systems\\nConsider a second order system of the form\\nH(s) =b1s+b0\\ns2+a1s+a0.\\nIn order to obtain intuition about these systems, we will be focusing on a par-\\nticular form of second order system:\\nH(s) =ω2\\nn\\ns2+ 2ζωns+ω2n, ωn>0.\\nThe poles of this transfer function are obtained from the quadratic formula as\\ns=−ζωn±ωn√\\nζ2−1. The location of these poles in the complex plane will\\nvary based on the value of ζ. We analyze three diﬀerent cases:\\n•0≤ζ <1: The system has two complex poles in the CLHP (they will be\\nin the OLHP if ζ >0). The system is said to be underdamped .\\n•ζ= 1: The system has two repeated poles at s=−ωn. The system is said\\nto be critically damped .\\n•ζ >1: The system has two poles on the negative real axis. The system is\\nsaid to be overdamped .\\nFigure 7.2: Location of Poles in Complex Plane for Diﬀerent Ranges of ζ. (a)\\n0≤ζ <1. (b)ζ= 1. (c)ζ >1.\\n7.2.1 Underdamped and Critically Damped Systems ( 0≤\\nζ≤1)\\nThe poles of the transfer function in this case are given by s=−ζωn±\\njωn√\\n1−ζ2. To simplify the notation, deﬁne\\nσ=ζωn, ωd=ωn√\\n1−ζ2,\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 58}, page_content='7.2 Step Response of Second Order Systems 51\\nin which case the poles are at s=−σ±jωd. The transfer function can be\\nwritten as\\nH(s) =ω2\\nn\\n(s+σ+jωd)(s+σ−jωd)=ω2\\nn\\n(s+σ)2+ω2\\nd.\\nThe Laplace Transform of the step response is given by Y(s) =H(s)1\\ns, and\\nusing a Laplace Transform table, we see that\\ny(t) = 1−e−σt(\\ncosωdt+σ\\nωdsinωdt)\\n. (7.2)\\n•Whenζ= 0, we have σ= 0 andωd=ωn, and the response becomes\\ny(t) = 1−cosωnt, which oscillates between 0 and 2 for all t.\\n•Whenζ= 1, we have σ=ωnandωd= 0, and the response becomes\\ny(t) = 1−e−ωnt(1 +ωnt); one can verify that this does not have any\\noscillations at all, and asymptotically reaches the steady state value of 1\\n(this is the DC gain H(0)).\\nThe response for intermediate values of ζfalls in between these two extremes.\\nThe behavior of y(t) for diﬀerent values of ζ(with a ﬁxed value of ωn) is shown\\nin Fig. 7.3.\\nFigure 7.3: Step response as a function of ζ, for 0≤ζ≤1.\\nAs we can see from the responses for various values of ζ, a larger value of ζ\\ncorresponds to fewer oscillations and less overshoot , and thusζis said to rep-\\nresent the amount of damping in the response (a higher value of ζcorresponds\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 59}, page_content='52 Step Responses of Linear Systems\\nto more damping). ζis called the damping ratio . Examining Fig. 7.2, we see\\nthat the angle between the imaginary axis and the vector connecting the pole\\nto the origin is given by sin−1ζ. The magnitude of the vector is given by ωn.\\nThus, asζincreases with a ﬁxed ωn, the poles move on the perimeter of a circle\\ntoward the real axis.\\nThe quantity ωnis called the undamped natural frequency , since it repre-\\nsents the location of the pole on the imaginary axis when there is no damping\\n(i.e., whenζ= 0). The quantity ωdis called the damped natural frequency ,\\nsince it represents the imaginary part of the pole when there is damping. When\\nζ= 0, we have ωd=ωn. Ifζ >0 and we increase ωn, the poles move further to\\nthe left in the OLHP. This causes the term σ=ζωnto increase, which causes\\nthe terme−σtto die out faster in the step response (equation (7.2)). Thus,\\nincreasingωnhas the eﬀect of making the oscillations die out faster (and, in\\ngeneral, making the system respond faster). Recall from the magnitude plot\\nof the second order frequency response from Section 4.3 that the bandwidth of\\nthe system is approximately equal to ωn. Thus, we obtain the following rule of\\nthumb for the underdamped system.\\nLargerωn⇔Larger bandwidth ⇔Faster response\\nWe will see this more formally in the next chapter.\\n7.2.2 Overdamped System ( ζ > 1)\\nThe poles of the transfer function in this case are given by s=−ζωn±\\nωn√\\nζ2−1, which are both on the negative real axis (as ζ→ ∞ , one pole\\napproaches s= 0, and the other pole approaches s=−∞). The transfer func-\\ntion can be written as\\nH(s) =ω2\\nn\\n(s+ζωn+ωn√\\nζ2−1)(s+ζωn−ωn√\\nζ2−1).\\nThe Laplace Transform of the step response is given by Y(s) =H(s)1\\ns, and\\nusing partial fraction expansion, we see that the step response will have the\\nform\\ny(t) = 1−k1e(−ζωn−ωn√\\nζ2−1)t−k2e(−ζωn+ωn√\\nζ2−1)t,\\nfor some constants k1andk2. This response has no oscillations; a sample\\nresponse is shown in Fig. 7.4.\\n7.2.3 Discussion\\nBased on the above analysis, we can come to the following general conclusions\\nabout how the poles of second order systems aﬀect their step responses.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 60}, page_content='7.2 Step Response of Second Order Systems 53\\nFigure 7.4: Step response of an overdamped system ( ζ >1).\\n•If the poles are complex, the step response will have oscillations and over-\\nshoot.\\n•As the poles move toward the real axis while maintaining a ﬁxed distance\\nfrom the origin, the amount of oscillation decreases (leading to less over-\\nshoot) – this corresponds to the damping ratio ζincreasing (with a ﬁxed\\nωn),\\n•Ifωnincreases, the poles move further left in the OLHP, and the oscilla-\\ntions die out faster.\\n•If all poles are on the negative real axis, there will be no oscillation and\\nno overshoot.\\nNote that if the transfer function has one or more poles in the open right half\\nplane, the step response will contain a term that goes to ∞ast→∞ , and thus\\nthere is no steady state response.\\nBased on these general rules, the step responses for various pole locations are\\nshown below:\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 61}, page_content='54 Step Responses of Linear Systems\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 62}, page_content='Chapter 8\\nPerformance of Second\\nOrder Step Responses\\nWe have seen that the step response of a second order system with transfer\\nfunction\\nH(s) =ω2\\nn\\ns2+ 2ζωns+ω2n\\nwill have diﬀerent characteristics, depending on the location of the poles (which\\nare a function of the values ζandωn). We will now introduce some measures\\nof performance for these step responses.\\n8.1 Performance Measures\\nWe will be studying the following metrics in order to evaluate the performance\\nof second order step responses.\\n•Rise time ( tr):The time taken for the response to ﬁrst get close to its\\nﬁnal value. This is typically measured as the time taken for the response\\nto go from 10% of its ﬁnal value to 90% of its ﬁnal value.\\n•Settling time ( ts):The time taken for the response to stay close to its\\nﬁnal value. We will take this to be the time after which the response stays\\nwithin 2% of its ﬁnal value. Other measures of “closeness” can also be\\nused (e.g., 1% instead of 2%, etc.).\\n•Peak value ( Mp) and overshoot OS:This is largest value of the step\\nresponse. One can also calculate the overshoot as the maximum amount\\nthat the response overshoots its ﬁnal value, divided by the ﬁnal value\\n(often expressed as a percentage).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 63}, page_content='56 Performance of Second Order Step Responses\\n•Peak time ( tp):This is the time at which the response hits its maximum\\nvalue (this is the peak of the overshoot).\\nFigure 8.1: Step response of second order system, with tr,Mp,tpandtsshown.\\n8.1.1 Rise time ( tr)\\nAn explicit formula for the rise time is somewhat hard to calculate. However,\\nwe notice that rise time increases with ζand decreases with ωn. The best linear\\nﬁt to the curve gives us the approximation\\ntr≈2.16ζ+ 0.6\\nωn,\\nwhich is reasonably accurate for 0 .3< ζ < 0.8. A cruder approximation is\\nobtained by ﬁnding a best ﬁt curve with ζ= 0.5, yielding\\ntr≈1.8\\nωn.\\nKeep in mind that these are only approximations, and iteration may be required\\nif design speciﬁcations are not met.\\n8.1.2 Peak value ( Mp), Peak time ( tp) and Overshoot OS\\nRecall that the step response will have overshoot only if the poles are complex\\n– this corresponds to the case 0 ≤ζ <1, and the corresponding system is called\\nunderdamped. The overshoot is deﬁned as\\nOS=Mp−y(∞)\\ny(∞),\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 64}, page_content='8.1 Performance Measures 57\\nwhereMpis the peak value of the step response, and y(∞) is the ﬁnal (steady\\nstate) value of the step response. Note that if we want to express the overshoot\\nas a percentage , we simply multiply OSby 100, and denote this by % OS.\\nWe can explicitly calculate the peak value of the step response (and the corre-\\nsponding time) as follows. First, note that at the peak value, the derivative of\\nthe step response is zero. Recalling that the step response is given by\\ny(t) = 1−e−σt(\\ncosωdt+σ\\nωdsinωdt)\\n,\\ncalculatedy\\ndtand set it equal to zero to obtain\\n0 =dy\\ndt=σe−σt(cosωdt+σ\\nωdsinωdt)−e−σt(−ωdsinωdt+σcosωdt)\\n=σ2\\nωde−σtsinωdt+ωde−σtsinωdt\\n= (σ2\\nωd+ωd)e−σtsinωdt .\\nFrom this, we obtain sin ωdt= 0, which occurs for t= 0,π\\nωd,2π\\nωd,···. The ﬁrst\\npeak therefore occurs at the peak time\\ntp=π\\nωd.\\nSubstituting this into the expression for y(t), we obtain the value of the step\\nresponse at the peak to be\\nMp=y(π\\nωd) = 1−e−σπ\\nωd(cosπ+σ\\nωdsinπ)\\n= 1 +e−σπ\\nωd.\\nSubstituting y(∞) = 1,σ=ζωn,ωd=ωn√\\n1−ζ2, and the above expression\\nforMpinto the deﬁnition of overshoot, we obtain\\nOS=1 +e−σπ\\nωd−1\\n1=e−ζωnπ\\nωn√\\n1−ζ2\\n=e−πζ√\\n1−ζ2.\\n8.1.3 Settling Time ( ts)\\nThe settling time tsis the time taken for the step response to stay within a\\ncertain percentage of its ﬁnal value. This percentage will vary depending on the\\napplication. In this course, we will take 2% as a good measure. To calculate ts,\\nwe note once again that the step response is\\ny(t) = 1−e−σt(\\ncosωdt+σ\\nωdsinωdt)\\n.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 65}, page_content='58 Performance of Second Order Step Responses\\nWe can obtain a rough approximation of tsby calculating the time at which the\\nexponential term e−σtbecomes equal to 0 .02 (since the cosine and sine terms\\noscillate forever between two ﬁxed values):\\ne−σts≈0.02⇒−σts≈ln 0.02⇒ts≈4\\nσ=4\\nζωn.\\nSummary. The expressions for the various performance metrics are:\\ntr≈2.16ζ+ 0.6\\nωnortr≈1.8\\nωn\\nMp= 1 +e−πζ√\\n1−ζ2(for systems with DC gain of 1)\\nOS=e−πζ√\\n1−ζ2\\ntp=π\\nωn√\\n1−ζ2=π\\nωd\\nts≈4\\nζωn.\\nNote that the expressions for trandtsare only approximations; more detailed\\nexpressions for these quantities can be obtained by performing a more careful\\nanalysis. For our purposes, the above relationships will be suﬃcient to obtain\\nintuition about the performance of second order systems. In particular, we note\\nthe following trends:\\n•Asωn(bandwidth) increases (with ζﬁxed),trde-\\ncreases,OSstays the same, tsdecreases and tpde-\\ncreases.\\n•Asζincreases (with ωnﬁxed),trstays approximately\\nconstant,OSdecreases,tsdecreases and tpincreases.\\nWe would typically like a small OS, smalltrand smallts.\\n8.2 Choosing Pole Locations to Meet Perfor-\\nmance Speciﬁcations\\nAs we will see later in the course, we can design a controller for a given system so\\nthat the overall closed loop transfer function has poles at any desired locations\\nin the complex plane. We will need to choose these pole locations so that the\\nstep response of the system achieves certain performance speciﬁcations. For\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 66}, page_content='8.2 Choosing Pole Locations to Meet Performance Speciﬁcations 59\\nexample, suppose that we want the step response to have overshoot less than\\nsome value ¯OS, rise time less than some value ¯tr, settling time less than some\\nvalue ¯ts, and peak time less than some ¯tp. From the expressions given at the end\\nof the previous section, these constraints on the step response can be translated\\ninto constraints on ζandωn:\\ne−πζ√\\n1−ζ2≤¯OS⇒Find upper bound for ζfrom this.\\n1.8\\nωn≤¯tr⇒ωn≥1.8\\n¯tr\\n4\\nσ≤¯ts⇒σ≥4\\n¯ts\\nπ\\nωd≤¯tp⇒ωd≥π\\n¯tp.\\nNoting that σis the real part of the poles of the transfer function, ωnis the\\ndistance of the complex poles from the origin, ωdis imaginary part of the poles,\\nand sin−1ζis the angle between the imaginary axis and the vector joining the\\norigin to the pole, we can formulate appropriate regions in the complex plane\\nfor the pole locations in order to satisfy the given speciﬁcations.\\nFigure 8.2: Pole Locations in the Complex Plane. (a) Overshoot. (b) Rise time.\\n(c) Settling time. (d) Peak time. (e) Combined speciﬁcations.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 67}, page_content='60 Performance of Second Order Step Responses\\nExample. We would like our second order system to have a step response with\\novershootOS≤0.1 and settling time ts≤2. What is the region in the complex\\nplane where the poles can be located?\\nSolution.\\n8.3 Eﬀects of Poles and Zeros on the Step Re-\\nsponse\\nSo far, we have been studying second order systems with transfer functions of\\nthe form\\nH(s) =ω2\\nn\\ns2+ 2ζωns+ω2n.\\nThis transfer function produced a step response y(t), with Laplace Transform\\nY(s) =H(s)1\\ns.\\nNote: All of the analysis so far also holds if we consider the transfer function:\\nH(s) =Kω2\\nn\\ns2+ 2ζωns+ω2n,\\nfor some constant K. In this case, the step response is simply scaled by K,\\nbut the time characteristics (such as rise time, settling time, peak time and\\novershoot) of the response are not aﬀected.\\nWe will now consider what happens when we add zeros or additional poles to\\nthe system.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 68}, page_content='8.3 Eﬀects of Poles and Zeros on the Step Response 61\\n8.3.1 Eﬀect of a Zero on the Step Response\\nSuppose that we modify the second order transfer function given above by\\nadding a zero at s=−z, for somez. The modiﬁed transfer function is given by\\nHz(s) =(1\\nzs+ 1)ω2\\nn\\ns2+ 2ζωns+ω2n.\\nNote that the reason for writing the zero term as1\\nzs+ 1 instead of s+zis to\\nmaintain a DC gain of 1 for the transfer function (just so that we can compare\\nit to the original transfer function). We can split the above transfer function\\ninto the sum of two terms:\\nHz(s) =ω2\\nn\\ns2+ 2ζωns+ω2n+1\\nzsω2\\nn\\ns2+ 2ζωns+ω2n=H(s) +1\\nzsH(s),\\nwhereH(s) is the transfer function of the original system (without the zero).\\nDenote the Laplace Transform of the step response for this system by Yz(s) =\\nHz(s)1\\ns. Using the above decomposition of Hz(s), we obtain\\nYz(s) =(\\nH(s) +1\\nzsH(s))1\\ns=H(s)1\\ns+1\\nzsH(s)1\\ns=Y(s) +1\\nzsY(s).\\nNoting that the inverse Laplace Transform of sY(s) is ˙y, we obtain\\nyz(t) =y(t) +1\\nz˙y(t).\\nThus the step response of the second order system with a zero at s=−zis\\ngiven by the step response of the original system plus a scaled version of the\\nderivative of the step response of the original system. A sample plot for z >0\\n(i.e., corresponding to the zero being in the OLHP) is shown in Fig. 8.3.\\nFigure 8.3: Step response of second order system with transfer function Hz(s) =\\n(1\\nzs+1)ω2\\nn\\ns2+2ζωns+ω2n,z>0.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 69}, page_content='62 Performance of Second Order Step Responses\\nNote that as zincreases (i.e., as the zero moves further into the left half plane),\\nthe term1\\nzbecomes smaller, and thus the contribution of the term ˙ y(t) decreases\\n(i.e., the step response of this system starts to resemble the step response of the\\noriginal system). From the above ﬁgure, the eﬀect of a LHP zero is to increase\\nthe overshoot, decrease the peak time, and decrease the rise time; the settling\\ntime is not aﬀected too much. In other words, a LHP zero makes the step\\nresponse faster . One can also see this by thinking about the eﬀect of the zero\\non the bandwidth of the system. Since the presence of the term (1\\nzs+ 1) in\\nthe numerator of the transfer function will only increase the magnitude of the\\nBode plot at frequencies above ω=z, we see that adding a zero will generally\\nincrease the bandwidth of the system. This ﬁts with our rule of thumb that a\\nlarger bandwidth corresponds to a faster response.\\nNow consider what happens if zis negative (which corresponds to the zero being\\nin the ORHP). In this case, the derivative ˙ y(t) is actually subtracted from y(t)\\nto produce yz(t). A sample plot is shown in Fig. 8.4. Note that the response\\ncan actually go in the opposite direction before rising to its steady state value.\\nThis phenomenon is called undershoot .\\nFigure 8.4: Step response of second order system with transfer function Hz(s) =\\n(1\\nzs+1)ω2\\nn\\ns2+2ζωns+ω2n,z<0.\\nRecall from Section 5.1.5 that zeros in the right half plane are called nonmini-\\nmum phase – this is due to the fact the phase of the system has a large swing\\nfrom its maximum and minimum values (as compared to the phase plot of the\\nsystem with the same magnitude plot, but with all zeros in the OLHP). The\\neﬀect of a RHP zero is to slow down the system, and perhaps introduce under-\\nshoot. However, the magnitude plot of the system is aﬀected in the same way\\nas with a LHP zero: the bandwidth increases. Thus, for a nonminimum phase\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 70}, page_content='8.3 Eﬀects of Poles and Zeros on the Step Response 63\\nzero, our rule of thumb about a larger bandwidth implying a faster response no\\nlonger holds.\\nIt is also worth noting that if z= 0, the above analysis no longer holds directly.\\nAdding a zero at s= 0 produces the transfer function Hz(s) =sH(s), and the\\nstep response of this system is purely the derivative of the step response of the\\noriginal system. However, the steady state value of this step response is zero,\\nnot 1 (note that this agrees with the DC gain of the new system).\\n8.3.2 Eﬀect of Poles on the Step Response\\nA generaln–th order system will have npoles in the complex plane. As we have\\nalready discussed, if any of these poles are in the RHP, the step response will\\nbe unstable (i.e., it will go to inﬁnity). Consider the case of all poles being in\\nthe OLHP; a sample distribution is shown in Fig. 8.5.\\nFigure 8.5: Sample distribution of poles in OLHP, with dominant poles encir-\\ncled.\\nFrom the partial fraction expansion, we know that a pole −pcontributes a term\\nof the form e−ptto the step response. If pis large, this exponential term dies out\\nquickly. Suppose that the set of poles for a system can be divided into a cluster\\nof poles that are closest to the origin, and another cluster that are very far away\\nin comparison (e.g., 5 times further away). The poles that are closest to the\\norigin are called the dominant poles of the system. The exponential terms in\\nthe step response corresponding to the far away poles will die out very quickly\\nin relation to the exponential terms corresponding to the dominant poles. Thus,\\nthe system eﬀectively behaves as a lower order system with only the dominant\\npoles. This is one way to approximate a high order system by a lower order\\nsystem (such as a ﬁrst or second order system).\\nSince each additional pole contributes an additional exponential term that must\\ndie out before the system reaches its ﬁnal value, each additional pole increases\\nthe rise time of the system. In other words, adding a pole to the system makes\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 71}, page_content='64 Performance of Second Order Step Responses\\nthe step response more sluggish . Again, one can see this by looking at the\\nbandwidth of the system: including an additional term of the form (1\\nps+ 1) in\\nthe denominator of the transfer function causes the Bode plot to decrease faster\\nafterω=p, which generally decreases the bandwidth of the system.\\nExample. Plot the step response of the system with transfer function\\nH(s) =4\\n(1\\nps+ 1)(s2+ 2s+ 4),\\nforp= 0.1,2,10,100.\\nSolution.\\nSummary. Based on our discussions, we can make the following observations:\\n•Adding a LHP zero to the transfer function makes the step response faster\\n(decreases the rise time and the peak time) and increases the overshoot.\\nThe bandwidth of the system is increased.\\n•Adding a RHP zero to the transfer function makes the step response\\nslower, and can make the response undershoot.1The bandwidth of the\\nsystem is increased.\\n•Adding a LHP pole to the transfer function makes the step response slower.\\nThe bandwidth of the system is decreased.\\n•If the system has a cluster of poles and zeros that are much closer (5 times\\nor more) to the origin than the other poles and zeros, the system can be\\napproximated by a lower order system with only those dominant poles and\\nzeros.\\n1Actually, one can show that the step response for a given (stable) linear time-invariant\\nsystem will have undershoot if and only if the transfer function has an oddnumber of zeros in\\nthe ORHP. See the paper “On Undershoot and Nonminimum Phase Zeros” by M. Vidyasagar\\n(IEEE Transactions on Automatic Control , vol. 31, no. 5, May 1986, p. 440) for the\\nderivation of this result.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 72}, page_content='Chapter 9\\nStability of Linear\\nTime-Invariant Systems\\nRecall from our discussion on step responses that if the transfer function contains\\npoles in the open right half plane, the response will go to inﬁnity. However, if\\nall poles of the transfer function are in the open left half plane, the response\\nwill settle down to the DC gain of the transfer function. To describe these\\ncharacteristics of systems, we deﬁne the following terms:\\n•A signalf(t) isbounded if there exists some constant Msuch that\\n|f(t)|≤Mfor allt. It is called unbounded if it is not bounded.\\n•A system is bounded-input bounded-output (BIBO) stable if every\\nbounded input leads to a bounded output. We will also refer to such\\nsystems simply as stable .\\n•A system is unstable if there is at least one bounded input that produces\\nan unbounded output.\\nA linear time-invariant system is stable if all the poles of the transfer\\nfunction are in the OLHP, and it is unstable if at least one pole is in\\nthe CRHP.\\n9.1 Pole-zero cancellations and stability\\nConsider the linear time-invariant system given by the transfer function\\nH(s) =bmsm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0=N(s)\\nD(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 73}, page_content='66 Stability of Linear Time-Invariant Systems\\nRecall that this system is stable if all of the poles are in the OLHP, and these\\npoles are the roots of the polynomial D(s). It is important to note that one\\nshould not cancel any common poles and zeros of the transfer func-\\ntion before checking the roots of D(s). Speciﬁcally, suppose that both of the\\npolynomials N(s) andD(s) have a root at s=a, for some complex (or real)\\nnumbera. One must notcancel out this common zero and pole in the transfer\\nfunction before testing for stability. The reason for this is that, even though the\\npole will not show up in the response to the input, it will still appear as a re-\\nsult of any initial conditions in the system, or due to additional inputs entering\\nthe system (such as disturbances). If the pole and zero are in the CRHP, the\\nsystem response might blow up due to these initial conditions or disturbances,\\neven though the input to the system is bounded, and this would violate BIBO\\nstability.\\nTo see this a little more clearly, consider the following example. Suppose the\\ntransfer function of a linear system is given by\\nH(s) =s−1\\ns2+ 2s−3=N(s)\\nD(s).\\nNoting that s2+ 2s−3 = (s+ 3)(s−1), suppose we decided to cancel out the\\ncommon pole and zero at s= 1 to obtain\\nH(s) =1\\ns+ 3.\\nBased on this transfer function, we might (erroneously) conclude that the system\\nis stable, since it only has a pole in the OLHP. What we should actually do is\\nlook at the original denominator D(s), and correctly conclude that the system\\nis unstable because one of the poles is in the CRHP. To see why the pole-\\nzero cancellation hides instability of the system, ﬁrst write out the diﬀerential\\nequation corresponding to the transfer function to obtain\\n¨y+ 2 ˙y−3y= ˙u−u .\\nTake the Laplace Transform of both sides, taking initial conditions into account:\\ns2Y(s)−sy(0)−˙y(0) + 2sY(s)−2y(0)−3Y(s) =sU(s)−u(0)−U(s).\\nRearrange this equation to obtain\\nY(s) =s−1\\ns2+ 2s−3\\ued19\\ued18\\ued17\\ued1a\\nH(s)U(s)+s+ 2\\ns2+ 2s−3y(0)+1\\ns2+ 2s−3˙y(0)−1\\ns2+ 2s−3u(0).\\nNote that the denominator polynomial in each of the terms on the right hand\\nsides is equal to D(s) (the denominator of the transfer function). For simplicity,\\nsuppose that y(0) =y0(for some real number y0), ˙y(0) = 0 and u(0) = 0. The\\npartial fraction expansion of the terms+2\\ns2+2s−3y0is given by\\ns+ 2\\ns2+ 2s−3y0=y0\\n4(1\\ns+ 3+1\\ns−1)\\n,\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 74}, page_content='9.2 Stability of the Unity Feedback Loop 67\\nand this contributes the termy0\\n4(\\ne−3t+et)\\n,t≥0, to the response of the sys-\\ntem. Note that the etterm blows up, and thus the output of the system blows\\nup ify0is not zero, even if the input to the system is bounded.\\nIf all poles of the transfer function are in the OLHP (before any pole-zero\\ncancellations), all initial conditions will decay to zero, and not cause the output\\nof the system to go unbounded.\\nThe above example demonstrates the following important fact:\\nStability of a transfer function must be checked without canceling\\nany common poles and zeros from the transfer function. In particular,\\nsystems with unstable pole-zero cancellations are unstable .\\n9.2 Stability of the Unity Feedback Loop\\nConsider the standard feedback structure shown below.\\nR(s)\\nC(s)E(s)\\nP(s)Y(s)\\n−\\nSuppose that we write P(s) =np(s)\\ndp(s)andC(s) =nc(s)\\ndc(s)for some polynomials\\nnp(s),dp(s),nc(s),dc(s). The transfer function from rtoyis given by\\nH(s) =P(s)C(s)\\n1 +P(s)C(s)=np(s)nc(s)\\ndp(s)dc(s)\\n1 +np(s)nc(s)\\ndp(s)dc(s)=np(s)nc(s)\\ndp(s)dc(s) +np(s)nc(s).\\nThe denominator of the above transfer function is called the characteristic poly-\\nnomial of the closed loop system, and we have the following result.\\nThe unity feedback system is stable if and only if all roots\\nof the characteristic polynomial dp(s)dc(s) +np(s)nc(s) are\\nin the OLHP.\\nNote that the above test captures unstable pole/zero cancellations: if there is\\nan unstable pole s=aindp(s) ordc(s), and that same root appears in either\\nnc(s) ornd(s), thens=awould be a root of dp(s)dc(s) +np(s)nc(s) and would\\nthus cause the characteristic polynomial to fail the test for stability.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 75}, page_content='68 Stability of Linear Time-Invariant Systems\\n9.3 Tests for Stability\\nConsider a general transfer function of the form\\nH(s) =bmsm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0=N(s)\\nD(s).\\nWe would like to determine whether all poles of this transfer function are in the\\nOLHP. One way to do this would be to actually ﬁnd the poles of the system\\n(by ﬁnding the roots of D(s)). However, ﬁnding the roots of a high-degree\\npolynomial can be complicated, especially if some of the coeﬃcients are symbols\\nrather than numbers (this will be the case when we are designing controllers, as\\nwe will see later). Furthermore, note that we do not need the actual values of\\nthe poles in order to determine stability – we only need to know if all poles are\\nin the OLHP. Can we determine this from the coeﬃcients of the polynomial?\\n9.3.1 A Necessary Condition for Stability\\nSuppose that the polynomial D(s) has roots−p1,−p2,...,−pn(for simplicity,\\nassume that these are all real, but the following analysis also holds if some of\\nthe roots are complex). The polynomial can then be written as\\nD(s) =sn+an−1sn−1+···+a1s+a0= (s+p1)(s+p2)...(s+pn).\\nHow do the coeﬃcients a0,a1,...,an−1relate top1,p2,...,pn? To see the\\npattern, consider the following cases:\\n(s+p1)(s+p2) =s2+ (p1+p2)s+p1p2\\n(s+p1)(s+p2)(s+p3) =s3+ (p1+p2+p3)s2+ (p1p2+p1p3+p2p3)s\\n+p1p2p3\\n(s+p1)(s+p2)(s+p3)(s+p4) =s4+ (p1+p2+p3+p4)s3\\n+ (p1p2+p1p3+p1p4+p2p3+p2p4+p3p4)s2\\n+ (p1p2p3+p1p2p4+p1p3p4+p2p3p4)s\\n+p1p2p3p4\\n...\\nBased on the above examples, we see that:\\n•an−1is the sum of all the pi’s.\\n•an−2is the sum of all products of the pi’s taken two at a time.\\n•an−3is the sum of all products of the pi’s taken three at a time.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 76}, page_content='9.3 Tests for Stability 69\\n...\\n•a0is the product of all the pi’s.\\nNow, suppose that all roots are in the OLHP (i.e., p1>0,p2>0,...,pn>0).\\nThis means that a0>0,a1>0,...,an−1>0 as well. This leads us to the\\nfollowing conclusion.\\nThe polynomial D(s) =sn+an−1sn−1+···+a1s+a0has all roots in\\nthe OLHP only if all of the coeﬃcients a0,a1,...,an−1are positive.\\nNote that the above condition is necessary , but it is not suﬃcient in general.\\nWe will see this in the following examples.\\nExamples.\\n•D(s) =s3−2s2+s+ 1:\\n•D(s) =s4+s2+s+ 1:\\n•D(s) =s3+ 2s2+ 2s+ 1:\\n•D(s) =s3+ 2s2+s+ 12:\\nIn the last example above, the polynomial can be factored as D(s) = (s+\\n3)(s2−s+ 4), and the second factor has roots in the CRHP. This shows that\\na polynomial having all coeﬃcients positive does not mean that all of the roots\\nare in the OLHP. Only the converse is true: if all of the roots are in the OLHP,\\nthen all of the coeﬃcients are positive.\\nAlthough the test for positive coeﬃcients allows us to immediately determine\\nwhether the roots of a polynomial are notstable, we need a way to conclusively\\ndetermine whether all of the roots arestable.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 77}, page_content='70 Stability of Linear Time-Invariant Systems\\n9.3.2 A Necessary and Suﬃcient Condition:\\nRouth-Hurwitz Test\\nThe problem of determining how many roots of the polynomial D(s) =ansn+\\nan−1sn−1+···+a1s+a0are in the ORHP was studied by E. J. Routh in the\\nlate 1800’s. He devised the following technique for solving this problem (we will\\nassume that the polynomial D(s) has no roots on the imaginary axis, so it is\\nsuﬃcient to check for poles in the ORHP, as opposed to CRHP).\\nFirst, construct a Routh array :\\nsnanan−2an−4···\\nsn−1an−1an−3an−5···\\nsn−2b1b2b3···\\nsn−3c1c2c3···\\n...............\\ns2∗ ∗\\ns1∗\\ns0∗\\nThe ﬁrst two rows of this array contain the coeﬃcients of the polynomial. The\\nnumbersb1,b2,b3,...on the third row are deﬁned as:\\nb1=−1\\nan−1⏐⏐⏐⏐anan−2\\nan−1an−3⏐⏐⏐⏐=an−1an−2−anan−3\\nan−1,\\nb2=−1\\nan−1⏐⏐⏐⏐anan−4\\nan−1an−5⏐⏐⏐⏐=an−1an−4−anan−5\\nan−1,\\nb3=−1\\nan−1⏐⏐⏐⏐anan−6\\nan−1an−7⏐⏐⏐⏐=an−1an−6−anan−7\\nan−1,\\n...\\nNotice the pattern: the i–th element on the third row is obtained by taking\\nthe negative determinant of the matrix consisting of the ﬁrst column and the\\n(i+1)–th column in the ﬁrst two rows, divided by the ﬁrst element in the second\\nrow. The third row will have one less element than the ﬁrst two rows.\\nSimilarly, the numbers c1,c2,c3,...on the fourth row are deﬁned as:\\nc1=−1\\nb1⏐⏐⏐⏐an−1an−3\\nb1b2⏐⏐⏐⏐=b1an−3−an−1b2\\nb1,\\nc2=−1\\nb1⏐⏐⏐⏐an−1an−5\\nb1b3⏐⏐⏐⏐=b1an−5−an−1b3\\nb1,\\nc3=−1\\nb1⏐⏐⏐⏐an−1an−7\\nb1b4⏐⏐⏐⏐=b1an−7−an−1b4\\nb1,\\n...\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 78}, page_content='9.3 Tests for Stability 71\\nAgain, notice the pattern : thei–th element on the fourth row is obtained by\\ntaking the negative determinant of the matrix consisting of the ﬁrst column and\\nthe (i+ 1)–th columns of the preceding two rows, divided by the ﬁrst element\\nin the immediately preceding row.\\nWe continue this process until the ( n+ 1)–th row (corresponding to s0in the\\nRouth array), which will have only one entry. After this process is complete,\\nwe can use the following result1to check stability of D(s).\\nThe number of sign changes in the ﬁrst column of the Routh array\\nindicates the number of roots that are in the ORHP. All roots are in\\nthe OLHP if and only if there are no sign changes in the ﬁrst column\\n(i.e., either all entries are positive, or all are negative).\\nNote: The above algorithm requires us to divide certain determinants by the\\nﬁrst entry in each row of the Routh array. If this entry is zero, but all other\\nentries in the row are nonzero, we can replace the zero by a small positive value\\nϵ, and continue as before (the above result still holds in this case). On the other\\nhand, if an entire row of the Routh array is zero, this signiﬁes the potential\\nexistence of poles on the imaginary axis, and a slightly more complex procedure\\nwill have to be followed. Be aware that these special cases exist, but we will not\\ndeal with them in this course.\\nExample. Determine whether the polynomial D(s) =s4+ 3s3+ 2s2+ 2s+ 9\\nhas all roots in the OLHP.\\nSolution.\\nExample. Determine whether the polynomial D(s) =s4+ 5s3+ 9s2+ 5s+ 2\\n1A relatively simple proof of this result can be found in the paper “Elementary Proof of\\nthe Routh-Hurwitz Test” by G. Meinsma ( Systems and Control Letters , vol. 25, no. 4, 1995,\\npp. 237-242).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 79}, page_content='72 Stability of Linear Time-Invariant Systems\\nhas all roots in the OLHP.\\nSolution.\\n9.3.3 Testing For Degree of Stability\\nThere may be times when we would like to test a polynomial to see if the\\nreal parts of all of its roots are less than a certain value; so far, we have been\\nconsidering this value to be zero (i.e., we have been testing to see if all roots lie\\nin the OLHP). Suppose that we would like to see if all roots of a polynomial\\nD(s) have real part less than λ. Consider the polynomial ¯D(s) =D(s+λ). It\\nis easy to see that the roots of ¯D(s) are the roots of D(s) shifted by λ: ifs=a\\nis a root of D(s), thens=a−λis a root of ¯D(s). Thus, all roots of D(s) have\\nreal parts less than λif and only if all roots of ¯D(s) are in the OLHP, and we\\ncan use the Routh-Hurwitz test on ¯D(s) to see whether all roots of D(s) lie to\\nthe left ofλ.\\nExample. Determine whether the polynomial D(s) =s3+ 3s2+ 3s+ 9 has all\\nroots with real parts less than −1.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 80}, page_content='9.3 Tests for Stability 73\\nSolution.\\n9.3.4 Testing Parametric Stability with Routh-Hurwitz\\nIn control system design, we will frequently run across cases where some of the\\ncoeﬃcients of the polynomial are parameters for us to design or analyze (such\\nas control gains, or unknown values for system components). We can use the\\nRouth-Hurwitz test to determine ranges for these parameters so that the system\\nwill be stable.\\nExample. In the feedback control loop shown below, determine the range of\\nvalues forKfor which the closed loop transfer function (from R(s) toY(s)) will\\nbe stable.\\nR(s)\\nK1\\n(s+6)(s+3)(s−1)Y(s)\\n−\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 81}, page_content='74 Stability of Linear Time-Invariant Systems\\nExample. In the feedback loop shown below, determine the values of Kanda\\nfor which the closed loop system is stable.\\nR(s)K(s+a)\\ns+11\\ns(s+2)(s+3)Y(s)\\n−\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 82}, page_content='Chapter 10\\nProperties of Feedback\\nWith the tools to analyze linear systems in hand, we now turn our attention\\nto feedback control. Recall the unity feedback control loop that we looked at\\nearlier:\\nC(s)P(s)R(s)D(s)\\n++Y(s)\\n−\\nFigure 10.1: Feedback Control.\\nIn the above ﬁgure, P(s) is the plant, C(s) is the controller, ris the reference\\nsignal,yis the output of the system, and dis adisturbance aﬀecting the\\ncontrol loop (e.g., wind on an airplane, noise in a sensor, faults in an electrical\\ngrid, etc.).\\nRecall from Chapter 1 that there are three main properties that a good control\\nsystem should have:\\n•Tracking. The output of the system should behave like the reference\\nsignal. This property is studied by examining the transfer function from\\nthe reference input to the output.\\n•Disturbance Rejection. The disturbances should aﬀect the output as\\nlittle as possible. This property is studied by examining the transfer func-\\ntion from the disturbance to the output.\\n•Robustness. The output should track the reference signal even if the\\nplant model is not exactly known, or changes slightly. This property is\\nstudied by examining the sensitivity of the transfer function to perturba-\\ntions in the plant, as we show below.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 83}, page_content='76 Properties of Feedback\\nSensitivity. LetTry(s) denote the transfer function of the control system from\\nthe reference rto the output y. Now suppose that we allow the plant P(s) to\\nchange by a small amount δP(s) to become the new plant ¯P(s) =P(s)+δP(s).\\nThis will cause the transfer function Try(s) to also change by a small amount\\nδTry(s), to become ¯Try(s) =Try(s)+δTry(s). The question is: how does δTry(s)\\ncompare to δP(s)? More speciﬁcally, the sensitivity is deﬁned as the fractional\\n(or percentage) change in the transfer function as related to the fractional change\\nin the plant model:\\nS(s) =δTry(s)\\nTry(s)\\nδP(s)\\nP(s)=δTry(s)\\nδP(s)P(s)\\nTry(s).\\nNote that for small perturbations δP(s) andδTry(s), the expressionδTry(s)\\nδP(s)is\\nthe derivative of Try(s) with respect to P(s). In order to have good robustness,\\nwe want the sensitivity to be as small as possible .\\nWe will analyze the tracking, disturbance rejection and robustness properties for\\nboth a feedforward control conﬁguration and a feedback control conﬁguration,\\nand see why feedback is an important concept for control system design.\\n10.1 Feedforward Control\\nRecall from the ﬁrst lecture that feedforward control does not make use of\\nmeasurements of the system output in order to supply the input. The block\\ndiagram for feedforward control is shown in Fig. 10.2.\\nC(s)P(s)R(s)D(s)\\n++Y(s)\\nFigure 10.2: Feedforward Control.\\nWe can examine how well feedforward control satisﬁes the properties listed\\nabove.\\n•Tracking. The transfer function from the reference to the output is ob-\\ntained by assuming that the disturbance is not present (i.e., take d= 0),\\nand is given by\\nTry(s) =Y(s)\\nR(s)=P(s)C(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 84}, page_content='10.2 Feedback Control 77\\nWe can potentially get perfect tracking by choosing C(s) =P(s)−1, in\\nwhich case we have Y(s) =R(s). Note, however, that “inverting” the\\nplant in this way may not always be possible in practice. Setting the\\nimplementation details aside for now, we note that feedforward control\\ncan potentially provide perfect tracking.\\n•Disturbance Rejection. The transfer function from the disturbance to\\nthe output is obtained by assuming that the reference signal is not present\\n(i.e.,r= 0), and is given by\\nTdy(s) =Y(s)\\nD(s)= 1.\\nThus, the output is completely aﬀected by the disturbance. Furthermore,\\nthe feedforward control scheme provides us with no way to reduce this\\ninﬂuence. Thus, feedforward control is bad at rejecting distur-\\nbances.\\n•Robustness. To examine how robust feedforward control is to variations\\nin the plant, we examine the sensitivity\\nS(s) =δTry(s)\\nδP(s)P(s)\\nTry(s).\\nSinceTry(s) =P(s)C(s), we have\\nS(s) =C(s)P(s)\\nP(s)C(s)= 1.\\nThis shows that the transfer function is 100% sensitive to changes in the\\nplant, which is bad for robustness .\\nWe can summarize the above ﬁndings as follows.\\nFeedforward control is potentially good for tracking ,bad for\\ndisturbance rejection andbad for robustness .\\n10.2 Feedback Control\\nNow consider the feedback control scheme shown in Fig. 10.1. We will study\\nhow well this control scheme satisﬁes the properties described earlier.\\n•Tracking. The transfer function from the reference to the output is ob-\\ntained by assuming that the disturbance is not present (i.e., take d= 0),\\nand is given by\\nTry(s) =Y(s)\\nR(s)=P(s)C(s)\\n1 +P(s)C(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 85}, page_content='78 Properties of Feedback\\nWe would like to make this transfer function as close to 1 as possible, so\\nthat we can get Y(s) =R(s). One way to accomplish this would be to\\nchooseC(s) =Kfor some very large constant K(this is called “high gain\\ncontrol”). In this case, the magnitude of P(s)C(s) will be large for all s,\\nand thusTry(s) is approximately equal to 1. Thus, feedback control\\ncan provide good tracking.\\n•Disturbance Rejection. The transfer function from the disturbance to\\nthe output is obtained by assuming that the reference signal is not present\\n(i.e.,r= 0), and is given by\\nTdy(s) =Y(s)\\nD(s)=1\\n1 +P(s)C(s).\\nWe would like to make this transfer function as small as possible (so\\nthat the disturbance does not aﬀect the output). Once again, suppose\\nwe chooseC(s) =Kfor some very large constant K. In this case, the\\ndenominator of Tdy(s) becomes very large, and so Tdy(s) becomes small.\\nThus, feedback control can be good at rejecting disturbances.\\n•Robustness. To examine how robust feedback control is to variations in\\nthe plant, we examine the sensitivity\\nS(s) =δTry(s)\\nδP(s)P(s)\\nTry(s).\\nSinceTry(s) =P(s)C(s)\\n1+P(s)C(s), we have\\nS(s) =C(s)\\n(1 +P(s)C(s))2P(s)\\nP(s)C(s)\\n1+P(s)C(s)=1\\n1 +P(s)C(s).\\nOnce again, choosing C(s) =K, for a large constant K, makesS(s) very\\nsmall. Thus, feedback control is robust to variations in the plant .\\nWe can summarize the above ﬁndings as follows.\\nFeedback control is good for tracking ,good for disturbance\\nrejection andgood for robustness .\\nIn addition to the above beneﬁts, we will see later that feedback control can\\nalso stabilize an unstable plant (whereas feedforward control cannot). Also, it\\nis worth noting that although we used high gain control to show that feedback\\nprovides good tracking, disturbance rejection and robustness, it is not the only\\noption (and sometimes not even the best option). In practice, high gains are\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 86}, page_content='10.2 Feedback Control 79\\nhard to implement in hardware (due to saturation eﬀects and physical limi-\\ntations). Furthermore, in some cases, high gain can even destabilize a stable\\nsystem (we will see this when we study root-locus methods). We will be study-\\ning ways to design more sophisticated feedback controllers to get around these\\nproblems.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 87}, page_content='80 Properties of Feedback\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 88}, page_content='Chapter 11\\nTracking of Reference\\nSignals\\nRecall the basic feedback control loop that we looked at earlier:\\nR(s)\\nC(s)E(s)\\nP(s)Y(s)\\n−\\nIn the above ﬁgure, P(s) is the plant, C(s) is the controller, ris the reference\\nsignal,yis the output of the system, and eis the error (i.e., e=r−y). We will\\nneglect disturbances for now. Note that the signal yis directly subtracted from\\nthe reference signal in this feedback loop, so this conﬁguration is called unity\\nfeedback . The transfer function from rtoyis\\nTry(s) =Y(s)\\nR(s)=P(s)C(s)\\n1 +P(s)C(s).\\nRecall that the product P(s)C(s) is called the forward gain of the feedback\\nloop. We can always write P(s)C(s) as\\nP(s)C(s) =a(s)\\nsqb(s),\\nfor some polynomials a(s) andb(s), and some nonnegative integer q(this is the\\nnumber of poles at the origin in the product P(s)C(s)). The polynomial b(s)\\nhas no roots at s= 0 (otherwise this root can be grouped into the term sq);\\nthis means that b(0)̸= 0. The transfer function then becomes\\nTry(s) =a(s)\\nsqb(s)\\n1 +a(s)\\nsqb(s)=a(s)\\nsqb(s) +a(s).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 89}, page_content='82 Tracking of Reference Signals\\nExample. SupposeP(s) =s+1\\ns2andC(s) =12(s+2)\\ns(s+4). What are a(s),b(s) and\\nq? What is the transfer function?\\nSolution.\\nWe’ll assume that C(s) is chosen so that the closed loop system is stable (other-\\nwise, we do not have any hope of tracking any signal). This means that all roots\\nofsqb(s) +a(s) are in the OLHP. We will now examine how well this feedback\\nloop tracks certain types of reference signals.\\n11.1 Tracking and Steady State Error\\nWe will start by examining the steady state error of the above feedback loop\\nto reference signals of the form r(t) =tm,t≥0, wheremis some nonnegative\\ninteger. The reference r(t) is a step input when m= 0, a ramp input when\\nm= 1, and a parabolic input when m= 2. Note from the Laplace Transform\\ntable that the Laplace transform of r(t) =tm,t≥0 isR(s) =m!\\nsm+1.\\nFigure 11.1: The reference input r(t) =tm,t≥0, form= 0,1,2.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 90}, page_content='11.1 Tracking and Steady State Error 83\\nTo determine how well the system tracks (or follows) the reference inputs, we\\nwill examine the error signal e=r−y. Speciﬁcally, the Laplace Transform of\\ne(t) is given by:\\nE(s) =R(s)−Y(s) =R(s)−P(s)C(s)E(s),\\nfrom which we obtain\\nE(s) =1\\n1 +P(s)C(s)R(s) =m!1\\n(1 +P(s)C(s))sm+1.\\nRecall that the Final Value Theorem states that if all poles of sE(s) are in the\\nOLHP, then the signal e(t) settles down to some ﬁnite steady state value. From\\nthe above expression for E(s), we have\\nsE(s) =m!1\\n(1 +P(s)C(s))sm.\\nNote that, as written, sE(s) seems to have mpoles at the origin. Note from our\\nearlier discussion, however, that P(s)C(s) hasqpoles at the origin, so that we\\ncan writeP(s)C(s) =a(s)\\nsqb(s), for some polynomials a(s) andb(s). The expression\\nforsE(s) can then be written as\\nsE(s) =m!1\\n(1 +a(s)\\nsqb(s))sm=m!b(s)\\n(sqb(s) +a(s))sm−q.\\nRecall that the polynomial sqb(s) +a(s) has all roots in the OLHP (by our\\nassumption of stability). We thus only have to check for poles at the origin\\n(given by the quantity sm−q). We consider three diﬀerent cases:\\n•Ifq >m , the function sE(s) will have all poles in the OLHP, and q−m\\nzeros at the origin. The steady state error is obtained from the Final Value\\nTheorem as\\ness= lim\\nt→∞e(t) = lim\\ns→0sE(s) =m!0q−mb(0)\\n0qb(0) +a(0)= 0.\\nThus, ifq>m , we have perfect steady state tracking (i.e., the steady\\nstate error is zero).\\n•Ifq=m, the function sE(s) has all poles in the OLHP, and no zeros at\\nthe origin. From the Final Value Theorem, we have\\ness= lim\\nt→∞e(t) = lim\\ns→0sE(s) = lim\\ns→0m!b(s)\\nsqb(s) +a(s)\\n= lim\\ns→0m!1\\nsq+a(s)\\nb(s)\\n= lim\\ns→0m!1\\nsq+sqP(s)C(s),\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 91}, page_content='84 Tracking of Reference Signals\\nwhich is some nonzero constant.1Note that if q= 0, the steady state\\nerror isess= lims→0m!1\\n1+P(s)C(s), and ifq >0, the steady state error\\nisess= lims→0m!1\\nsqP(s)C(s). Thus, we have steady state tracking to\\nwithin a constant ﬁnite error.\\n•Ifq < m , the function sE(s) will have m−qpoles at the origin. Thus\\nthe signale(t) blows up as t→∞ , and there is no steady state value. In\\nother words, the system output does not track the reference input\\nat all.\\nSummary. SupposeP(s)C(s) hasqpoles at the origin ( qis a non-\\nnegative integer), and suppose the reference input to the unity feedback\\nloop isr(t) =tm,t≥0, wheremis a nonnegative integer.\\n•Ifq>m , the output y(t) will track the reference r(t) perfectly in\\nsteady state (i.e., the steady state error will be zero).\\n•Ifq=m, the output y(t) will track the reference r(t) to within a\\nconstant (ﬁnite) steady state error.\\n•Ifq<m , the output y(t) will not track the reference r(t) at all.\\nNote that if a linear system can track a signal tm,t≥0, then it can also track\\nany polynomial of degree mor less (by linearity).\\nSystem type. The above results indicate that the number of poles at the origin\\ninP(s)C(s) determines the type of reference inputs that the closed loop system\\ncan track. Thus, the integer qis called the system type . Speciﬁcally, a system\\nof typeqcan track reference signals that are polynomials of degree qor less to\\nwithin a constant ﬁnite steady state error.\\nNote: It does not matter whether the poles in P(s)C(s) come from the plant\\nP(s) or from the controller C(s). The only thing that matters is how many poles\\ntheir product has. We can therefore use this fact to construct controllers with a\\ncertain number of poles in order to track certain types of reference signals, even\\nif the plant does not have the required number of poles. We will see this in the\\nnext lecture.\\n1Do not try to memorize this. Instead, always just derive the tracking error using ﬁrst\\nprinciples, ﬁrst calculating E(s) in terms of Try(s) and R(s), and then applying the ﬁnal\\nvalue theorem.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 92}, page_content='11.1 Tracking and Steady State Error 85\\nExample. Consider the unity feedback loop with C(s) =12(s+2)\\ns(s+4)andP(s) =\\ns+1\\ns2. What is the system type? What is the steady state tracking error for the\\nsignalsr(t) =1(t),r(t) =t1(t),r(t) =t21(t),r(t) =t31(t), andr(t) =t41(t)?\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 93}, page_content='86 Tracking of Reference Signals\\nExample. Suppose that C(s) =K(for some positive constant K), andP(s) =\\n1\\ns+1. What is the system type? What is the steady state tracking error for the\\nsignalsr(t) =1(t),r(t) =t1(t) andr(t) =t21(t)?\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 94}, page_content='11.1 Tracking and Steady State Error 87\\nTo see why having an integrator guarantees perfect tracking for a step input (if\\nthe closed loop system is stable), rearrange the closed loop system as follows:\\nR(s)1\\nsE(s) W(s) Rest of\\nP(s)C(s)Y(s)\\n−\\nIn the above diagram, we have simply pulled the integrator out of the product\\nP(s)C(s), and denoted the signal at the output of the integrator by W(s) (or\\nw(t) in the time-domain). Now suppose that the closed loop system is stable\\n(note that this is a necessary assumption); in this case, all of the signals in the\\nsystem will settle down to some steady state values when r(t) is a unit step\\ninput. This includes the signal w(t), which is related to e(t) as\\nW(s) =1\\nsE(s)⇔w(t) =∫t\\n0e(τ)dτ.\\nIfe(t) settles down to some nonzero value, the above integral will become un-\\nbounded, and thus w(t) will not settle down to some steady state value, con-\\ntradicting the fact that the system is stable. Thus the only way for all signals\\nto have settled to a steady state value (which is guaranteed by stability) is if\\ne(t)→0. An alternative way to see this is to note that if w(t) settles down to\\na steady state value, then ˙ w(t) =e(t) = 0.\\nThis is an example of what is known as the internal model principle : if we\\nwish to perfectly track a signal of a certain form, we should include a model of\\nthat signal inside our feedback loop.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 95}, page_content='88 Tracking of Reference Signals\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 96}, page_content='Chapter 12\\nPID Control\\nR(s)\\nC(s)E(s)\\nP(s)Y(s)\\n−\\nSo far, we have examined the beneﬁts of feedback control, and studied how\\nthe poles of P(s)C(s) aﬀect the ability of the control system to track reference\\ninputs. We will now study a type of controller C(s) that is commonly used in\\npractice, called a proportional-integral-derivative (PID) controller . To\\ndevelop this controller, we will assume that the plant is a second order system\\nof the form\\nP(s) =b0\\ns2+a1s+a0.\\nNote that the transfer function from rtoyfor the above feedback loop is given\\nby\\nTry(s) =P(s)C(s)\\n1 +P(s)C(s).\\n12.1 Proportional (P) Control\\nWe start with a simple controller of the form C(s) =KP, whereKPis a\\nconstant that we will choose. In this case, the input to the plant is simply\\nu(t) =KPe(t), which is proportional to the error. Thus, this type of controller\\nis called a proportional controller .\\nWith this controller, the transfer function from rtoyin the feedback control\\nsystem becomes\\nTry(s) =KPb0\\ns2+a1s+ (a0+KPb0).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 97}, page_content='90 PID Control\\nRecall that the poles of this transfer function dictate how the system behaves\\nto inputs. In particular, we would like to ensure that the system is stable (i.e.,\\nall poles are in the OLHP). Since the gain KPaﬀects one of the coeﬃcients in\\nthe denominator polynomial, it can potentially be used to obtain stability.\\nExample. SupposeP(s) =1\\ns2+3s−1. Can we stabilize this plant with propor-\\ntional control?\\nSolution.\\nExample. SupposeP(s) =1\\ns2−3s−1. Can we stabilize this plant with propor-\\ntional control?\\nSolution.\\nThe above examples demonstrate that simple proportional control can stabilize\\nsome plants, but not others.\\nAnother beneﬁt of proportional control is that it can potentially be used to\\nspeed up the response of the system. Recall the standard second order system\\nhad a denominator of the form s2+ 2ζωns+ω2\\nn, and the larger ωnis, the faster\\nthe system responds. In the closed loop transfer function Try(s) above, the term\\nω2\\nnis given by a0+KPb0, and thus we can potentially make ωnvery large by\\nchoosingKPto be very large, thereby speeding up the system.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 98}, page_content='12.2 Proportional-Integral (PI) Control 91\\nNow let’s consider tracking. Recall from the previous lecture that in order to\\ntrack a step input perfectly (i.e., with zero steady state error), the system must\\nbe of type 1 (a type 0 system would track a step within a ﬁnite steady state\\nerror). IfC(s) =KPandP(s) =b0\\ns2+a1s+a0, the system would only be of type\\n0 (ifa0is not zero), and thus we will not be able to track a step perfectly. To\\nrectify this, we will have to add an integrator to the controller in order to make\\nthe system type 1.\\n12.2 Proportional-Integral (PI) Control\\nTo obtain perfect tracking for step inputs, we will introduce an integrator into\\nthe controller (i.e., we will add a pole at the origin) in order to ensure that the\\nsystem will be of type 1. The controller thus becomes\\nC(s) =KP+KI\\ns.\\nIn the time-domain, this corresponds to the input to the plant being chosen as\\nu(t) =KPe(t) +KI∫t\\n0e(τ)dτ ,\\nand thus this is called a proportional-integral controller . With this con-\\ntroller, the transfer function from rtoyis\\nTry(s) =b0\\ns2+a1s+a0KPs+KI\\ns\\n1 +b0\\ns2+a1s+a0KPs+KI\\ns=b0(KPs+KI)\\ns3+a1s2+ (a0+KPb0)s+KIb0.\\nNote that we now have a third order system. Two of the coeﬃcients of the\\ndenominator polynomial can be arbitrarily set by choosing KPandKIappro-\\npriately. Unfortunately, we still have no way to stabilize the system if a1<0\\n(recall that for stability, all coeﬃcients must be positive). Even if the system\\nis stable with the given value of a1, we might want to be able to choose better\\npole locations for the transfer function in order to obtain better performance.\\nTo do this, we add one ﬁnal term to the controller.\\n12.3 Proportional-Integral-Derivative (PID) Con-\\ntrol\\nConsider the PI controller from the last section, and add a term that corresponds\\nto the derivative of the error. The controller with this additional term has the\\nform\\nC(s) =KP+KI\\ns+KDs .\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 99}, page_content='92 PID Control\\nIn the time-domain, the input to the plant due to this controller is given by\\nu(t) =KPe(t) +KI∫t\\n0e(τ)dτ+KD˙e(t),\\nand so this controller is called a proportional-integral-derivative controller .\\nThe transfer function from rtoyis\\nTry(s) =b0\\ns2+a1s+a0KPs+KI+KDs2\\ns\\n1 +b0\\ns2+a1s+a0KPs+KI+KDs2\\ns\\n=b0(KPs+KI+KDs2)\\ns3+ (a1+KDb0)s2+ (a0+KPb0)s+KIb0.\\nNote that we are now able to arbitrarily set all coeﬃcients of the denominator\\npolynomial, via appropriate choices of KP,KIandKD. Thus we can now guar-\\nantee stability (only for a second order plant, though), good transient behavior,\\nand perfect tracking!\\nExample. Consider the plant P(s) =1\\ns2−3s−1. Design a PID controller so that\\nthe closed loop system has perfect tracking for a step input, and has poles at\\ns=−5,−6,−7.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 100}, page_content='12.4 Implementation Issues 93\\n12.4 Implementation Issues\\nPID control is extremely common in industry, as it is easy to design – we just\\nhave to “tune the knobs” corresponding to the gains KP,KIandKDappropri-\\nately. However, it is worth noting that it may not be desirable to implement\\nthe controller as given above; in practice, all signals will contain high frequency\\nnoise, and diﬀerentiating noise will once again create signals with large mag-\\nnitudes. To avoid this, the derivative term KDsis usually implemented in\\nconjunction with a low pass ﬁlter of the form1\\nτs+1, for some small τ. This has\\nthe eﬀect of attenuating the high frequency noise entering the diﬀerentiator,\\nand produces the controller\\nC(s) +KP+KI\\ns+KDs\\nτs+ 1.\\nWe will be seeing controllers of this form frequently in the second half of the\\ncourse.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 101}, page_content='94 PID Control\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 102}, page_content='Chapter 13\\nRoot Locus\\nBased on our discussion so far, we know that the response of a linear system to\\nan input is dictated by the location of the poles of the transfer function. For\\nexample, the response will be unstable if there are any poles in the CRHP, or\\nmay contain oscillations if the poles appear in complex conjugates. We have also\\nseen that feedback control can be used to move the poles of a closed loop sys-\\ntem: by choosing the controller gain appropriately, one can potentially stabilize\\nunstable systems (and perhaps even destabilize stable systems). In this section\\nof the course, we will examine in more detail how the poles of a transfer function\\nvary in the complex plane in response to changes in a certain parameter. We\\nwill begin with some examples.\\nExample. Consider the unity feedback loop with C(s) =KandP(s) =1\\ns−3.\\nHow does the pole of the closed loop system vary with K(forK≥0)?\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 103}, page_content='96 Root Locus\\nExample. Consider the unity feedback loop with C(s) =KandP(s) =1\\ns2+2s.\\nHow do the poles of the closed loop system vary with K(forK≥0)?\\nSolution.\\nExample. Consider the closed loop transfer function Try(s) =1\\ns2+bs+1. How\\ndo the poles of the system vary with b(forb≥0)?\\nSolution.\\nWhile we are able to easily draw the locations of the poles for ﬁrst and second\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 104}, page_content='13.1 The Root Locus Equations 97\\norder systems, we cannot do the same for higher order systems (because it\\nbecomes diﬃcult to explicitly calculate the roots). Furthermore, we would like\\nto obtain some intuition about how the poles of the system will be aﬀected by\\nour choice of controller. We would thus like to come up with a way to sketch\\nhow the poles of a system behave in response to a change in a parameter. Since\\nthe poles are given by the roots of the denominator polynomial, such a sketch is\\ncalled a root locus . The trajectory of each root in the plane is called a branch\\nof the root locus.\\n13.1 The Root Locus Equations\\nConsider the unity feedback loop:\\nR(s)\\nK L(s)Y(s)\\n−\\nThe transfer function L(s) could represent the plant, or it could represent some\\ncomposite system (such as the combination of a controller and plant). We will\\nwrite\\nL(s) =N(s)\\nD(s)=sm+bm−1sm−1+bm−2sm−2+···+b1s+b0\\nsn+an−1sn−1+an−2sn−2+···+a1s+a0,\\nwhereN(s) andD(s) are polynomials in s. As usual, the degree of N(s) ism,\\nthe degree of D(s) isn, and we assume that n≥m(i.e.,L(s) is proper). The\\ntransfer function from rtoyis given by\\nTry(s) =KL(s)\\n1 +KL(s)=KN(s)\\nD(s) +KN(s)=KN(s)\\n∆(s).\\nThe polynomial ∆( s) =D(s)+KN(s) is called the characteristic polynomial\\nof the system. Note that the roots of D(s)+KN(s) are the closed loop poles ,\\nthe roots of D(s) are the open loop poles , and the roots of N(s) are the open\\nloop zeros . When we plot these elements graphically, we will use ×to denote\\npoles, and◦to denote zeros.\\nThe root locus is a graph of how the roots of D(s) +KN(s) vary with\\nK. Equivalently, the root locus is the set of all solutions sto the\\nequationL(s) =−1\\nK.\\nNote that the root locus can actually be used to ﬁnd how the roots of any\\npolynomial vary with a single parameter, and thus it is a very general tool. For\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 105}, page_content='98 Root Locus\\nexample, aside from analyzing how the poles of a unity feedback loop vary with\\na controller gain K, the root locus can also be used to analyze how the poles\\nvary in response to a change in one of the system parameters. We saw this in\\nthe third example above, and we will see more of it later.\\nTo start, we will only focus on the case where Kvaries from 0 to∞– this is\\ncalled the positive root locus . We will deal with the negative root locus later.\\nWe will also assume that both N(s) andD(s) are monic (i.e., the coeﬃcient\\ncorresponding to the highest power in both polynomials is equal to 1). This\\nis not a strict assumption, because we can always divide the entire polynomial\\nD(s) +KN(s) by the leading coeﬃcient of D(s), and then absorb the leading\\ncoeﬃcient of N(s) intoKto deﬁne a new gain ¯K. After plotting the root locus,\\nwe can then map the gain ¯Kback toK.\\n13.1.1 Phase Condition\\nTo obtain an alternative (but equivalent) characterization of the root locus,\\nconsider the equation\\nL(s) =−1\\nK.\\nSince we are focusing on the case where K≥0, we see that L(s) must be\\na negative real number, and the root locus consists of all points satisfying this\\ncondition. In particular, since the phase of a negative real number is 180 degrees\\n(orπradians), we obtain the following characterization of the root locus.\\nThe positive root locus is the set of all points sin the complex plane for\\nwhich ∠L(s) = (2l+ 1)πradians (where lis any integer).\\nWe can obtain a geometric interpretation of the above condition as follows. Let\\nL(s) =(s+z1)(s+z2)···(s+zm)\\n(s+p1)(s+p2)···(s+pn),\\nwhere−z1,−z2,...,−zmare the open loop zeros, and −p1,−p2,...,−pnare\\nthe open loop poles. The phase of L(¯s), for some point ¯ sin the complex plane,\\nis given by\\n∠L(¯s) =∠(¯s+z1) +∠(¯s+z2) +···+∠(¯s+zm)\\n−∠(¯s+p1)−∠(¯s+p2)−···− ∠(¯s+pn).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 106}, page_content='13.1 The Root Locus Equations 99\\nNote that the phase of the point ¯ s+ziis given by the angle between the positive\\nreal axis and the vector from −zito ¯s:\\nThe same holds for the phase of the point ¯ s+pi. The phase of L(¯s) can therefore\\nbe obtained by summing these angles, and this will allow us to determine if ¯ s\\nis on the root locus.\\nExample. ConsiderL(s) =s+4\\ns((s+1)2+1). Is the point s=−3 on the root locus?\\nIs the point s=−4 +jon the root locus?\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 107}, page_content='100 Root Locus\\nWhile we can use the above method to test if speciﬁc points are on the root locus,\\nit is quite cumbersome to determine allpoints in the complex plane that are on\\nthe root locus in this way. What we need are some general rules for sketching\\nthe root locus for a given L(s) (or equivalently, for the equation D(s)+KN(s)).\\n13.2 Rules for Plotting the Positive Root Locus\\nWe will now develop some rules for plotting the positive root locus for a given\\npolynomial D(s) +KN(s).\\n13.2.1 Start Points and (Some) End Points of the Root\\nLocus\\nConsider the equation D(s) +KN(s) = 0. Since this is an n–th degree polyno-\\nmial, it will have nroots, and thus the root locus will have nbranches. Let’s\\nstart by considering what happens for the extreme values of K:\\n•WhenK= 0, the roots of this equation are simply the roots of D(s),\\nwhich are the open loop poles.\\n•WhenK→∞ , we consider the equivalent root locus equationN(s)\\nD(s)=−1\\nK.\\nAsK→∞ , the right side goes to zero, and thus the root locus consists\\nof the points that causeN(s)\\nD(s)to be zero. This will be true for the mroots\\nofN(s) (i.e., the open loop zeros), and thus mof the branches end at the\\nopen loop zeros. We will see what happens to the other n−mbranches\\nlater.\\nThis brings us to the following rule:\\nRule 1. Thenbranches of the root locus begin at the open loop poles\\n(whenK= 0). Of the nbranches,mbranches end at the open loop\\nzeros (when K=∞).\\n13.2.2 Points on the Real Axis\\nRecall that the positive root locus contains all points ¯ ssuch that\\n∠(¯s+z1)+∠(¯s+z2)+···+∠(¯s+zm)−∠(¯s+p1)−∠(¯s+p2)−···− ∠(¯s+pn)\\n= (2l+ 1)πradians.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 108}, page_content='13.2 Rules for Plotting the Positive Root Locus 101\\nConsider a point s= ¯son the real axis. Each real pole or zero to the right\\nof ¯scontributes−πradians or πradians to the angle. Each pair of complex\\nconjugate poles or zeros contributes nothing to the angle of a ¯ s(since the angles\\nof the complex conjugate poles or zeros will sum to zero). Each pole or zero to\\nthe left of ¯swill also contribute nothing (i.e., 0 radians) to the angle.\\nThus, in order for ¯ sto satisfy the above condition, there must be an odd number\\nof zeros or poles to the right of ¯ s.\\nRule 2. The positive root locus contains all points on the real axis\\nthat are to the left of an odd number of zeros or poles.\\nExample. ConsiderL(s) =(s+3)(s+7)\\ns2((s+1)2+1)(s+5). Determine the portions of the\\nreal axis that are on the root locus.\\nSolution.\\n13.2.3 Asymptotic Behavior of the Root Locus\\nWe have already seen that mout of thenbranches end up at the open loop\\nzeros asK→∞ . To see what happens to the other n−mbranches, consider\\nthe root locus equation L(s) =−1\\nK. AsK→∞ , the right side goes to zero,\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 109}, page_content='102 Root Locus\\nand thus the root locus consists of the points that cause L(s) to be zero. This\\nwill be true for the mopen loop zeros – are there any other choices of sthat\\nwill make the left hand side equal to zero? To answer this, write L(s) as\\nL(s) =sm+bm−1sm−1+···+b1s+b0\\nsn+an−1sn−1+···+a1s+a0\\n=1\\nsn−m+bm−11\\nsn−m+1+···+b11\\nsn−1+b01\\nsn\\n1 +an−11\\ns+···+a11\\nsn−1+a01\\nsn.\\nIfn>m , we see that the numerator goes to zero if |s|→∞ . Thus, the system\\nL(s) =N(s)\\nD(s)is said to have n−mzeros at inﬁnity , in addition to the mﬁnite\\nzeros (i.e., the roots of N(s)). We can thus conclude that mof thenbranches\\ngo to the open loop zeros, and the remaining n−mbranches go oﬀ to inﬁnity\\nasK→∞ . The question is, how do these branches approach inﬁnity? The\\nfollowing rule characterizes the behavior of these branches.\\nRule 3. Of thenbranches in the root locus, n−mof the branches go\\nto inﬁnity, and asymptotically approach lines coming out of the point\\ns=αwith angles Φ l, where\\nα=Σ open loop poles −Σ open loop zeros\\nn−m,Φl=(2l+ 1)π\\nn−m,(13.1)\\nforl= 0,1,2,...,n−m−1.\\nThe asymptotes for a few values of n−mare shown below:\\nWe will now go over a sketch of the proof of this result.1First, note that the\\n1This proof is borrowed from Prof. Daniel Liberzon at the University of Illinois.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 110}, page_content='13.2 Rules for Plotting the Positive Root Locus 103\\ntransfer function L(s) hasnpoles andmzeros at certain locations. Now, if we\\nwere to consider some point swith a very large magnitude (i.e., very far away\\nfrom the other poles and zeros), the poles and zeros would essentially look like\\nthey were clustered at one point; let’s call this point α. So, for large|s|, we\\nwould like to ﬁnd a good value of αso that we can approximate the transfer\\nfunction as\\nL(s) =sm+bm−1sm−1+bm−2sm−2+···+b1s+b0\\nsn+an−1sn−1+an−2sn−2+···+a1s+a0≈1\\n(s−α)n−m\\n⇔sn+an−1sn−1+an−2sn−2+···+a1s+a0\\nsm+bm−1sm−1+bm−2sm−2+···+b1s+b0≈(s−α)n−m.\\nNote that we are taking the exponent to be n−m, because to the point s, the\\nmzeros look like they are directly on top of npoles, and thus they ‘cancel’ each\\nother out. To see what value of αto choose, let’s start dividing the denominator\\non the left hand side into the numerator to obtain the ﬁrst couple of terms of\\nthe quotient:\\nThus, we can write\\n(s−α)n−m≈sn−m+ (an−1−bm−1)sn−m−1+···,\\nand since (s−α)n−m=sn−m−α(n−m)sn−m−1+···, if we compare the second\\nterm in the two expansions, we obtain\\nα=bm−1−an−1\\nn−m. (13.2)\\nNext, suppose that\\nN(s) = (s+z1)(s+z2)···(s+zm) =sm+m∑\\ni=1zism−1+···\\nD(s) = (s+p1)(s+p2)···(s+pn) =sn+n∑\\ni=1pisn−1+···.\\nThus, we have bm−1=∑m\\ni=1ziandan−1=∑n\\ni=1pi, which we substitute into\\n(13.2) to produce αin (13.1).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 111}, page_content='104 Root Locus\\nTo derive the asymptote angles in (13.1), consider the root locus of ( s−α)−(n−m).\\nRecall that the root locus of a function is the set of all ssuch that\\n∑\\n∠s+zi−∑\\n∠s+pi= (2l+ 1)π (13.3)\\nfor some integer l, whereziare the zeros and piare the poles. In this case, the\\nfunction (s−α)−(n−m)has no zeros, and all n−mpoles atα. Thus, we have∑∠s+pi≈(n−m)∠s−α, and the above expression becomes\\n∠s−α=(2l+ 1)π\\nn−m.\\nNote that the negative sign in front of the pole angles in (13.3) contributes an\\nangle of−π, which can just be absorbed into the term (2 l+ 1)π. There are\\nn−mdiﬀerent possibilities for the angle on the right hand side of the above\\nequation, corresponding to l= 0,1,...,n−m−1 (after this, the angles start\\nrepeating), and thus there are n−mdiﬀerent asymptotes leading out from the\\npoles atαwith the angles speciﬁed by (13.1).\\nExample. ConsiderL(s) =1\\ns(s+2). Draw the portions of the real axis that are\\non the positive root locus, and determine the asymptotes.\\nSolution.\\nExample. ConsiderL(s) =1\\ns((s+1)2+1). Draw the portions of the real axis that\\nare on the positive root locus, and determine the asymptotes.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 112}, page_content='13.2 Rules for Plotting the Positive Root Locus 105\\nSolution.\\nExample. ConsiderL(s) =s+6\\ns((s+1)2+1). Draw the portions of the real axis that\\nare on the positive root locus, and determine the asymptotes.\\nSolution.\\nSince we are only interested in polynomials D(s)+KN(s) that have purely real\\ncoeﬃcients, the roots of the polynomial will either be real or appear as complex\\nconjugate pairs. This produces the following important fact.\\nThe root locus is always symmetric about the real axis .\\n13.2.4 Breakaway Points\\nWe have already seen some examples of root loci where two or more points\\ncome together and then bounce oﬀ each other in opposite directions. Such\\npoints are called breakaway points. Note that at such points, the characteristic\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 113}, page_content='106 Root Locus\\npolynomial ∆( s) =D(s) +KN(s) will have multiple roots at the breakaway\\npoint. Let the breakaway point be s= ¯s. Then we can write\\n∆(s) = (s−¯s)q¯D(s),\\nwhereq≥2 is the multiplicity of the root ¯ s, and ¯D(s) is some polynomial. This\\nmeans that ∆(¯ s) = 0 andd∆\\nds(¯s) = 0. Substituting ∆( s) =D(s) +KN(s), we\\nhave\\nD(¯s) +KN(¯s) = 0\\ndD\\nds(¯s) +KdN\\nds(¯s) = 0.\\nSolving the ﬁrst equation, we get K=−D(¯s)\\nN(¯s), and substituting this into the\\nsecond equation, we come to the following rule.\\nRule 4. The root locus will have multiple roots at the points ¯ sfor\\nwhich both of the following conditions are satisﬁed.\\n•N(¯s)dD\\nds(¯s)−D(¯s)dN\\nds(¯s) = 0.\\n• −D(¯s)\\nN(¯s)=Kis a positive real number.\\nExample. Draw the positive root locus for L(s) =s+6\\ns(s+2).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 114}, page_content='13.2 Rules for Plotting the Positive Root Locus 107\\nExample. Verify that the branches in the positive root locus for L(s) =\\n1\\ns((s+1)2+1)never intersect.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 115}, page_content='108 Root Locus\\nThere are various other rules that we could derive to draw root locus plots, but\\nthey tend to be cumbersome to apply by hand. The above rules will be suﬃcient\\nfor us to get intuition about many systems.\\n13.2.5 Some Root Locus Plots\\nExample. Consider a control system in unity feedback with P(s) =1\\ns2and\\nC(s) =Ks+1\\ns+12. Draw the positive root locus.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 116}, page_content='13.2 Rules for Plotting the Positive Root Locus 109\\nExample. Consider a control system in unity feedback with P(s) =1\\ns2and\\nC(s) =Ks+1\\ns+4. Draw the positive root locus.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 117}, page_content='110 Root Locus\\nExample. Consider a control system in unity feedback with P(s) =1\\ns2and\\nC(s) =Ks+1\\ns+9. Draw the positive root locus.\\nSolution.\\nThe above examples show that as the pole of the controller moves in closer to\\nthe root locus, it tends to push the branches of the locus to the right. From our\\ndiscussion so far, we can state the following rules of thumb: poles repel, and\\nzeros attract .\\n13.2.6 Choosing the Gain from the Root Locus\\nThe positive root locus tells us how the poles of the closed loop system vary as\\nwe increase Kfrom 0 to∞. Once we’ve plotted the root locus, we may wish to\\nselect points on the branches so that the closed loop system will have certain\\ndesired properties (such as rise time, overshoot, peak time, etc). We then need\\nto ﬁnd the gain Kso that the closed loop poles will be at the desired locations.\\nTo ﬁnd the gain, note that\\nL(s) =−1\\nK⇔K=−1\\nL(s).\\nSinceKis a positive real number, we can examine the magnitude of both sides\\nof the above equation to obtain\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 118}, page_content='13.3 Rules for Plotting the Negative Root Locus 111\\nK=1\\n|L(s)|=|s+p1||s+p2|···|s+pn|\\n|s+z1||s+z2|···|s+zm|.\\nSpeciﬁcally, if we have a desired point ¯ son the root locus, we can ﬁnd the gain\\nKthat produces a pole at ¯ sby multiplying and dividing the lengths of the\\nvectors from each of the poles and zeros to ¯ s, according to the above equation.\\nExample. SupposeL(s) =1\\ns2+2s. Find the gain Kthat results in the closed\\nloop system having a peak time of at most 2 πseconds.\\nSolution.\\nNote that MATLAB is an extremely useful tool for doing this in practical con-\\ntroller design. Once one has plotted the root locus for a given system in MAT-\\nLAB (using the rlocus command), one can simply click on the root locus branch\\nat any desired location to ﬁnd the value of the gain at that point.\\n13.3 Rules for Plotting the Negative Root Locus\\nIn the last section, we saw how to plot the root locus for positive values of the\\ngainK. We can now complete the root locus by considering negative values of\\nK– this is called the negative root locus . The only diﬀerence in this case\\nstems from the phase condition. Recall that the root locus consists of all points\\nssatisfyingL(s) =−1\\nK. IfKis a negative real number, L(s) is a positive real\\nnumber, and thus we can state the following.\\nThe negative root locus is the set of all points sin the complex plane for\\nwhich ∠L(s) = 2lπradians (where lis any integer).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 119}, page_content='112 Root Locus\\nAll of the rules for plotting the positive root locus translate directly once we\\nconsider this new phase condition:\\n•Rule 1. Thenbranches of the root locus begin at the open loop poles\\n(whenK= 0). Of the nbranches,mbranches end at the open loop zeros\\n(whenK=−∞).\\n•Rule 2. The negative root locus contains all points on the real axis that\\nare to the left of an even number of zeros or poles.\\n•Rule 3. Of thenbranches in the root locus, n−mof the branches go to\\ninﬁnity, and asymptotically approach lines coming out of the point s=α\\nwith angles Φ l, where\\nα=Σ open loop poles −Σ open loop zeros\\nn−m,Φl=2lπ\\nn−m,\\nforl= 0,1,2,...,n−m−1.\\n•Rule 4. The root locus will have multiple roots at the points ¯ sfor which\\nboth of the following conditions are satisﬁed.\\nN(¯s)dD\\nds(¯s)−D(¯s)dN\\nds(¯s) = 0.\\n−D(¯s)\\nN(¯s)=Kis anegative real number.\\nNote that the gain for a particular point son the negative root locus is given\\nby\\nK=−1\\n|L(s)|=−|s+p1||s+p2|···|s+pn|\\n|s+z1||s+z2|···|s+zm|.\\nThe asymptotes for the negative root locus look like this:\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 120}, page_content='13.3 Rules for Plotting the Negative Root Locus 113\\nExample. Determine the negative root locus for L(s) =1\\ns((s+1)2+1), and then\\ndraw the complete root locus (both positive and negative).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 121}, page_content='114 Root Locus\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 122}, page_content='Chapter 14\\nStability Margins from\\nBode Plots\\nThe last chapter showed how to analyze and understand the closed loop system\\nfrom a root locus perspective. We will now study the use of Bode plots to\\nanalyze closed loop systems, complementing the root locus techniques. In the\\nnext chapter, we will use these ideas to design controllers (building on our study\\nof PID controllers).\\nSuppose we’re given the Bode plot for the transfer function L(s), and we would\\nlike to study properties of the following feedback loop:\\nR(s)\\nK L(s)Y(s)\\n−\\nIn other words, we would like to infer some things about the closed loop\\nsystem based on the open loop Bode plot . Remember that we also did this\\nwhen we studied root locus plots: we studied the locations of the closed loop\\npoles by starting with the open loop poles and zeros.\\nRecall the root locus equation 1 + KL(s) = 0 (the closed loop poles are the\\nvaluessthat satisfy this equation). When Kis a positive real number, this\\nmeans that|KL(s)|= 1 and ∠KL(s)≡π(modulo 2π). A points=jωon the\\nimaginary axis (for some ω) will be on the positive root locus if |KL(jω)|= 1 and\\n∠KL(jω)≡π. Since we have access to |KL(jω)|and∠KL(jω) from the Bode\\nplot, we should be able to determine the imaginary axis crossings by ﬁnding the\\nfrequencies ω(if any) on the plot that satisfy the conditions |KL(jω)|= 1 (or\\n20 log|KL(jω)|= 0) and ∠KL(jω)≡π.\\nTo develop this further, suppose that L(s) =1\\ns(s+1)(s\\n100+1). The Bode plot of\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 123}, page_content='116 Stability Margins from Bode Plots\\nKL(s) (withK= 1) is given below:\\nWe’ll be using the following terminology.\\n•Gain crossover frequency: This is the frequency ωcgsuch that\\n|KL(jωcg)|= 1 (or equivalently, 20 log |KL(jωcg)|= 0).\\n•Phase crossover frequency: This is the frequency ωcpsuch that\\n∠KL(jωcp)≡π.\\nFor the above example, we have ωcg≈1 andωcp≈10. The phase at ωcg\\nis approximately −3π\\n4, and so the feedback conﬁguration with K= 1 does\\nnot have any closed loop poles on the imaginary axis. Is there another value\\nofKfor which the closed loop system will have poles on the imaginary axis\\n(and thus cross the boundary from stability to instability)? To determine this\\nfrom the Bode plot, note that 20 log |KL(jω)|= 20 logK+ 20 log|L(jω)|and\\n∠KL(jω) =∠L(jω) (forK > 0). Thus,Khas no eﬀect on the phase, and it\\naﬀects the magnitude plot by shifting it up or down by 20 log K. For example,\\nwhenK= 10, the entire magnitude gets shifted up by 20 log 10 = 20 dB (when\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 124}, page_content='117\\nthe vertical axis denotes 20 log |KL(s)|); this is shown on the above Bode plot\\nby the dashed lines. Based on this plot, we see that changing Khas the eﬀect of\\nchanging the gain crossover frequency (but not the phase crossover frequency).\\nIn order to ﬁnd the value of Kthat causes some closed loop poles to lie on\\nthe imaginary axis in the above example, we need to ﬁnd out how to make the\\ngain crossover frequency and the phase crossover frequency coincide. Examining\\nthe magnitude plot, we see that 20 log |L(j10)|≈− 40, and thus the magnitude\\ncurve needs to be shifted up by approximately 40 dB in order to set ωcg=ωcp,\\nwhich can be accomplished by setting 20 log K≈40, orK≈100. Thus, we can\\nconclude that the closed loop system will have an imaginary axis crossing when\\nK≈100. One can easily see from the Bode plot that this is the only positive\\nvalue ofKfor which this will happen.\\nWe can verify this result by examining the positive root locus of L(s):\\nAs expected, the branches cross the imaginary axis only once (other than the\\ntrivial case where K= 0). To ﬁnd the locations where the branches cross the\\nimaginary axis, we note that\\n1 +KL(s) = 0\\n⇔1 +K1\\ns(s+ 1)(s\\n100+ 1)= 0\\n⇔s3+ 101s2+ 100s+ 100K= 0.\\nWe use the Routh-Hurwitz test to determine the region of stability as 0 <K <\\n101. Thus, we have a potential imaginary axis crossing at K= 101. To ﬁnd the\\npoints on the imaginary axis where this happens, we set s=jωandK= 101\\nand solve the equation\\n(jω)3+ 101(jω)2+ 100(jω) + 100(101) = 0\\n⇔ −jω3−101ω2+ 100ωj+ 100(101) = 0 .\\nSetting the imaginary and real parts to zero, we ﬁnd that ω= 10. Thus, we\\nhave an imaginary axis crossing at s=±10jwhenK= 101. Note that this\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 125}, page_content='118 Stability Margins from Bode Plots\\nagrees with the analysis from the Bode plot (the Bode plot actually told us\\nK≈100, since we approximated the Bode plot with straight lines).\\nWhile we could determine imaginary axis crossings by looking at the Bode\\nplot, we didn’t necessarily know which direction the branches were going –\\nare we going from stability to instability, or instability to stability? We could\\ndetermine this information by looking at the root locus, but we will later develop\\na completely frequency domain approach to characterizing the stability of the\\nclosed loop system. For now, we will assume that the closed loop system is\\nstable with a given value of K, and investigate ways to design controllers using\\na frequency domain analysis in order to improve the stability of the closed loop\\nsystem.\\nStability Margins\\nWe will deﬁne some terminology based on the discussion so far. Consider again\\nthe Bode plot of KL(s) withK= 1:\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 126}, page_content='119\\nAssuming that the closed loop system is stable, we can ask the question: How\\nfar from instability is the system? There are two metrics to evaluate this:\\n•Gain margin: This is the amount by which Kcan be multiplied\\nbefore|KL(jωcp)|= 1 (i.e., the gain crossover frequency and phase\\ncrossover frequencies coincide).\\n•Phase margin: This is the amount by which the phase at ωcg\\nexceeds−π; more speciﬁcally, it is deﬁned as\\nPM =∠L(jωcg) +π .\\nIn general, we would like to have large gain and phase margins in order to\\nimprove the stability of the system. In the above example with K= 1, the gain\\nmargin is approximately 100, and the phase margin is approximatelyπ\\n4. Let us\\nconsider some more examples, just to be clear on the concept of gain and phase\\nmargins.\\nExample. What is the gain margin and phase margin for KL(s) =1\\ns(s+1)2?\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 127}, page_content='120 Stability Margins from Bode Plots\\nExample. What is the gain margin and phase margin for KL(s) =s+1\\ns2(s\\n10+1)?\\nSolution.\\nIn the above example, we noticed that the gain margin is ∞, since the phase only\\nhits−πatω=∞. However, note that as we increase K, the gain crossover\\nfrequency starts moving to the right, and the phase margin decreases. If we\\nexamine the root locus for the system L(s) =s+1\\ns2(s\\n10+1), we see that we have a\\nset of poles that move vertically in the plane as K→∞ , and thus the damping\\nratioζfor these poles decreases as K→∞ . This seems to indicate that there\\nmight be some relationship between the phase margin and the damping ratio ζ.\\nWe will now derive an explicit relationship between these two quantities.\\nConsider the system L(s) =ω2\\nn\\ns(s+2ζωn), which is placed in the feedback conﬁgu-\\nration\\nR(s)\\nL(s)Y(s)\\n−\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 128}, page_content='121\\nThe closed loop transfer function is Try(s) =ω2\\nn\\ns2+2ζωns+ω2n, which is the standard\\nsecond order system with damping ratio ζ. The phase plot of L(jω) is given by\\nThis shows that the gain margin is ∞(and this is easily veriﬁed by looking at\\nthe root locus). Next, let’s examine the phase margin. By setting the magnitude\\nofL(jω) equal to 1, one can verify that the Bode plot of L(s) has gain crossover\\nfrequency equal to\\nωcg=ωn√√\\n1 + 4ζ4−2ζ2.\\nUsing the fact that PM =∠L(jωcg) +π, we obtain (after some algebra)\\nPM = tan−1\\uf8eb\\n\\uf8ed2ζ√√\\n1 + 4ζ4−2ζ2\\uf8f6\\n\\uf8f8.\\nNotice that the phase margin is a function of ζand notωn. Interestingly, this\\nseemingly complicated expression can be approximated fairly well by a straight\\nline for small values of ζ:\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 129}, page_content='122 Stability Margins from Bode Plots\\nFor 0≤ζ≤0.7, the phase margin (in degrees) and damping ratio are\\nrelated by\\nPM≈100ζ .\\nWhile we derived the above expression for the standard second order system, we\\ncan also use it as a general rule of thumb for higher order systems. Speciﬁcally,\\nas the phase margin decreases, the system becomes less stable, and might exhibit\\noscillatory behavior. We can use the above relationship to design control systems\\nin the frequency domain in order to obtain certain time-domain characteristics\\n(such as meeting overshoot speciﬁcations).\\nAnother useful rule-of-thumb that is generally adopted for the closed loop band-\\nwidthωBWis as follows:\\nIn general, we have ωcg≤ωBW≤2ωcg, andωBW≈ωn, which leads to\\nthe approximation\\nωBW≈ωcg≈ωn.\\nNote that our discussions here have assumed a typical Bode plot that has large\\nmagnitude at low frequencies, and low magnitude at high frequencies, with a\\nsingle gain crossover frequency. We can deal with more complicated Bode plots\\nby generalizing our discussions, but we’ll focus on these typical Bode plots for\\nnow.\\nIn order to obtain fast transient behavior, we typically want a large gain crossover\\nfrequency, but this would come at the cost of decreasing the phase margin. Fur-\\nthermore, in order to obtain better steady state tracking, we would typically\\nwant to increase the gain Kin order to boost the low frequency behavior, but\\nthis would again move the gain crossover frequency to the right and decrease\\nthe phase margin. Therefore, we must consider more complicated controllers\\n(other than just a simple proportional controller K) in order to obtain a good\\nphase margin, a good gain crossover frequency, and good steady state tracking.\\nThis will be the focus of the next part of the course.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 130}, page_content='Chapter 15\\nCompensator Design Using\\nBode Plots\\nWe now turn our attention to designing dynamic controllers (also called com-\\npensators), building on our earlier study of PID controllers. We have seen so far\\nthat the phase margin of a given system is representative of the system’s stabil-\\nity, and is directly related to the damping of the system – a larger phase margin\\nmakes the system more stable, and increases the damping. Given a system, we\\nthus want to design a controller that improves the phase margin. In certain sys-\\ntems, one way to do this would be to decrease the gain of the system, so that the\\ngain crossover frequency moves to the left (in the direction of increasing phase).\\nHowever, we have seen that the low frequency gain of the system is related to\\nhow well the system tracks reference inputs – a larger low frequency gain corre-\\nsponds to better tracking. Another metric is the gain crossover frequency: since\\nthe gain crossover frequency is approximately equal to the bandwidth and the\\nnatural frequency of the system, a larger gain crossover frequency corresponds\\nto faster response, but also leads to smaller phase margins. Therefore, we would\\nlike to design more sophisticated controllers in order to keep the low frequency\\ngain large (in order to meet tracking speciﬁcations), or to increase the gain\\ncrossover frequency (in order to obtain faster transients), and also to increase\\nthe phase at the gain crossover frequency (in order to boost the phase margin).\\nIn this chapter, we will study the design of lead and lagcompensators using\\nBode plots. We will start by introducing the form of these controllers.\\n15.1 Lead and Lag Compensators\\nIn our discussion on root locus plots, we came up with the following rule of\\nthumb: poles repel and zeros attract. In particular, we saw that adding a zero to\\nthe system via the controller can produce stability, when a simple proportional\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 131}, page_content='124 Compensator Design Using Bode Plots\\ncontroller could not. Recall that this was the same conclusion that we reached\\nwhen we were studying PID control.\\nExample. For the unity feedback loop with P(s) =1\\ns2, draw the positive root\\nlocus when C(s) =KandC(s) =K(s+ 1).\\nSolution.\\nHowever, we also discussed the fact that the PD controller C(s) =KP+KDsis\\nnot physically implementable, since it is not proper, and it would diﬀerentiate\\nhigh frequency noise, thereby producing large swings in output. In order to\\navoid this, we replaced the PD controller with a controller of the form C(s) =\\nKP+KDsp\\ns+p; the larger the value of p, the better the controller approximates\\nPDcontrol, but the more susceptible it is to high frequency noise. The modiﬁed\\nPD controller can be written as\\nC(s) =KP+KDps\\ns+p=KP(s+p) +KDps\\ns+p\\n=(KP+KDp)s+KPp\\ns+p\\n= (KP+KDp)s+KPp\\nKP+KDp\\ns+p.\\nIf we letK=KP+KDpandz=KPp\\nKP+KDp, we obtain the dynamic controller\\nC(s) =Ks+z\\ns+p.\\nThis controller is called a lead controller (or lead compensator) if z <p and\\nalag controller (or lag compensator) if z >p . To see where this terminology\\ncomes from, recall that if we applied a sinusoidal input cos( ωt) to the controller\\nC(s), the output would be |C(jω)|cos(ωt+∠C(jω)) in steady state. The phase\\nofC(jω) is given by ∠C(jω) =∠(jω+z)−∠(jω+p), and ifz < p , we have\\n∠C(jω)>0 (i.e., the output leads the input). On the other hand, if z >p , we\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 132}, page_content='15.1 Lead and Lag Compensators 125\\nhave∠C(jω)<0 (i.e., the output lagsthe input).\\nAs described above, the approximation to the PD controller has a large pole\\np, and thus is a lead compensator. As one might expect, a lag compensator is\\nthen an approximation to a PI controller. Speciﬁcally, consider a PI controller\\nof the form\\nC(s) =KP+KI\\ns=KPs+KI\\ns=KPs+KI\\nKP\\ns.\\nRecall that the reason for considering PI control was that it guaranteed perfect\\ntracking for a step (if the closed loop system is stable). It did this by introducing\\na pole at the origin in P(s)C(s), which is the same as saying that it increased\\nthe DC gain of P(s)C(s) to inﬁnity. In general, the higher we can make the\\nDC gain of P(s)C(s), the better it can track reference inputs. One way to do\\nthis would be to add a PI controller to the loop, but in some circumstances,\\nwe might be interested in using a stable controller (whereas the PI controller by\\nitself is unstable). Thus, suppose we approximate the PI controller by\\nC(s) =Ks+z\\ns+p,\\nwhereK=KP,z=KI\\nKP, andpis a small positive number. The smaller we make\\np, the better this controller approximates the PI controller. In particular, we\\nare interested in using this controller to boost the DC gain of P(s)C(s), and so\\nwe would like to make z>p . As we discussed earlier, this is a lag controller .\\nLag controllers are frequently used to improve the steady state error after we\\nhave already satisﬁed the transient specs (potentially with some other con-\\ntroller). The objective is typically to boost the DC gain of the controller, while\\ntrying to keep the poles of the closed loop system from changing too much.\\nOne example of this is lead-lag compensator design: use a lead compensator\\nto stabilize the system, and then use a lag compensator to boost the tracking\\naccuracy. We will discuss this later.\\nTo summarize:\\n•Lead compensation approximates PD control, and is used to stabilize the\\nsystem and improve the transient characteristics (by moving the locus to\\nthe left and improving the phase margin).\\n•Lag compensation approximates PI control, and is used to boost DC gain.\\nWe are now ready to design lead and lag compensators.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 133}, page_content='126 Compensator Design Using Bode Plots\\n15.2 Lead Compensator Design\\nFirst, consider the standard unity feedback loop:\\nR(s)\\nC(s)E(s)\\nP(s)Y(s)\\n−\\nA lead controller will have the form C(s) =Kcs+z\\ns+p, wherep>z . Sincep>z ,\\nwe can write z=αpfor some 0<α< 1. The Bode form of the above controller\\nis then given by\\nC(s) =Kcs+αp\\ns+p=Kcαp(s\\nαp+ 1)\\np(s\\np+ 1)=Kcα\\ued19\\ued18\\ued17\\ued1a\\nKs\\nαp+ 1\\ns\\np+ 1\\n\\ued19\\ued18\\ued17\\ued1a\\nCl(s).\\nThe phase margin of the closed loop system can be obtained by examining the\\nBode plot of C(s)P(s), which is obtained by simply adding together the Bode\\nplots ofCl(s) andKP(s) (since the magnitude is on a log scale, and the phases\\ninherently add). The gain Kof the compensator can be ﬁrst be chosen to meet\\nsteady state error speciﬁcations, or to obtain a certain crossover frequency. Once\\nthat is done, let’s see what the lead compensator contributes to the system by\\nexamining the Bode plot of Cl(s):\\nWe see that the phase plot of Cl(s) has a bump, and we can use this positive\\nphase contribution to increase the phase of KP(s). Speciﬁcally, we would like\\nto chooseαandpso that the bump occurs near the crossover frequency of\\nKCl(s)P(s), thereby increasing the phase margin of the system. To see how to\\nchoose the pole and zero, note that the phase of Cl(jω) is given by\\n∠Cl(jω) = tan−1(ω\\nαp)−tan−1(ω\\np).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 134}, page_content='15.2 Lead Compensator Design 127\\nFrom the phase plot, we note that the maximum phase occurs halfway between\\nthe zero and the pole (on a logarithmic scale). If we denote the frequency where\\nthe maximum phase occurs as ωmax, we have\\nlogωmax=1\\n2(log(αp) + log(p)) = log√\\nαp2,\\nfrom which we obtain ωmax=√αp. If we denote φmax=∠Cl(jωmax), we obtain\\n(after some algebra)\\nsinφmax=1−α\\n1 +α.\\nThese expressions are important, so let’s restate them:\\nThe maximum phase of the lead compensator with zero at αpand pole\\natpis denoted by φmaxand occurs at the frequency ωmax=√αp. The\\nmaximum phase satisﬁes the equation\\nsinφmax=1−α\\n1 +αor equivalently, α=1−sinφmax\\n1 + sinφmax.\\nThe idea will be to choose the pole and zero of the compensator such that ωmax\\nlies on the crossover frequency of KP(s), with the hope of contributing an extra\\nφmaxdegrees of phase margin. Let’s try an example to see how this works.\\nExample. ConsiderKP(s) =1\\ns(s+1). Draw an approximate Bode plot for\\nCl(s)KP(s) when the pole and zero of the compensator are such that the max-\\nimum compensator phase occurs at the gain crossover frequency of KP(s).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 135}, page_content='128 Compensator Design Using Bode Plots\\nFrom the above example, we see that although the compensator does contribute\\nφmaxto the phase at the gain crossover frequency of KP(s), the gain crossover\\nfrequency of Cl(s)KP(s) actually shifts to the right due to the positive magni-\\ntude contribution of Cl(s). Thus, the phase margin of KCl(s)P(s) is actually\\na little less than the phase margin of KP(s) plusφmax. In order to still get our\\ndesired phase margin, we should therefore make φmaxa little larger than we need\\n(usually about 10◦extra is enough), so that the phase margin of KCl(s)P(s)\\nwill meet the speciﬁcation.\\nThe complete design procedure for lead compensators is as follows.\\nLead Compensator Design\\n1. ChooseKto meet a steady state error speciﬁcation, or to meet a\\ngain crossover frequency speciﬁcation (in the latter case, one can\\nchooseKso that the crossover frequency of KP(s) is a little less\\nthan desired, since the lead compensator will shift the frequency\\nto the right a little bit).\\n2. Find the phase margin of KP(s) (from the Bode plot).\\n3. Find how much extra phase is required in order to meet the phase\\nmargin spec. Set φmaxto be this extra phase plus 10◦.\\n4. Findα=1−sinφmax\\n1+sinφmax.\\n5. Setωmaxto be the gain crossover frequency of KP(s). From this,\\nwe can calculate p=ωmax√αandz=√αωmax. The compensator is\\ngiven by\\nC(s) =Ks\\nαp+ 1\\ns\\np+ 1.\\n6. Check if the compensator achieves the speciﬁcations. If not, iter-\\nate or add another lead compensator.\\nNote: The lead compensator also sometimes appears as Clead(s) =Gain 11+aTs\\n1+Ts.\\nComparing this to the lead compensator given above, we have Gain 1=K,\\nT=1\\npanda=1\\nα.\\nExample. ConsiderP(s) =1\\ns(s+1). Design a lead compensator so that the\\nclosed loop system has a steady state tracking error of 0 .1 to a ramp input, and\\novershoot less than 25%.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 136}, page_content='15.2 Lead Compensator Design 129\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 137}, page_content='130 Compensator Design Using Bode Plots\\n15.3 Lag Compensator Design\\nLet us now consider lag controller design using the Bode plot method. Recall\\nthat lag controllers are approximations to PI controllers, and are used to boost\\nthe DC gain (in order to improve the steady state tracking error). Here, we will\\nsee how to design lag compensators using the Bode plot method to improve the\\nphase margin and satisfy steady state tracking specs. The Bode plot analysis\\nwill give us a perspective on why the pole and zero of the lag compensator are\\nusually chosen to be very small.\\nA lag controller will have the form C(s) =Kcs+z\\ns+p, wherez > p . Sincez > p ,\\nwe can write z=βpfor someβ >1. The Bode form of the above controller is\\nthen given by\\nC(s) =Kcs+βp\\ns+p=Kcβp(s\\nβp+ 1)\\np(s\\np+ 1)=Kcβs\\nβp+ 1\\ns\\np+ 1\\n\\ued19\\ued18\\ued17\\ued1a\\nCg(s).\\nNote that we are interested in the gain-boosting properties of the lag controller,\\nand so we will group the DC gain βwith the dynamics of the controller in the\\ntermCg(s) (this is in contrast to the lead controller, where we grouped the DC\\ngainαwith the gain Kc). In this case, we will be using the gain Kcto obtain a\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 138}, page_content='15.3 Lag Compensator Design 131\\ndesired phase margin, and the controller Cg(s) to boost the DC gain. Since the\\nBode plot of C(s)P(s) is obtained simply by adding together the Bode plots of\\nCg(s) andKcP(s), let us examine the Bode plot of Cg(s):\\nNote from the magnitude plot that Cg(s) will add to the magnitude of KcP(s)\\nat low frequencies, thereby reducing the steady state tracking error:\\nFurthermore, we see that the phase plot of Cg(s) has a dip between ω=pand\\nω=z, which will reduce the phase of KcP(s) in that frequency range. This\\nis generally bad, because a lower phase might lead to a reduced phase margin.\\nThe idea will be to choose the pole and zero very small, so that the dip in phase\\nwill occur at very low frequencies (far away from the gain crossover frequency).\\nThe design procedure for lag compensators can be summarized as follows.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 139}, page_content='132 Compensator Design Using Bode Plots\\nLag Compensator Design\\n1 ChooseKcto meet the phase margin speciﬁcation (with about\\n10◦of buﬀer to accommodate the phase lag induced by the lag\\ncontroller) by moving the gain crossover frequency to the left.\\n2 Find the low frequency gain of KcP(s), and determine how much\\nextra gainβshould be contributed by Cg(s) in order to meet the\\ntracking speciﬁcation.\\n3 Choose the zero zof the compensator to be about one decade\\nbelow the gain crossover frequency of KcP(s).\\n4 Choose the pole pof the compensator as p=z\\nβ. The compensator\\nis given by\\nC(s) =Kcβs\\nβp+ 1\\ns\\np+ 1.\\n5 Check if the compensator achieves the speciﬁcations. If not, iter-\\nate or add another compensator.\\nExample. ConsiderP(s) =1\\ns(s+1). Design a lag compensator so that the\\nclosed loop system has a steady state tracking error of 0 .1 to a ramp input, and\\novershoot less than 10%.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 140}, page_content='15.3 Lag Compensator Design 133\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 141}, page_content='134 Compensator Design Using Bode Plots\\nNote that we can use either a lead compensator or a lag compensator to satisfy\\nthe specs here. The diﬀerence is that the lag compensator increases the phase\\nmargin by reducing the gain crossover frequency, whereas the lead compensator\\nincreases the phase margin by adding more phase to the system. Therefore, the\\nresponse of the system with the lead compensator will generally be faster than\\nthat of the same system with a lag compensator. However, the lag compen-\\nsator is capable of boosting the DC gain of the system without substantially\\nmoving the gain crossover frequency or reducing the phase margin. Thus, a lag\\ncompensator is often used in order to improve the tracking characteristics of an\\nexisting controller, without aﬀecting the other performance metrics too much.\\nThe choice of controller will generally depend on the application requirements\\nand constraints.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 142}, page_content='Chapter 16\\nNyquist Plots\\nSo far, we have studied root locus methods and Bode plot methods for analyzing\\nthe behavior of closed loop systems from the open loop transfer functions. The\\nroot locus allows us to see how the poles of the transfer function change when\\nwe vary a certain parameter, and allows us to visualize the eﬀect of adding\\nadditional poles and zeros. However, the root locus is not capable of handling\\ndelays in the feedback loop (because a delay of τcontributes a term e−sτto\\nthe transfer function, which does not have a nice zero/pole interpretation).\\nFurthermore, the root locus cannot handle general uncertainties in the model\\n(it can, however, tell us something about the locations of the poles when a single\\nparameter is allowed to change slightly).\\nBode plots are able to capture uncertainties and delay, and we have seen how to\\nuse them to design controllers and analyze properties of the closed loop system.\\nHowever, up to this point, we have been assuming that the closed loop system\\nis stable when we put P(s) in the unity feedback loop with a certain controller\\ngainK. Under this condition, we have seen how to use the Bode plot of the\\nopen loop system KP(s) to determine how much we can boost Kbefore the\\nclosed loop poles cross the imaginary axis. We have also seen how to use Bode\\nplots to design lead and lag controllers in order to meet certain performance\\nspeciﬁcations. We will now study Nyquist plots , which complement Bode\\nplots to provide us with frequency response techniques to determine the stability\\nof the closed loop system (i.e., we will not have to assume initial stability, as\\nwe did in the Bode plot analysis). Furthermore, the Nyquist plots will provide\\nus with an alternative mechanism to evaluate the robustness of the system (via\\nthe gain margin and phase margin). To develop these concepts, we will need\\nthe notion of contours in the complex plane.\\nContour: A contour is a piecewise smooth path in the complex plane. The\\ncontour is closed if it starts and ends at the same point. A contour is simple\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 143}, page_content='136 Nyquist Plots\\nif it doesn’t cross itself at any point.\\nSuppose we have a system with transfer function\\nH(s) =(s+z1)(s+z2)···(s+zm)\\n(s+p1)(s+p2)···(s+pn),\\nand we consider a simple closed clockwise contour Cin the complex plane. At\\neach point ¯ son the contour C,H(¯s) is simply some complex number. If we\\nevaluateH(s) at all points on C, we get a closed (but not necessarily simple)\\ncontour which we will denote by H(C):\\nLet’s focus on a particular point ¯ son the contour C. The complex number H(¯s)\\nhas a magnitude and a phase; the latter is given by\\n∠H(¯s) =m∑\\ni=1∠(¯s+zi)−n∑\\ni=1∠(¯s+pi).\\nNote thatH(¯s) can be represented as a vector from the origin with magnitude\\n|H(¯s)|and angle ∠H(¯s), as shown in the above ﬁgure. We will be interested in\\nseeing how the phase of H(¯s) changes as the point ¯ smoves around the contour\\nC. To do this, we see from the above expression for ∠H(¯s) that we can examine\\nhow each of the quantities ∠(¯s+zi) and∠(¯s+pi) vary as ¯smoves around the\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 144}, page_content='137\\ncontourC. Suppose the contour Cand the distribution of poles and zeros looks\\nlike this:\\nThe quantity ∠(¯s+zi) is given by the angle between the vector from −zito\\n¯sand the positive real axis, and the quantity ∠(¯s+pi) is given by the angle\\nbetween the vector from −pito ¯sand the positive real axis. Now, consider a\\nzero−zithat is outside the contour C. As ¯smoves around the contour Cand\\ncomes back to its starting point, the vector ¯ s+ziswings up and down, but it\\ndoes not swing all the way around. As a result, the net change in ∠(¯s+zi) is\\n0◦. The same analysis holds for a pole outside the contour C.\\nNow consider a zero −zjinside the contour C. As ¯smoves around C, the vector\\n¯s+zjturns all the way around, and the net change in ∠(¯s+zj) is therefore\\n−360◦. Similarly, if we consider a pole −pjinsideC, the net change in ∠(¯s+pj)\\nis also−360◦.\\nIf we put this all together, we see that every zero and pole inside the contour\\nCinduces a net phase change of −360◦as ¯smoves around C, and every zero\\nand pole outside the contour Cinduces a net phase change of 0◦. LetZdenote\\nthe number of zeros of H(s) inside the contour C, and letPdenote the number\\nof poles of H(s) inside the contour C. From the earlier expression for ∠H(¯s),\\nwe see that ∠H(¯s) undergoes a net change of −(Z−P)360◦as ¯smoves around\\nthe contour C. Since each net change of −360◦means that the vector from the\\norigin toH(¯s) swings clockwise around the origin for one full rotation, a net\\nchange of−(Z−P)360◦means that the contour H(C) must encircle the origin\\nin the clockwise direction Z−Ptimes. This leads us to the following principle.\\nThe Principle of the Argument: LetCbe a simple closed clockwise\\ncontour, and consider the contour H(C) which is generated by evaluating\\na functionH(s) onC. The contour H(C) will encircle the origin in a\\nclockwise direction Z−Ptimes, where Zis the number of zeros and Pis\\nthe number of poles of H(s) that are contained inside C.\\nNote: The reason for calling this the Principle of the Argument is that the phase\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 145}, page_content='138 Nyquist Plots\\nof a complex number is also sometimes called the argument of the number, and\\nthe above principle is derived by considering how the phase of H(¯s) changes as\\n¯smoves around the contour C.\\nAlso note that we assume that the contour Cdoes not pass through any of the\\npoles or zeros of the transfer function (because the phase contribution of a zero\\nor pole is undeﬁned if we evaluate the contour at that point). Similarly, the\\nabove argument only applies if the contour H(C) does not pass through the\\norigin; the number of encirclements of the origin is undeﬁned otherwise.\\n16.1 Nyquist Plots\\nWe will now use the Principle of the Argument to study the stability of a closed\\nloop system. Consider a system L(s) placed in the following feedback loop:\\nR(s)\\nL(s)Y(s)\\n−\\nThe transfer function from rtoyis given by\\nTry(s) =L(s)\\n1 +L(s),\\nand the closed loop poles of this system are the set of all values ssuch that\\n1 +L(s) = 0. Deﬁne H(s) = 1 +L(s) (note that H(s) is a transfer function).\\nSpeciﬁcally, if we denote L(s) =N(s)\\nD(s), we obtain\\nH(s) = 1 +N(s)\\nD(s)=D(s) +N(s)\\nD(s).\\nNote that the poles of H(s) are actually the poles of L(s) (which are the open-\\nloop poles). The zeros of H(s) are the poles of the transfer function Try(s),\\nand thus they are the closed loop poles of the system. To determine how many\\nclosed loop poles lie in the CRHP, we use the Principle of the Argument. First,\\ndeﬁne the contour Cas follows:\\nThis contour encloses the entire right half plane. Part C1contains points of the\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 146}, page_content='16.1 Nyquist Plots 139\\nforms=jωasωranges from 0 to ∞, and partC2contains points of the form\\ns=−jω, asωranges from∞to 0. Parts C1andC2form the left boundary\\nof the right half plane. Part C3is a semicircle of inﬁnite radius, and can be\\ndescribed by the points s=ϵejθ, whereϵ→∞ , andθstarts at 90 degrees and\\nends at−90 degrees. Suppose we evaluate H(s) onCto produce the contour\\nH(C); for this choice of C,H(C) is called the Nyquist Plot ofH. If we letN\\ndenote the number of times H(C) encircles the origin clockwise, the Principle\\nof the Argument tells us that\\nN=Z−P ,\\nwhere\\n•Zis number of zeros of H(s) enclosed by the contour C(which corresponds\\nto the number of closed loop poles in the right half plane),\\n•Pis the number of poles of H(s) enclosed by the contour C(corresponding\\nto the number of open loop poles in the right half plane).\\nSincePis known (for example, by knowing L(s), or by assuming that L(s) is\\nstable), and since Ncan be determined by looking at the contour H(C), we\\ncan ﬁgure out Z, and thus determine the stability of the closed loop system.\\nWe will see an example of a Nyquist plot in the next example, and then we will\\ndiscuss how to draw these plots by hand.\\nExample. SupposeL(s) =10\\n(s+1)3. Determine the stability of the closed loop\\nsystem by examining the Nyquist plot of H, whereH(s) = 1 +L(s), andCis\\nthe contour containing the right half plane.\\nSolution.\\nIn order to apply the above technique, we needed to draw the Nyquist plot of\\nH(which is the contour H(C)). We can relate the Nyquist plot of Hto the\\nNyquist plot of the open loop system L(s) by noting that H(s) = 1 +L(s). The\\ncontourH(C) is thus obtained by shifting the contour L(C) one unit to the\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 147}, page_content='140 Nyquist Plots\\nright in the complex plane:\\nEncirclements of the origin by H(C) thus correspond to encirclements of the\\npoint−1 on the real axis by L(C). This means that we can simply focus on\\ndrawing the Nyquist plot of L, and seeing how many times it encircles the −1\\npoint. Next, we will see how to draw the Nyquist plot of L.\\n16.2 Drawing Nyquist Plots\\nConsider again the contour C:\\nThe Nyquist plot of L(s) is obtained by combining the contours L(C1),L(C2)\\nandL(C3), whereC1,C2andC3are the three portions of the contour C. We\\nwill now examine how to draw each of these contours.\\nContourC1\\nNote that the contour C1is made up of points of the form s=jω, asωranges\\nfrom 0 to∞. Each point on the contour L(C1) is then of the form L(jω), which\\nis just a complex number with magnitude |L(jω)|and phase ∠L(jω). We have\\naccess to these quantities from the Bode plot of L(s), and so we can draw the\\ncontourL(C1) by drawing the magnitude and phase plots from the Bode plot\\ntogether in the complex plane.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 148}, page_content='16.2 Drawing Nyquist Plots 141\\nExample. ConsiderL(s) =10\\n(s+1)2. Draw the contour L(C1).\\nSolution.\\nExample. ConsiderL(s) =10\\n(s+1)3. Draw the contour L(C1).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 149}, page_content='142 Nyquist Plots\\nContourC2\\nNow that we have drawn the contour L(C1), let us turn our attention to the\\ncontourL(C2). Note that the points on C2are of the form s=−jω, asωranges\\nfrom∞to 0. The points on the contour L(C2) are thus of the form L(−jω),\\nwhich is the complex conjugate of L(jω). The magnitude of L(jω) andL(−jω)\\nare the same, but the phases are negatives of each other. This means that the\\ncontourL(C2) is simply a mirrored version of L(C1) about the real axis. The\\ncontourL(C2) can now be added to the plots in the examples above.\\nContourC3\\nThe contour C3is described by points of the form s=ϵejθ, whereϵ→∞ ,\\nandθranges from 90◦to−90◦. The contour L(C3) is made up of points of the\\nformL(ϵejθ), and each of these points can be evaluated by substituting ϵejθinto\\nL(s). Speciﬁcally, note that since ϵis taken to be very large (inﬁnite, in fact),\\nthis term will dominate every factor that it appears in. Thus, if L(s) is strictly\\nproper,L(ϵejθ) will simply evaluate to zero (and thus L(C3) is a single point at\\nthe origin). If L(s) is nonstrictly proper, then L(ϵejθ) will be some constant.\\nThis will become clearer by evaluating L(C3) for the previous two examples,\\nand also from the following additional example.\\nExample. Draw the Nyquist plot of L(s) =s+1\\ns+10.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 150}, page_content='16.2 Drawing Nyquist Plots 143\\n16.2.1 Nyquist Plots For Systems With Poles/Zeros On\\nThe Imaginary Axis\\nThe Principle of the Argument assumes that the contour Cdoes not pass\\nthrough any of the zeros or poles of the function H(s) (because the angle con-\\ntribution of a pole or zero is undeﬁned when we evaluate the contour at that\\npoint). However, there may be cases when we want to draw the Nyquist plot\\nof a system L(s) that has poles or zeros on the imaginary axis. In this case,\\nwe modify the standard contour Cto take a small detour around the poles or\\nzeros:\\nFor example, the new portion C4on the contour is described by points of the\\nforms=ϵejθwhereϵ→0, andθranges from−90◦to 90◦. We can evaluate\\nL(C4) by substituting s=ϵejθintoL(s), and examining what happens as ϵ→0\\n(similarly to what was done for the portion C3). A few examples will make this\\nclear.\\nExample. ConsiderL(s) =1\\ns(s+1). Draw the Nyquist Plot of L(s).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 151}, page_content='144 Nyquist Plots\\nExample. ConsiderL(s) =1\\ns2(s+1). Draw the Nyquist Plot of L(s).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 152}, page_content='16.2 Drawing Nyquist Plots 145\\nExample. ConsiderL(s) =s(s+1)\\n(s+10)2. Draw the Nyquist Plot of L(s).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 153}, page_content='146 Nyquist Plots\\n16.3 Stability Margins from Nyquist Plots\\nNow that we have seen how to establish stability of a closed loop system by\\ndrawing the Nyquist plot of the open loop system L(s), we can return to the\\ntopic of stability margins. Speciﬁcally, when we were looking at Bode plots, we\\nconsidered gain and phase margins as indicators of how stable the closed loop\\nsystem was. Since the Nyquist plot tells us about the stability of the system, it\\ncan also provide us with the gain and phase margins.\\nTo see this, consider the closed loop system:\\nR(s)\\nK L(s)Y(s)\\n−\\nThe gainKsimply scales the Nyquist plot (since the magnitude on every point\\nof the contour KL(C) simply gets multiplied by K). In other words, increasing\\nKserves to push all of the points on the Nyquist plot further away from the\\norigin. We will see this from the following example.\\nExample. Draw the Nyquist plot of KL(s) forK= 1 andK= 200, where\\nL(s) =1\\ns(s+1)(s+10).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 154}, page_content='16.3 Stability Margins from Nyquist Plots 147\\nNote that the system is stable for small K, but unstable for large K(this can\\nbe conﬁrmed from the root locus of L(s)):\\nRecall that the gain margin is deﬁned as the factor by which Kcan be increased\\nbefore the closed loop system becomes unstable (we will deﬁne the gain margin\\nonly for systems that are closed loop stable for an initial value of K). In the\\nNyquist plot, this corresponds to scaling the plot so that the number of encir-\\nclements of the−1 point changes. Note that this is in complete accordance\\nwith the Bode plot analysis. Speciﬁcally, the point −1 in the complex plane\\nis a complex number with magnitude 1 and phase −180◦. When we looked\\nat Bode plots, we showed that imaginary axis crossings occur when the gain\\ncrossover frequency and phase crossover frequency coincide (which corresponds\\nto the case where KL(jω) =−1).\\nSimilarly, the phase margin is deﬁned as the amount by which the angle of\\nL(jωcg) exceeds−180◦, whereωcgis the point where |L(jωcg)|= 1. In the\\nNyquist plot, this can be obtained in the following way. First, draw a line\\nfrom the origin to the point where the Nyquist plot crosses a circle of radius\\n1 centered at the origin. This crossing point corresponds to |L(jω)|= 1. The\\nphase margin is then the angle between this line and the negative real axis:\\nExample. Identify the gain margin and phase margin for the example given\\nabove (with L(s) =1\\ns(s+1)(s+10)andK= 1).\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 155}, page_content='148 Nyquist Plots\\nExample. Investigate the stability (and associated margins) for the system\\nKL(s) =10(s+1)\\ns(s−1).\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 156}, page_content='16.3 Stability Margins from Nyquist Plots 149\\nNyquist Plots With Uncertainty and Delay\\nOne of the beneﬁts of Nyquist plots and Bode plots is that they provide a means\\nto deal with uncertainty in the system. Most systems are susceptible to high\\nfrequency noise, and it is usually hard to get a good indication of the magnitude\\nand phase of L(jω) for large values of ω. In this cases, we usually have a region\\nof uncertainty in the Nyquist plots and Bode plots for high frequencies:\\nThe gain margin and phase margin are clearly useful concepts for dealing with\\nthis issue. Typically, we would like to design the system to have suﬃciently\\nhigh margins so that the closed loop system is stable even with the worst case\\nuncertainty.\\nAnother beneﬁt of Nyquist and Bode plots is that they can readily handle delays\\nin the system. For example, consider the system ¨ y(t) + 2 ˙y(t) +y(t) =u(t−T).\\nIn this system, the output at time tis a function of the input at time t−T.\\nSince the Laplace transform of a delayed signal u(t−T) ise−sTU(s), the transfer\\nfunction for this system is given by\\nL(s) =Y(s)\\nU(s)=e−sT\\n(s+ 1)2.\\nWhens=jω, the terme−jωTis a complex number with magnitude 1 and phase\\n−ωT. This term has the eﬀect of subtracting ωTradians from the phase at each\\nfrequencyωon Bode plot of1\\n(s+1)2:\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 157}, page_content='150 Nyquist Plots\\nThe Nyquist plot of L(s) thus looks like this:\\nOnce again, the phase margin and gain margin come in handy, as they give us\\nan indication of the maximum delay that the system can tolerate before going\\nunstable. More speciﬁcally, note that a large delay can cause the Nyquist plot\\nto rotate enough that the number of encirclements of −1 changes, indicating\\nthat the closed loop system becomes unstable. In other words, a large delay can\\ndestabilize a feedback loop that is otherwise stable!\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 158}, page_content='Chapter 17\\nModern Control Theory:\\nState Space Models\\nUp to this point, we have been analyzing and designing control systems by us-\\ning a transfer-function approach (which allowed us to conveniently model the\\nsystem, and use techniques such as root-locus, Bode plots and Nyquist plots).\\nThese techniques were developed and studied during the ﬁrst half of the twen-\\ntieth century in an eﬀort to deal with issues such as noise and bandwidth issues\\nin communication systems. Transfer function methods have various drawbacks\\nhowever, since they cannot deal with nonlinear systems, are not very convenient\\nwhen considering systems with multiple inputs and outputs, and are diﬃcult to\\nuse for formulating ‘optimal’ control strategies. Starting in the 1950’s (around\\nthe time of the space race), control engineers and scientists started turning to\\nstate-space models of control systems in order to address some of these is-\\nsues. These are purely time-domain ordinary diﬀerential equation models of\\nsystems, and are able to eﬀectively represent concepts such as the internal state\\nof the system, and also present a method to introduce optimality conditions into\\nthe controller design procedure. This chapter will provide an introduction to\\nthe state-space approach to control design (sometimes referred to as “modern\\ncontrol”).\\n17.1 State-Space Models\\nState-space models are simply a set of diﬀerential equations deﬁning a system,\\nwhere the highest derivative in each equation is of order 1. To derive these\\nmodels, it is easiest to start with an example. Consider the system that is given\\nby the diﬀerential equation\\n¨y+ 3 ˙y+ 2y= 4u .\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 159}, page_content='152 Modern Control Theory: State Space Models\\nThe transfer function for this system can be readily found to be H(s) =Y(s)\\nU(s)=\\n4\\ns2+3s+2. To represent this model in state-space form, we ﬁrst draw an all-\\nintegrator block diagram for this system. Speciﬁcally, the all-integrator\\nblock diagram is simply a set of integrator blocks that are chained together\\naccording to the constraints imposed by the system. To obtain the diagram for\\nthis system, we ﬁrst solve for the highest derivative:\\n¨y=−2y−3 ˙y+ 4u .\\nStarting from the highest derivative (¨ y), we need to somehow obtain the lower\\nderivativesyand ˙y. This can be done by integrating ¨ ytwice, so we chain together\\ntwo integrator blocks. From this, we can easily obtain the all-integrator block\\ndiagram as:\\nEach integrator block in this diagram can be viewed as representing one of the\\ninternal states of the system. Let us assign a state variable to the output of\\neach integrator in order to represent the states. In this case, we will use the\\nstate variables x1andx2deﬁned as\\nx1=y, x 2= ˙y .\\nUsing the all integrator block diagram, we can diﬀerentiate each of the state\\nvariables to obtain\\n˙x1= ˙y=x2\\n˙x2= ¨y=−2y−3 ˙y+ 4u=−2x1−3x2+ 4u\\ny=x1.\\nThe above ﬁrst-order diﬀerential equations form the state-space model of\\nthe system. We can represent this model more concisely in matrix-vector form\\nas\\n[\\n˙x1\\n˙x2]\\n\\ued19\\ued18\\ued17\\ued1a\\n˙x=[\\n0 1\\n−2−3]\\n\\ued19\\ued18\\ued17\\ued1a\\nA[\\nx1\\nx2]\\n\\ued19\\ued18\\ued17\\ued1a\\nx+[\\n0\\n4]\\n\\ued19\\ued18\\ued17\\ued1a\\nBu\\ny=[1 0]\\n\\ued19\\ued18\\ued17\\ued1a\\nC[x1\\nx2]\\n\\ued19\\ued18\\ued17\\ued1a\\nx.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 160}, page_content='17.1 State-Space Models 153\\nGeneral linear state-space models are thus given by\\n˙x=Ax+Bu\\ny=Cx.(17.1)\\n•The vector xis called the state vector of the system. We will denote\\nthe number of states in the system by n, so that x∈Rn. The quantity\\nnis often called the order of the system. In the above example, we have\\nn= 2.\\n•In general, we might have multiple inputs u1,u2,...,umto the system. In\\nthis case, we can deﬁne an input vector u =[u1u2···um]′(the\\nnotation M′indicates the transpose of matrix M). In the above example,\\nm= 1.\\n•In general, we might have multiple outputs y1,y2,...,yp. In this case, we\\ncan deﬁne the output vector y =[y1y2···yp]′. Note that each of\\nthese outputs represents a sensor measurement of some of the states of\\nthe system. In the above example, we have p= 1.\\n•Thesystem matrix A is ann×nmatrix representing how the states of\\nthe system aﬀect each other.\\n•Theinput matrix B is ann×mmatrix representing how the inputs to\\nthe system aﬀect the states. The inputs are applied by mactuators.\\n•Theoutput matrix C is ap×nmatrix representing the portions of the\\nstates that are measured by the outputs. The outputs are provided by p\\nsensors.\\nLet us consider another example with multiple inputs and outputs.\\nExample. Derive the state-space model for the following mass-spring-damper\\nsystem. The inputs to the system are the forces F1andF2, and we would like\\nto measure the positions of each of the masses.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 161}, page_content='154 Modern Control Theory: State Space Models\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 162}, page_content='17.1 State-Space Models 155\\nThe states in state-space models often represent physical quantities in the sys-\\ntem. For example, one common model1for an F-8 aircraft contains four states:\\n•V: the horizontal-velocity deviation in feet/second.\\n•γ: the ﬂight-path angle in radians.\\n•α: the angle of attack in radians.\\n•q: the pitch rate in radians/second.\\nFurthermore, the input to the system is applied via a deﬂection in the elevator\\nangle, and is denoted by δe. These quantities are shown visually below:\\nThe state-space model for this system is given by\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0˙V\\n˙γ\\n˙α\\n˙q\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\n\\ued19\\ued18\\ued17\\ued1a\\n˙x=\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0−1.357×10−2−32.2−46.3 0\\n1.2×10−40 1.214 0\\n−1.212×10−40−1.214 1\\n5.7×10−40−9.01−6.696×10−1\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\n\\ued19 \\ued18\\ued17 \\ued1a\\nA\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0V\\nγ\\nα\\nq\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\n\\ued19\\ued18\\ued17\\ued1a\\nx+\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0−0.433\\n0.1394\\n−0.1394\\n−0.1577\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\n\\ued19\\ued18\\ued17\\ued1a\\nBδe\\ny=[\\n0 0 0 1\\n1 0 0 0]\\n\\ued19\\ued18\\ued17\\ued1a\\nCx.\\nNote that real aircraft dynamics are more complicated than this, and are non-\\nlinear; however they can be approximated by choosing the dominant states of\\nthe system, and linearizing the dynamics. We will look at this in more detail\\nnext.\\n1See the paper Linear Regulator Design for Stochastic Systems by a Multiple Time-Scales\\nMethod by Teneketzis and Sandell, IEEE Transactions in Automatic Control, vol 22, no. 4,\\nAug 1977, pp. 615-621, for more details.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 163}, page_content='156 Modern Control Theory: State Space Models\\n17.2 Nonlinear State-Space Models and Lineariza-\\ntion\\nAlthough we have been focusing on linear systems so far in the course, many\\npractical systems are nonlinear . Since state-space models are time-domain\\nrepresentations of systems, they can readily capture nonlinear dynamics.\\nExample: Pendulum.\\nWhile we can represent nonlinear systems using state-space models, we have\\nmuch better analysis techniques and tools for linear systems. Thus, nonlinear\\nsystems are frequently approximated by linear systems through a process known\\naslinearization . For example, suppose that we are interested in the model of\\nthe pendulum when it is close to vertical (i.e., when θis close to zero). In this\\ncase, note that sin θ≈θforθ≈0:\\nThe second state equation becomes ˙ x2=−g\\nlx1+1\\nml2Te, and thus the nonlinear\\npendulum model can be approximated by the linear model\\n˙x=[0 1\\n−g\\nl0]\\nx+[0\\n1\\nml2]\\nTe\\ny=[1 0]\\nx.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 164}, page_content='17.2 Nonlinear State-Space Models and Linearization 157\\nNext, we will see how to do this linearization more systematically.\\n17.2.1 Linearization via Taylor Series\\nConsider a general nonlinear diﬀerential equation of the form\\n˙x=f(x),\\nwherexis a real-valued signal and f(·) is some nonlinear function. In order to\\nlinearize general nonlinear systems of this form, we will use the Taylor Series\\nexpansion of functions. Suppose that ¯ xis a point such that f(¯x) = 0. In this\\ncase, the point ¯ xis called an equilibrium point of the above system, since we\\nhave ˙x= 0 whenx= ¯x(i.e., the system reaches an equilibrium at ¯ x). Recall\\nthat the Taylor Series expansion of f(x) around the point ¯ xis given by\\nf(x) =f(¯x)+df\\ndx⏐⏐⏐⏐\\nx=¯x(x−¯x)+1\\n2d2f\\ndx2⏐⏐⏐⏐\\nx=¯x(x−¯x)2+1\\n6d3f\\ndx3⏐⏐⏐⏐\\nx=¯x(x−¯x)3+···.\\nThis can be written as\\nf(x) =f(¯x) +df\\ndx⏐⏐⏐⏐\\nx=¯x\\ued19\\ued18\\ued17\\ued1a\\na(x−¯x) + higher order terms.\\nForxsuﬃciently close to ¯ x, these higher order terms will be very close to zero,\\nand so we can drop them to obtain the approximation\\nf(x)≈f(¯x) +a(x−¯x).\\nSincef(¯x) = 0, the nonlinear diﬀerential equation ˙ x=f(x) can be approxi-\\nmated near the equilibrium point by\\n˙x=a(x−¯x).\\nTo complete the linearization, we deﬁne the perturbation state (also known\\nasdelta state )δx=x−¯x, and using the fact that δ˙x= ˙x, we obtain the\\nlinearized model\\nδ˙x=aδx .\\nNote that this linear model is valid only near the equilibrium point (how “near”\\ndepends on how nonlinear the function is).\\nExtension To Functions of Multiple States and Inputs\\nThe extension to functions of multiple states and inputs is very similar to the\\nabove procedure. Suppose the evolution of state xiis given by\\n˙xi=fi(x1,x2,...,xn,u1,u2,...,um),\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 165}, page_content='158 Modern Control Theory: State Space Models\\nfor some general function fi. Suppose that the equilibrium points are given by\\n¯x1,¯x2,..., ¯xn,¯u1,¯u2,..., ¯um, so that\\nfi(¯x1,¯x2,..., ¯xn,¯u1,¯u2,..., ¯um) = 0∀i∈{1,2,...,n}.\\nNote that the equilibrium point should make allof the functions fiequal to\\nzero, so that all states in the system stop moving when they reach equilibrium.\\nThe linearization of fiabout the equilibrium point is then given by\\nfi(x1,...,xn,u1,...,um)≈n∑\\nj=1∂fi\\n∂xj⏐⏐⏐⏐\\nxj=¯xj(xj−¯xj)+m∑\\nj=1∂fi\\n∂uj⏐⏐⏐⏐\\nuj=¯uj(uj−¯uj).\\nIf we deﬁne the delta states and inputs δxj=xj−¯xj(for 1≤j≤n) and\\nδuj=uj−¯uj(for 1≤j≤m), the linearized dynamics of state xiare given by\\nδ˙xi=n∑\\nj=1∂fi\\n∂xj⏐⏐⏐⏐\\nxj=¯xjδxj+m∑\\nj=1∂fi\\n∂uj⏐⏐⏐⏐\\nuj=¯ujδuj.\\nNote: Sometimes the “ δ” notation is dropped in the linearized equation, with\\nthe implicit understanding that we are working with a linearized system.\\nExample. Linearize the nonlinear state-space model\\n˙x1=x2\\n1+ sinx2−1\\n˙x2=−x3\\n2+u\\ny=x1+x2\\naround the equilibrium point ¯ x1= 1,¯x2= 0,¯u= 0.\\nSolution.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 166}, page_content='17.3 The Transfer Function of a Linear State-Space Model 159\\n17.3 The Transfer Function of a Linear State-\\nSpace Model\\nSince we can generally convert nonlinear models to a linear model (in a small\\nregion around the equilibrium point), we will focus on linear state-space models\\nof the form\\n˙x=Ax+Bu,x∈Rn,u∈Rm,y∈Rp\\ny=Cx.\\nfor the rest of the chapter. Since this model represents a linear system, we can\\nask how the matrices A,BandCrelate to the transfer function of the system.\\nTo see this, take the Laplace Transform of the above state space equations:\\nsX(s)−x(0) = AX(s) +BU(s)\\nY(s) =CX(s).\\nNote that this includes the initial conditions of all the states. The ﬁrst equation\\ncan be rearranged to solve for X(s) as follows:\\n(sI−A)X(s) =x(0) + BU(s)⇔X(s) = (sI−A)−1x(0) + (sI−A)−1BU(s).\\nThe term Irepresents the n×nidentity matrix. Substituting this into the\\nequation for Y(s), we obtain\\nY(s) =C(sI−A)−1x(0) + C(sI−A)−1BU(s).\\nThe transfer function of the state-space model ˙x=Ax+Bu,y=Cx\\n(when x(0) = 0) is\\nH(s) =C(sI−A)−1B.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 167}, page_content='160 Modern Control Theory: State Space Models\\nNote that H(s) is ap×mmatrix, and thus it is a generalization of the transfer\\nfunction for standard single-input single-output systems. In fact, it is a matrix\\nwhere entry i,jis a transfer function describing how the j–th input aﬀects the\\ni–th output. When p= 1 andm= 1, we get the transfer function that we\\nstudied in the ﬁrst part of the course.\\nExample. Calculate the transfer function for the state space model\\n˙x=[0 1\\n−2−3]\\n\\ued19\\ued18\\ued17\\ued1a\\nAx+[0\\n4]\\n\\ued19\\ued18\\ued17\\ued1a\\nBu, y =[1 0]\\n\\ued19\\ued18\\ued17\\ued1a\\nCx.\\nSolution.\\nNote that the above solution agrees with the transfer function at the beginning\\nof the section.\\n17.4 Obtaining the Poles from the State-Space\\nModel\\nIn the last section, we saw that the transfer function of the linear system with\\nstate-space model\\n˙x=Ax+Bu\\ny=Cx\\nis given by H(s) =C(sI−A)−1B. Now, note that inverse of any matrix Mis\\ngiven byM−1=1\\ndet(M)adj(M), where det( M) is the determinant ofMand\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 168}, page_content='17.4 Obtaining the Poles from the State-Space Model 161\\nadj(M) is the adjoint matrix corresponding to M(this is just a matrix whose\\nentries are polynomials obtained from the entries of M). This means that the\\ndenominator of every entry in matrix ( sI−A)−1is det(sI−A), and so the poles\\nof the transfer function H(s) are the values of sfor which det( sI−A) = 0.\\nNext, recall the deﬁnition of the eigenvalues andeigenvectors of ann×nsquare\\nmatrix A. Speciﬁcally, a complex number λand an×1 vector vare said to be\\nan eigenvalue and eigenvector, respectively, of Aif they satisfy the equation\\nAv=λv.\\nIn other words, multiplying Abyvproduces a scaled version of v, and the\\nscaling factor is λ. Rearranging this equation, we get ( λI−A)v=0. Recall\\nthat this equation has a nonzero solution for vif and only if the matrix λI−Ahas\\nlinearly dependent columns, which is equivalent to saying that det( λI−A) = 0.\\nThus every possible λthat causes the determinant to be zero is an eigenvalue of\\nA, and as noted above, these are also the poles of the transfer function of the\\nlinear system.\\nThe poles of the transfer function H(s) =C(sI−A)−1Bare exactly\\nthe eigenvalues of matrix A. In other words, the poles are the values s\\nthat satisfy det( sI−A) = 0.\\nExample. Find the poles of the system with A=[0 1\\n−20−9]\\n,B=[1\\n1]\\n,\\nC=[\\n2 3]\\n.\\nSolution.\\nExample. Find the poles of the system with A=\\uf8ee\\n\\uf8f01 1−2\\n0−9 3\\n0 0 2\\uf8f9\\n\\uf8fb,B=\\uf8ee\\n\\uf8f01\\n1\\n0\\uf8f9\\n\\uf8fb,\\nC=[\\n1 0 1]\\n.\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 169}, page_content='162 Modern Control Theory: State Space Models\\nSolution.\\n17.5 An Overview of Design Approaches for State-\\nSpace Models\\nThere are various properties of systems that one can analyze in the state-space\\ndomain. For the plant given by the state-space equations in (17.1), the following\\ndeﬁnitions are commonly used.\\n•The system (17.1) is said to be controllable if there exists an input signal\\nu(t) such that the state x(T) achieves any desired value at some time-step\\nT.\\n•The system (17.1) is said to be observable if it is possible to recover the\\nentire state x(t) by looking at the outputs y(t) of the system over some\\nperiod of time.\\nControllability is about making the system state (not just the output) behave\\nhow we want it to by applying proper inputs. Observability is about whether we\\ncan determine what the internal state of the system is doing by looking at the\\noutputs. Both of these concepts play central roles in modern control systems\\ndesign.\\nWhen it comes to stabilization of systems in the state-space domain, one com-\\nmonly considers the use of linear state feedback . Speciﬁcally, suppose that\\nwe have access to the entire state x(t) of the system for all time; this is unreal-\\nistic, since we only have access to y(t), which measures only a few of the states,\\nbut let’s just assume it for now. Linear state feedback control applies an input\\nof the form\\nu(t) =−Kx(t),\\nc⃝Shreyas Sundaram'),\n",
       " Document(metadata={'source': 'ece380_notes.pdf', 'page': 170}, page_content='17.5 An Overview of Design Approaches for State-Space Models 163\\nfor some matrix Kthat we will choose. The closed loop system is then\\n˙x=Ax+Bu=Ax−BKx = (A−BK)x.\\nThe dynamics of the closed loop system are given by the matrix A−BK;\\nspeciﬁcally, as discussed in the previous section, the poles of this system are\\ngiven by the eigenvalues of this matrix. Thus, in order to obtain a stable system,\\nwe have to choose Kso that all eigenvalues of A−BKare stable (i.e., in the\\nOLHP). It turns out that it is possible to do this if the system is controllable.\\nThe above feedback mechanism assumed that we have access to the entire state.\\nSince we only have access to the measurements of a few state variables (provided\\nby the output y(t)), one strategy would be to try to reconstruct the entire state,\\nbased on the measurements available. This is possible if the system is observable,\\nin which case one can construct a state-estimator that provides an estimate\\nofx(t) to be used with the linear state feedback input described above. The\\narchitecture of state feedback control with a state estimator looks like this:\\nThe details of these topics, along with issues such as choosing the inputs op-\\ntimally, dealing with noise, etc., are treated in more advanced undergraduate\\nand graduate courses. Hopefully this course has piqued your interest in control\\nsystems, and motivated you to learn more about this subject in future courses!\\nThe End.\\nc⃝Shreyas Sundaram')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"ece380_notes.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\". \n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\". \n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['context', 'question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To solve for x in the equation 2x + 6 = 10, you can follow these steps:\\n\\n1. Subtract 6 from both sides:\\n   2x + 6 - 6 = 10 - 6\\n   2x = 4\\n\\n2. Divide both sides by 2:\\n   2x / 2 = 4 / 2\\n   x = 2\\n\\nSo, x = 2.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"2x + 6 = 10\",\n",
    "        \"question\": \"What is x?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "# would use pinecone instead here\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages, \n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    } \n",
    "    | prompt \n",
    "    | model \n",
    "    | parser \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what do you know?\n",
      "I don't know.\n",
      "Question: how many pages do you have access to?\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"what do you know?\",\n",
    "    \"how many pages do you have access to?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(chain.invoke({\"question\": question}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
